{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79782990",
   "metadata": {},
   "source": [
    "# A버전 codexa2 (LightGCN, implicit)\n",
    "- rating 무시, 유저별 8/1/1, popularity 네거티브 혼합\n",
    "- BPR + Recall/NDCG@K + 규칙기반 추천수 평가\n",
    "- early stopping + 베스트 checkpoint + 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff41e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# 설정\n",
    "DATA_PATH = Path('../data/train.csv')\n",
    "MODEL_DIR = Path('../codex_models'); MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "SEED = 42\n",
    "TRAIN_RATIO = 0.8; VAL_RATIO = 0.1\n",
    "EMBED_DIM = 64\n",
    "N_LAYERS = 3\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "BATCH_SIZE = 2048\n",
    "EPOCHS = 50\n",
    "POP_RATIO = 0.7\n",
    "N_NEG = 2\n",
    "K_EVALS = [10, 20]\n",
    "PATIENCE = 5\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "np.random.seed(SEED); torch.manual_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd20d9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_interactions(path: Path):\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "def encode_ids(df):\n",
    "    users = sorted(df['user'].unique()); items = sorted(df['item'].unique())\n",
    "    user2idx = {u:i for i,u in enumerate(users)}\n",
    "    item2idx = {v:i for i,v in enumerate(items)}\n",
    "    out = df.copy()\n",
    "    out['user_idx'] = out['user'].map(user2idx)\n",
    "    out['item_idx'] = out['item'].map(item2idx)\n",
    "    return out, user2idx, item2idx\n",
    "\n",
    "def split_userwise(df, train_ratio=0.8, val_ratio=0.1, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    trains=[]; vals=[]; tests=[]\n",
    "    for _, g in df.groupby('user_idx'):\n",
    "        idx = rng.permutation(len(g)); g=g.iloc[idx]\n",
    "        n=len(g); n_train=int(n*train_ratio); n_val=int(n*val_ratio)\n",
    "        trains.append(g.iloc[:n_train]); vals.append(g.iloc[n_train:n_train+n_val]); tests.append(g.iloc[n_train+n_val:])\n",
    "    return pd.concat(trains, ignore_index=True), pd.concat(vals, ignore_index=True), pd.concat(tests, ignore_index=True)\n",
    "\n",
    "def build_user_pos(df):\n",
    "    return df.groupby('user_idx')['item_idx'].agg(lambda x:set(x.tolist())).to_dict()\n",
    "\n",
    "def item_popularity(df, n_items):\n",
    "    counts = df['item_idx'].value_counts()\n",
    "    freq = np.ones(n_items)*1e-8\n",
    "    freq[counts.index] = counts.values\n",
    "    return freq/freq.sum()\n",
    "\n",
    "def make_norm_adj(num_users, num_items, edges):\n",
    "    rows = edges['user_idx'].to_numpy(); cols = edges['item_idx'].to_numpy() + num_users\n",
    "    data = np.ones(len(edges), dtype=np.float32)\n",
    "    mat = sp.coo_matrix((data,(rows, cols)), shape=(num_users+num_items, num_users+num_items))\n",
    "    mat = mat + mat.T\n",
    "    deg = np.array(mat.sum(axis=1)).flatten()\n",
    "    deg_inv_sqrt = np.power(deg, -0.5); deg_inv_sqrt[np.isinf(deg_inv_sqrt)] = 0.0\n",
    "    norm = sp.diags(deg_inv_sqrt) @ mat @ sp.diags(deg_inv_sqrt)\n",
    "    norm = norm.tocoo()\n",
    "    indices = torch.tensor(np.vstack((norm.row, norm.col)), dtype=torch.long)\n",
    "    values = torch.tensor(norm.data, dtype=torch.float32)\n",
    "    return torch.sparse_coo_tensor(indices, values, size=norm.shape).coalesce()\n",
    "\n",
    "def recall_at_k(ranked, gt, k):\n",
    "    if not gt: return 0.0\n",
    "    hit=sum(1 for i in ranked[:k] if i in gt)\n",
    "    return hit/min(k,len(gt))\n",
    "\n",
    "def ndcg_at_k(ranked, gt, k):\n",
    "    dcg=0.0\n",
    "    for idx,item in enumerate(ranked[:k]):\n",
    "        if item in gt:\n",
    "            dcg += 1/np.log2(idx+2)\n",
    "    ideal=min(len(gt),k); idcg=sum(1/np.log2(i+2) for i in range(ideal))\n",
    "    return dcg/idcg if idcg>0 else 0.0\n",
    "\n",
    "def rule_k(count):\n",
    "    if count<=10: return max(2,1)\n",
    "    return max(int(np.floor(0.2*count)),1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dc3c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BPRDataset(Dataset):\n",
    "    def __init__(self, df, num_items, user_pos, pop_prob, n_neg=1, pop_ratio=0.7, seed=42):\n",
    "        self.users=df['user_idx'].to_numpy(); self.pos=df['item_idx'].to_numpy(); self.num_items=num_items\n",
    "        self.user_pos=user_pos; self.pop_prob=pop_prob; self.n_neg=n_neg; self.pop_ratio=pop_ratio\n",
    "        self.rng=np.random.default_rng(seed)\n",
    "    def __len__(self): return len(self.users)\n",
    "    def __getitem__(self, idx):\n",
    "        u=int(self.users[idx]); i_pos=int(self.pos[idx]); seen=self.user_pos.get(u,set()); neg=None\n",
    "        while True:\n",
    "            if self.rng.random()<self.pop_ratio:\n",
    "                j=int(self.rng.choice(self.num_items, p=self.pop_prob))\n",
    "            else:\n",
    "                j=int(self.rng.integers(0,self.num_items))\n",
    "            if j not in seen:\n",
    "                neg=j; break\n",
    "        return u, i_pos, neg\n",
    "\n",
    "class LightGCN(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embed_dim, n_layers, adj):\n",
    "        super().__init__(); self.num_users=num_users; self.num_items=num_items; self.n_layers=n_layers; self.adj=adj\n",
    "        self.emb = nn.Embedding(num_users+num_items, embed_dim)\n",
    "        nn.init.normal_(self.emb.weight, std=0.1)\n",
    "    def forward(self):\n",
    "        x=self.emb.weight; embs=[x]\n",
    "        for _ in range(self.n_layers):\n",
    "            x=torch.sparse.mm(self.adj, x); embs.append(x)\n",
    "        out=torch.stack(embs, dim=0).mean(dim=0)\n",
    "        return out[:self.num_users], out[self.num_users:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bebd7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bpr_loss(u, i, j, reg=1e-4):\n",
    "    pos=(u*i).sum(dim=1); neg=(u*j).sum(dim=1)\n",
    "    loss = -torch.log(torch.sigmoid(pos-neg)+1e-8).mean()\n",
    "    reg_loss = reg*(u.norm(2).pow(2)+i.norm(2).pow(2)+j.norm(2).pow(2))/u.shape[0]\n",
    "    return loss+reg_loss\n",
    "\n",
    "def evaluate(model, user_pos_train, eval_df, k_list, device='cpu'):\n",
    "    model.eval(); u_emb,i_emb=model.forward(); u_emb=u_emb.to(device); i_emb=i_emb.to(device)\n",
    "    user_pos_eval = build_user_pos(eval_df)\n",
    "    metrics={k:{'rec':[],'ndcg':[]} for k in k_list}\n",
    "    for u, gt in user_pos_eval.items():\n",
    "        scores = (u_emb[u] @ i_emb.T)\n",
    "        seen=user_pos_train.get(u,set())\n",
    "        if seen:\n",
    "            scores[list(seen)] = -1e9\n",
    "        ranked = torch.topk(scores, k=max(k_list)).indices.cpu().numpy()\n",
    "        for k in k_list:\n",
    "            metrics[k]['rec'].append(recall_at_k(ranked, gt, k))\n",
    "            metrics[k]['ndcg'].append(ndcg_at_k(ranked, gt, k))\n",
    "    out={}\n",
    "    for k,v in metrics.items():\n",
    "        out[k]=(float(np.mean(v['rec'])), float(np.mean(v['ndcg'])))\n",
    "    return out\n",
    "\n",
    "def evaluate_rule(model, user_pos_train, eval_df, device='cpu'):\n",
    "    model.eval(); u_emb,i_emb=model.forward(); u_emb=u_emb.to(device); i_emb=i_emb.to(device)\n",
    "    user_pos_eval = build_user_pos(eval_df)\n",
    "    recalls=[]; hits=[]\n",
    "    for u, gt in user_pos_eval.items():\n",
    "        scores = (u_emb[u] @ i_emb.T)\n",
    "        seen=user_pos_train.get(u,set())\n",
    "        if seen:\n",
    "            scores[list(seen)] = -1e9\n",
    "        k = rule_k(len(user_pos_train.get(u,set())))\n",
    "        ranked = torch.topk(scores, k=k).indices.cpu().numpy()\n",
    "        hit = len([x for x in ranked if x in gt])\n",
    "        hits.append(hit)\n",
    "        recalls.append(hit/max(len(gt),1))\n",
    "    return float(np.mean(recalls)), float(np.mean(hits))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eff3dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 데이터 준비\n",
    "raw = load_interactions(DATA_PATH)\n",
    "df, user2idx, item2idx = encode_ids(raw)\n",
    "train_df, val_df, test_df = split_userwise(df, train_ratio=TRAIN_RATIO, val_ratio=VAL_RATIO, seed=SEED)\n",
    "num_users=len(user2idx); num_items=len(item2idx)\n",
    "user_pos_train = build_user_pos(train_df)\n",
    "pop_prob = item_popularity(train_df, num_items)\n",
    "adj = make_norm_adj(num_users, num_items, train_df).to(DEVICE)\n",
    "\n",
    "train_ds = BPRDataset(train_df, num_items, user_pos_train, pop_prob, n_neg=N_NEG, pop_ratio=POP_RATIO, seed=SEED)\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "model = LightGCN(num_users, num_items, EMBED_DIM, N_LAYERS, adj).to(DEVICE)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448c6606",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 학습 루프 + early stopping\n",
    "best_val = -1; patience_counter=0; history={'loss':[], 'val':[]}\n",
    "best_state=None\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train(); total=0.0\n",
    "    for u,i,j in train_loader:\n",
    "        u=u.to(DEVICE); i=i.to(DEVICE); j=j.to(DEVICE)\n",
    "        user_emb,item_emb = model.forward()\n",
    "        loss = bpr_loss(user_emb[u], item_emb[i], item_emb[j])\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "        total += loss.item()*u.shape[0]\n",
    "    avg_loss = total/len(train_loader.dataset)\n",
    "    val_metrics = evaluate(model, user_pos_train, val_df, K_EVALS, device=DEVICE)\n",
    "    history['loss'].append(avg_loss); history['val'].append(val_metrics)\n",
    "    best_k = K_EVALS[0]; val_recall = val_metrics[best_k][0]\n",
    "    if val_recall > best_val:\n",
    "        best_val = val_recall; best_state = {k:v.cpu() if torch.is_tensor(v) else v for k,v in model.state_dict().items()}; patience_counter=0\n",
    "    else:\n",
    "        patience_counter +=1\n",
    "    print(f\"Epoch {epoch} loss={avg_loss:.4f} val@{best_k} recall={val_metrics[best_k][0]:.4f} ndcg={val_metrics[best_k][1]:.4f} (patience {patience_counter}/{PATIENCE})\")\n",
    "    if patience_counter>=PATIENCE:\n",
    "        print('Early stopping'); break\n",
    "# restore best\n",
    "if best_state:\n",
    "    model.load_state_dict(best_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0ae41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 평가 (val/test, 규칙기반 포함)\n",
    "for split_name, data in [('val', val_df), ('test', test_df)]:\n",
    "    metrics = evaluate(model, user_pos_train, data, K_EVALS, device=DEVICE)\n",
    "    rule_rec, rule_hit = evaluate_rule(model, user_pos_train, data, device=DEVICE)\n",
    "    print(f\"[{split_name.upper()}] rule recall={rule_rec:.4f} hit={rule_hit:.4f}\")\n",
    "    for k,v in metrics.items():\n",
    "        print(f\"[{split_name.upper()}] k={k} recall={v[0]:.4f} ndcg={v[1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db9a085",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 시각화: loss + val recall@K_EVALS[0]\n",
    "ks = K_EVALS[0]\n",
    "recalls=[v[ks][0] for v in history['val']]\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1); plt.plot(history['loss']); plt.title('Train Loss'); plt.xlabel('epoch')\n",
    "plt.subplot(1,2,2); plt.plot(recalls); plt.title(f'Val Recall@{ks}'); plt.xlabel('epoch')\n",
    "plt.tight_layout();\n",
    "plt.savefig(MODEL_DIR/'codexa2_learning_curves.png'); plt.close()\n",
    "print('saved plot to', MODEL_DIR/'codexa2_learning_curves.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17765760",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 저장\n",
    "torch.save({'state_dict': model.state_dict(), 'num_users': num_users, 'num_items': num_items, 'embed_dim': EMBED_DIM, 'n_layers': N_LAYERS}, MODEL_DIR/'codexa2_lightgcn.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784171e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 추론 유틸\n",
    "def predict_ox(model, user_enc, item_enc, csv_path: Path, k=10, return_score=False):\n",
    "    df_in = pd.read_csv(csv_path)\n",
    "    users = df_in['user'].map(user_enc); items = df_in['item'].map(item_enc)\n",
    "    if users.isnull().any() or items.isnull().any():\n",
    "        raise ValueError('미등록 user/item 존재')\n",
    "    user_emb, item_emb = model.forward(); user_emb=user_emb.to(DEVICE); item_emb=item_emb.to(DEVICE)\n",
    "    results=[]; scores_list=[]\n",
    "    with torch.no_grad():\n",
    "        for u,i in zip(users.to_numpy(), items.to_numpy()):\n",
    "            scores = (user_emb[u] @ item_emb.T)\n",
    "            topk = torch.topk(scores, k=k).indices.cpu().numpy().tolist()\n",
    "            score = float((user_emb[u]*item_emb[i]).sum().cpu())\n",
    "            scores_list.append(score); results.append('O' if i in topk else 'X')\n",
    "    df_in['recommend']=results\n",
    "    if return_score:\n",
    "        df_in['score']=scores_list\n",
    "    total_o=df_in['recommend'].eq('O').sum(); total=len(df_in)\n",
    "    print(df_in)\n",
    "    print(f\"====================\n",
    "Total recommends = {total_o}/{total}\n",
    "Not recommend = {total-total_o}/{total}\")\n",
    "    return df_in\n",
    "\n",
    "# 예시\n",
    "# predict_ox(model, user2idx, item2idx, Path('../data/sample1.csv'), k=10, return_score=True)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}