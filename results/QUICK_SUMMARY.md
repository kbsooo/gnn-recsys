# ğŸ¯ EDA Quick Summary

## ë°ì´í„°ì…‹ í•œëˆˆì— ë³´ê¸°

### ğŸ“Š ê¸°ë³¸ í†µê³„
```
Users:        668ëª…
Items:        10,321ê°œ
Interactions: 105,139ê°œ
Sparsity:     98.48%
Density:      1.52%
```

### ğŸ‘¥ ì‚¬ìš©ì íŠ¹ì„±
```
í‰ê·  ìƒí˜¸ì‘ìš©:    157ê°œ
ì¤‘ì•™ê°’:           70ê°œ
í™œë™ë²”ìœ„:         20 ~ 5,672ê°œ
í‰ê·  í‰ì :        3.66 (std: 0.46)
```

### ğŸ¬ ì˜í™” íŠ¹ì„±
```
í‰ê·  ìƒí˜¸ì‘ìš©:    10ê°œ
ì¤‘ì•™ê°’:           3ê°œ
ì¸ê¸°ë²”ìœ„:         1 ~ 324ê°œ

Long-tail:
  - 1íšŒë§Œ:        35.3%
  - â‰¤5íšŒ:         67.4%
  - â‰¤10íšŒ:        79.1%
```

### â­ í‰ì  ë¶„í¬
```
ìµœë¹ˆê°’:    4.0 (27.4%)
í‰ê· :      3.52
ì¤‘ì•™ê°’:    3.5

ê¸ì •í¸í–¥:  82%ê°€ 3ì  ì´ìƒ
```

### ğŸ¯ Threshold ë¶„ì„ (ì¶”ì²œ O/X)
```
â‰¥4.0: 49.3% vs 50.7%  â† âœ… ì¶”ì²œ!
â‰¥3.5: 60.9% vs 39.1%
â‰¥3.0: 81.5% vs 18.5%
```

---

## ğŸš¨ í•µì‹¬ ë„ì „ ê³¼ì œ

1. **ê·¹ë„ì˜ Sparsity (98.5%)**
   - GNN message passing ì œí•œì 

2. **Long-tail ë¶„í¬**
   - 79% ì•„ì´í…œì´ â‰¤10 interactions
   - Cold-start ë¬¸ì œ

3. **ì‚¬ìš©ì í™œë™ë„ ë¶„ì‚°**
   - 20 ~ 5,672ê°œ (ì°¨ì´ 284ë°°)
   - Degree normalization í•„ìš”

4. **ë¹„ì—°ì†ì  Item ID**
   - 1 ~ 149,532 ë²”ìœ„, ì‹¤ì œ 10,321ê°œ
   - Re-indexing í•„ìˆ˜

5. **í‰ì  ê¸ì • í¸í–¥**
   - Negative sampling ì „ëµ ì¤‘ìš”

---

## ğŸ’¡ ì¶”ì²œ ì „ëµ

### ì „ì²˜ë¦¬
- [x] User/Item re-indexing (0ë¶€í„° ì‹œì‘)
- [x] Threshold 4.0 ì‚¬ìš©
- [x] Train/Val split (80:20)
- [x] Negative sampling (1:1 ratio)

### ëª¨ë¸
- [x] **LightGCN** (1ìˆœìœ„) - ê°„ë‹¨í•˜ê³  íš¨ê³¼ì 
- [ ] GraphSAGE (2ìˆœìœ„) - ë‹¤ì–‘í•œ aggregator
- [ ] GAT (3ìˆœìœ„) - Attention (ë³µì¡í•¨)

### í•™ìŠµ
- [x] Loss: Binary Cross-Entropy or BPR
- [x] Epochs: 50-100 (early stopping)
- [x] Embedding dim: 64 or 128
- [x] Layers: 2-3
- [x] Metrics: Precision@K, Recall@K, Hit Rate

---

## ğŸ“ˆ ê¸°ëŒ€ íš¨ê³¼

### GNNì´ ë„ì›€ ë  ê²ƒ:
âœ… Collaborative filtering (ìœ ì‚¬ ì‚¬ìš©ì/ì•„ì´í…œ ë°œê²¬)
âœ… Sparse ë°ì´í„°ì—ì„œ íŒ¨í„´ í•™ìŠµ
âœ… Multi-hop neighbor ì •ë³´ í™œìš©
âœ… Implicit feedback ì²˜ë¦¬

### ì£¼ì˜í•  ì :
âš ï¸ Over-smoothing (layer ë„ˆë¬´ ë§ìœ¼ë©´ ì„±ëŠ¥ ì €í•˜)
âš ï¸ Long-tail item ì„±ëŠ¥ ë‚®ì„ ìˆ˜ ìˆìŒ
âš ï¸ Negative sampling ì „ëµì— ë”°ë¼ ì„±ëŠ¥ ì°¨ì´ í¼

---

## ğŸ“ ìƒì„±ëœ íŒŒì¼

```
results/
â”œâ”€â”€ EDA_REPORT.md                    (ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸)
â”œâ”€â”€ QUICK_SUMMARY.md                 (ì´ íŒŒì¼)
â”œâ”€â”€ eda_visualizations.png           (9ê°œ ì‹œê°í™”)
â””â”€â”€ eda_detailed_analysis.png        (3ê°œ ì‹¬í™” ë¶„ì„)

notebooks/
â”œâ”€â”€ eda_analysis.py                  (í†µê³„ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸)
â””â”€â”€ visualizations.py                (ì‹œê°í™” ìŠ¤í¬ë¦½íŠ¸)
```

---

## ğŸ¯ ë‹¤ìŒ ìŠ¤í…

1. â¬œ **ë°ì´í„° ì „ì²˜ë¦¬ êµ¬í˜„** (preprocessing.py)
2. â¬œ **PyTorch Geometric ì„¤ì¹˜**
3. â¬œ **Baseline GNN ëª¨ë¸** (model.py)
4. â¬œ **í•™ìŠµ ë£¨í”„** (train.py)
5. â¬œ **ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸** (inference.py)
6. â¬œ **í‰ê°€ & ì‹œê°í™”**
7. â¬œ **ë°œí‘œ ì¤€ë¹„**

---

**Ready to Code? Let's build the GNN! ğŸš€**
