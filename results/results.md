## @gnn_recsys_v4.ipynb 결과

============================================================
Training 시작 (V4 - Negative Ratio 증가)
============================================================
Model: LightGCN
  - Users: 668, Items: 10321
  - Embedding dim: 32
  - Layers: 1
  - Total params: 351,648

Device: mps
Batch size: 512
Learning rate: 0.001
Weight decay: 0.0001
⭐ Negative ratio: 4 (V3: 1 → V4: 4)
Patience: 15
============================================================
Epoch   1/100 | Loss: 0.6908 | P@10: 0.0128 | R@10: 0.0124 | NDCG@10: 0.0191
Epoch   5/100 | Loss: 0.3751 | P@10: 0.0413 | R@10: 0.0660 | NDCG@10: 0.0667
Epoch  10/100 | Loss: 0.3244 | P@10: 0.0414 | R@10: 0.0655 | NDCG@10: 0.0664
Epoch  15/100 | Loss: 0.3167 | P@10: 0.0410 | R@10: 0.0651 | NDCG@10: 0.0651
Epoch  20/100 | Loss: 0.3122 | P@10: 0.0416 | R@10: 0.0634 | NDCG@10: 0.0652
Epoch  25/100 | Loss: 0.3069 | P@10: 0.0435 | R@10: 0.0655 | NDCG@10: 0.0674
Epoch  30/100 | Loss: 0.3031 | P@10: 0.0431 | R@10: 0.0663 | NDCG@10: 0.0670

Early stopping at epoch 32
============================================================
Training 완료! (V4)
Best Recall@10: 0.0664
============================================================

============================================================
Test Set 평가 (V4)
============================================================

Top-5 추천:
  Precision@5: 0.1210
  Recall@5:    0.0487
  NDCG@5:      0.1340

Top-10 추천:
  Precision@10: 0.1058
  Recall@10:    0.0775
  NDCG@10:      0.1331

Top-20 추천:
  Precision@20: 0.0912
  Recall@20:    0.1250
  NDCG@20:      0.1411
============================================================

## @baseline_models.ipynb 결과

============================================================
BPR-MF Training 시작
============================================================
Model: BPR-MF (Matrix Factorization)
  - Users: 668, Items: 10321
  - Embedding dim: 64
  - Total params: 703,296

Device: mps
Batch size: 512
Learning rate: 0.0005
Negative ratio: 4
============================================================
Epoch   1/100 | Loss: 0.6944 | R@10: 0.0021
Epoch   5/100 | Loss: 0.6790 | R@10: 0.0148
Epoch  10/100 | Loss: 0.5954 | R@10: 0.0581
Epoch  15/100 | Loss: 0.3897 | R@10: 0.0686
Epoch  20/100 | Loss: 0.3181 | R@10: 0.0662
Epoch  25/100 | Loss: 0.2935 | R@10: 0.0647
Epoch  30/100 | Loss: 0.2803 | R@10: 0.0672

Early stopping at epoch 30
============================================================
BPR-MF Training 완료!
Best Recall@10: 0.0686
============================================================

============================================================
BPR-MF - Test 평가
============================================================

Top-5 추천:
  Precision@5: 0.1210
  Recall@5:    0.0484
  NDCG@5:      0.1373

Top-10 추천:
  Precision@10: 0.1102
  Recall@10:    0.0800
  NDCG@10:      0.1389

Top-20 추천:
  Precision@20: 0.0926
  Recall@20:    0.1248
  NDCG@20:      0.1448
============================================================

## @gnn_recsys_v5.ipynb

============================================================
Training 시작 (V5 - Standard Configuration)
============================================================
Model: LightGCN
  - Users: 668, Items: 10321
  - Embedding dim: 64
  - Layers: 2
  - Total params: 703,296
  - Train samples: 44,542
  - Params/Data ratio: 15.79x

Device: mps
Batch size: 512
Learning rate: 0.0005
Weight decay: 0.0001
Negative ratio: 4
Patience: 15
============================================================
Epoch   1/100 | Loss: 0.6908 | P@10: 0.0086 | R@10: 0.0072 | NDCG@10: 0.0120
Epoch   5/100 | Loss: 0.4340 | P@10: 0.0425 | R@10: 0.0666 | NDCG@10: 0.0670
Epoch  10/100 | Loss: 0.3409 | P@10: 0.0424 | R@10: 0.0664 | NDCG@10: 0.0666
Epoch  15/100 | Loss: 0.3357 | P@10: 0.0416 | R@10: 0.0658 | NDCG@10: 0.0652

Early stopping at epoch 18
============================================================
Training 완료! (V5)
Best Recall@10: 0.0671
============================================================

============================================================
Test Set 평가 (V5)
============================================================

Top-5 추천:
  Precision@5: 0.1246
  Recall@5:    0.0498
  NDCG@5:      0.1363

Top-10 추천:
  Precision@10: 0.1073
  Recall@10:    0.0784
  NDCG@10:      0.1340

Top-20 추천:
  Precision@20: 0.0899
  Recall@20:    0.1217
  NDCG@20:      0.1387
============================================================