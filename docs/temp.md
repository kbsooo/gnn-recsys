ğŸ“Š ë‘ ë…¸íŠ¸ë¶ ì‹¤í–‰ ê²°ê³¼ ë¶„ì„                                                  02:40 PM  claude-sonnet-4-5-20250929

  1. í•µì‹¬ ì„±ëŠ¥ ë¹„êµ

  | ì§€í‘œ               | LightGCN (GNN) | NeuMF (DL) | ë¹„êµ            |
  |------------------|----------------|------------|---------------|
  | Best Recall@10   | 0.0620         | 0.0739     | NeuMF +19%    |
  | Final Recall@10  | 0.0589         | 0.0459     | -             |
  | Final NDCG@10    | 0.0662         | 0.0373     | LightGCN +77% |
  | Best F1 Score    | 0.6583         | 0.6643     | NeuMF +0.9%   |
  | Final Loss       | 0.3837         | 0.0146     | -             |
  | Total Parameters | 703,296        | 1,433,537  | NeuMF 2ë°°      |

  ---
  2. ğŸš¨ ì‹¬ê°í•œ ë¬¸ì œ ë°œê²¬

  ì„±ëŠ¥ì´ ì˜ˆìƒë³´ë‹¤ ê·¹ë„ë¡œ ë‚®ìŒ!

  - ì˜ˆìƒ: Recall@10 â‰ˆ 0.20~0.30
  - ì‹¤ì œ: Recall@10 â‰ˆ 0.06~0.07
  - Gap: ì˜ˆìƒì˜ 25~30% ìˆ˜ì¤€

  ì´ëŠ” ëª…í™•í•œ ë¬¸ì œë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

  ---
  3. ë¬¸ì œ ì›ì¸ ë¶„ì„

  3.1 í‰ê°€ ì§€í‘œ ê³„ì‚° ë°©ì‹ ë¬¸ì œ

  í˜„ì¬ êµ¬í˜„:
  # Per-user evaluation: ê° userì— ëŒ€í•´ ëª¨ë“  10,321ê°œ item ì¤‘ Top-10 ì¶”ì¶œ
  y_true = np.zeros(n_items)  # 10,321ê°œ ì¤‘ positiveë§Œ í‘œì‹œ
  for _, row in user_interactions.iterrows():
      y_true[item_idx] = row['label']

  ë¬¸ì œì :
  - Validationì—ì„œ ê° userë‹¹ í‰ê·  31ê°œ ìƒí˜¸ì‘ìš© (21,284 / 668)
  - ê·¸ ì¤‘ ì•½ 15ê°œê°€ positive (49.28%)
  - 10,321ê°œ item ì¤‘ 10ê°œë§Œ ì„ íƒí•˜ë©´ ë‹¹ì—°íˆ hit í™•ë¥ ì´ ë‚®ìŒ
  - Recall@10 = 10/15 = 0.67 ì´ì–´ì•¼ í•˜ì§€ë§Œ, ëª¨ë“  itemì—ì„œ randomí•˜ê²Œ ì¶”ì²œí•˜ë©´
  í›¨ì”¬ ë‚®ìŒ

  3.2 ëª¨ë¸ì´ ì œëŒ€ë¡œ í•™ìŠµë˜ì§€ ì•ŠìŒ

  ì¦ê±°:
  1. LightGCN:
    - Lossê°€ 0.40 â†’ 0.38ë¡œ ê±°ì˜ ê°ì†Œ ì•ˆí•¨
    - Recall@10ì´ 100 epoch ë™ì•ˆ 0.058~0.062 ì‚¬ì´ì—ì„œ ì •ì²´
  2. NeuMF:
    - LossëŠ” 0.21 â†’ 0.015ë¡œ ì˜ ê°ì†Œ
    - í•˜ì§€ë§Œ Recall@10ì´ epoch 15 (0.0739) ì´í›„ ì˜¤íˆë ¤ ê°ì†Œ â†’ Overfitting
    - NDCG@10ë„ 0.0694 â†’ 0.0373ìœ¼ë¡œ ì‹¬ê°í•˜ê²Œ ê°ì†Œ

  3.3 ê·¼ë³¸ ì›ì¸

  1. Negative Sampling ë°©ì‹ ë¬¸ì œ
    - í˜„ì¬: ëª¨ë“  ìƒí˜¸ì‘ìš©ì„ positiveë¡œ ì·¨ê¸‰ (rating ë¬´ì‹œ)
    - ì‹¤ì œë¡œëŠ” rating < 4.0ì¸ ê²ƒë„ í•™ìŠµ ë°ì´í„°ì— í¬í•¨
    - ì˜ëª»ëœ positive sampleì„ í•™ìŠµí•˜ê³  ìˆìŒ
  2. í‰ê°€ í”„ë¡œí† ì½œ ë¶ˆì¼ì¹˜
    - í•™ìŠµ: ëª¨ë“  ìƒí˜¸ì‘ìš©ì„ positiveë¡œ ì‚¬ìš©
    - í‰ê°€: rating â‰¥ 4.0ë§Œ positiveë¡œ ì·¨ê¸‰
    - Train-Test ë¶ˆì¼ì¹˜
  3. ë°ì´í„° í¬ì†Œì„± ê³¼ì†Œí‰ê°€
    - 98.48% sparsityì—ì„œ 10,321ê°œ item ì „ì²´ rankingì€ ë„ˆë¬´ ì–´ë ¤ì›€
    - Userë‹¹ í‰ê·  125ê°œë§Œ í•™ìŠµ ë°ì´í„° (83,855 / 668)

  ---
  4. NeuMFê°€ LightGCNë³´ë‹¤ ë‚˜ì€ ì´ìœ 

  ì˜ˆìƒê³¼ ë°˜ëŒ€ ê²°ê³¼:
  - ì¼ë°˜ì ìœ¼ë¡œ LightGCN > NeuMF (5-10%)
  - ì‹¤ì œ: NeuMF > LightGCN (19%)

  ì›ì¸:
  1. ë°ì´í„° í¬ê¸°ê°€ ë„ˆë¬´ ì‘ìŒ (668 users, 105k interactions)
    - Graph structureì˜ ì´ì ì´ ì œí•œì 
    - Multi-hop aggregationì´ noiseë¥¼ ì¦í­ì‹œí‚¬ ìˆ˜ ìˆìŒ
  2. LightGCNì´ underfitting
    - Loss ê°ì†Œê°€ ê±°ì˜ ì—†ìŒ (0.40 â†’ 0.38)
    - Graph convolutionì´ íš¨ê³¼ì ìœ¼ë¡œ í•™ìŠµë˜ì§€ ì•ŠìŒ
  3. NeuMFê°€ overfitting
    - ì´ˆê¸°ì—ëŠ” ì˜ í•™ìŠµë˜ë‹¤ê°€ (epoch 15: 0.0739)
    - ì´í›„ validation ì„±ëŠ¥ ê¸‰ë½ (epoch 100: 0.0459)
    - Best model ì €ì¥ìœ¼ë¡œ 0.0739 ìœ ì§€

  ---
  5. Threshold íŠœë‹ ê²°ê³¼ ë¶„ì„

  LightGCN

  Best threshold: 0.2122 (F1: 0.6583)
  Precision: 0.5094, Recall: 0.9303

  NeuMF

  Best threshold: -5.0894 (F1: 0.6643)
  Precision: 0.5140, Recall: 0.9387

  ë¬¸ì œì :
  - ë‘ ëª¨ë¸ ëª¨ë‘ ë§¤ìš° ë‚®ì€ threshold ì„ íƒ
  - ê²°ê³¼: ê±°ì˜ ëª¨ë“  ê²ƒì„ ì¶”ì²œ (19,155/21,284 = 90%)
  - High Recall (93%), Low Precision (51%)
  - ì´ëŠ” ëª¨ë¸ì´ ì˜ë¯¸ ìˆëŠ” êµ¬ë¶„ì„ ëª»í•œë‹¤ëŠ” ì¦ê±°

  ---
  6. ê¸´ê¸‰ ê°œì„  í•„ìš”ì‚¬í•­

  6.1 ì¦‰ì‹œ ìˆ˜ì • (Critical)

  1. í•™ìŠµ ë°ì´í„° í•„í„°ë§
  # í˜„ì¬: ëª¨ë“  ìƒí˜¸ì‘ìš©ì„ í•™ìŠµ
  train_df = train_df  # ì „ì²´

  # ìˆ˜ì •: rating >= 4.0ë§Œ í•™ìŠµ
  train_df_positive = train_df[train_df['label'] == 1]
  2. í‰ê°€ í”„ë¡œí† ì½œ ìˆ˜ì •
  # í˜„ì¬: ëª¨ë“  10,321ê°œ item ì¤‘ ranking
  # ìˆ˜ì •: Leave-One-Out (100ê°œ item ì¤‘ ranking)
  sampled_negatives = random.sample(unseen_items, 99)
  candidates = sampled_negatives + [positive_item]
  3. In-batch Negative Sampling
  # í˜„ì¬: Random negative from all items
  # ìˆ˜ì •: Batch ë‚´ì˜ ë‹¤ë¥¸ positiveë¥¼ negativeë¡œ ì‚¬ìš©

  6.2 ëª¨ë¸ ê°œì„ 

  1. LightGCN
    - Learning rate ì¦ê°€ (1e-3 â†’ 5e-3)
    - Embedding dim ì¦ê°€ (64 â†’ 128)
    - Layer ìˆ˜ ì¤„ì´ê¸° (3 â†’ 2)
  2. NeuMF
    - Early stopping patience ì¤„ì´ê¸° (20 â†’ 10)
    - Dropout ì¦ê°€ (0.2 â†’ 0.3)
    - Learning rate ê°ì†Œ (1e-3 â†’ 5e-4)

  ---
  7. ê²°ë¡ 

  âŒ í˜„ì¬ ìƒíƒœ: ì‹¤íŒ¨

  ë‘ ëª¨ë¸ ëª¨ë‘:
  - Recall@10 â‰ˆ 0.06 (ì˜ˆìƒì˜ 25%)
  - ì˜ë¯¸ ìˆëŠ” ì¶”ì²œì„ í•˜ì§€ ëª»í•¨
  - ê±°ì˜ ëª¨ë“  ê²ƒì„ "O"ë¡œ ì¶”ì²œ (90%)

  ğŸ”§ í•„ìˆ˜ ìˆ˜ì •ì‚¬í•­

  1. í•™ìŠµ ë°ì´í„°: rating â‰¥ 4.0ë§Œ positiveë¡œ ì‚¬ìš©
  2. í‰ê°€ ë°©ì‹: Leave-One-Out ë˜ëŠ” sampled ranking
  3. Hyperparameter: ë” ê³µê²©ì ì¸ íŠœë‹ í•„ìš”
  4. Negative Sampling: Hard negative mining í•„ìˆ˜

  ğŸ“Œ í•µì‹¬ êµí›ˆ

  - ë°ì´í„° ì „ì²˜ë¦¬ê°€ ëª¨ë¸ë³´ë‹¤ ì¤‘ìš”
  - Train-Test ì¼ê´€ì„±ì´ í•µì‹¬
  - í‰ê°€ í”„ë¡œí† ì½œì´ ì„±ëŠ¥ì— í° ì˜í–¥
  - ì‘ì€ ë°ì´í„°ì…‹ì—ì„œëŠ” GNNì´ í•­ìƒ ì¢‹ì€ ê²ƒì€ ì•„ë‹˜

  ì´ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë…¸íŠ¸ë¶ì„ ìˆ˜ì •í•´ì•¼ í• ì§€, ì•„ë‹ˆë©´ í˜„ì¬ ìƒíƒœë¡œ ì œì¶œí• ì§€
  ê²°ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.