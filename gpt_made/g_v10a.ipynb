{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGCN V9a - Hard Negative Mining + Rating Weighted Graph\n",
    "\n",
    "## 핵심 개선사항 (V8 대비)\n",
    "- **Hard Negative Mining**: Random이 아닌 어려운 negative 샘플링\n",
    "- **Rating Weighted Graph**: Rating에 따른 edge weight 차별화\n",
    "- **Hybrid 추천**: Threshold + Top-K (0~K개 추천)\n",
    "- **AUC-ROC 평가**: O/X 구분 능력 측정\n",
    "- Rating은 graph weight에만 사용, 평가는 모든 구매가 positive\n",
    "- GPU 최적화 유지 (MPS/CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# CUDA 우선\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f'Device: {device} ({torch.cuda.get_device_name()})')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(f'Device: {device}')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 전처리 (Rating 무시, Edge 존재만 확인)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total interactions: 105,139\n",
      "Unique users: 668\n",
      "Unique items: 10321\n",
      "\n",
      "Rating distribution:\n",
      "rating\n",
      "0.5     1189\n",
      "1.0     3254\n",
      "1.5     1564\n",
      "2.0     7929\n",
      "2.5     5473\n",
      "3.0    21676\n",
      "3.5    12224\n",
      "4.0    28831\n",
      "4.5     8174\n",
      "5.0    14825\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Users: 668, Items: 10321\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/train.csv')\n",
    "\n",
    "# Rating 정보 포함 (Graph weight용)\n",
    "print(f\"Total interactions: {len(df):,}\")\n",
    "print(f\"Unique users: {df['user'].nunique()}\")\n",
    "print(f\"Unique items: {df['item'].nunique()}\")\n",
    "\n",
    "# Rating 분포 확인\n",
    "print(f\"\\nRating distribution:\")\n",
    "print(df['rating'].value_counts().sort_index())\n",
    "\n",
    "# ID 매핑\n",
    "user2idx = {u: i for i, u in enumerate(sorted(df['user'].unique()))}\n",
    "item2idx = {it: i for i, it in enumerate(sorted(df['item'].unique()))}\n",
    "idx2user = {i: u for u, i in user2idx.items()}\n",
    "idx2item = {i: it for it, i in item2idx.items()}\n",
    "\n",
    "n_users, n_items = len(user2idx), len(item2idx)\n",
    "\n",
    "df['user_idx'] = df['user'].map(user2idx)\n",
    "df['item_idx'] = df['item'].map(item2idx)\n",
    "\n",
    "print(f\"\\nUsers: {n_users}, Items: {n_items}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User K values statistics (MAX_K=100):\n",
      "  Min K: 4\n",
      "  Max K: 100\n",
      "  Mean K: 24.74\n",
      "  Median K: 14.00\n",
      "\n",
      "Cold users (≤10 interactions): 0 (0.0%)\n",
      "Users with K=MAX_K: 41 (6.1%)\n"
     ]
    }
   ],
   "source": [
    "# User별 interaction count 및 K값 계산\n",
    "user_interaction_count = df.groupby('user_idx').size().to_dict()\n",
    "\n",
    "MAX_K = 100  # K 상한선 (너무 많은 추천 방지)\n",
    "\n",
    "def get_k_for_user(count):\n",
    "    \"\"\"User별 추천 개수 K 계산 (상한선 적용)\"\"\"\n",
    "    if count <= 10:\n",
    "        return 2  # Cold user: 무조건 2개\n",
    "    k = max(2, int(count * 0.2))  # 20% of interactions\n",
    "    return min(k, MAX_K)  # 상한선 적용\n",
    "\n",
    "user_k = {u: get_k_for_user(c) for u, c in user_interaction_count.items()}\n",
    "\n",
    "# 통계\n",
    "k_values = list(user_k.values())\n",
    "print(f\"User K values statistics (MAX_K={MAX_K}):\")\n",
    "print(f\"  Min K: {min(k_values)}\")\n",
    "print(f\"  Max K: {max(k_values)}\")\n",
    "print(f\"  Mean K: {np.mean(k_values):.2f}\")\n",
    "print(f\"  Median K: {np.median(k_values):.2f}\")\n",
    "\n",
    "# Cold users (≤10 interactions)\n",
    "cold_users = sum(1 for c in user_interaction_count.values() if c <= 10)\n",
    "print(f\"\\nCold users (≤10 interactions): {cold_users} ({100*cold_users/n_users:.1f}%)\")\n",
    "\n",
    "# Users hitting MAX_K\n",
    "capped_users = sum(1 for u, k in user_k.items() if k == MAX_K)\n",
    "print(f\"Users with K=MAX_K: {capped_users} ({100*capped_users/n_users:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train edges: 73,293\n",
      "Val edges: 15,479\n",
      "Test edges: 16,367\n",
      "\n",
      "Train rating distribution:\n",
      "rating\n",
      "0.5      831\n",
      "1.0     2288\n",
      "1.5     1056\n",
      "2.0     5545\n",
      "2.5     3800\n",
      "3.0    15009\n",
      "3.5     8554\n",
      "4.0    20124\n",
      "4.5     5720\n",
      "5.0    10366\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Train/Val/Test Split (70/15/15)\n",
    "# 각 user의 positive edges를 분할\n",
    "# Rating 정보도 유지 (Graph weight용)\n",
    "\n",
    "train_data, val_data, test_data = [], [], []\n",
    "\n",
    "for user_idx in range(n_users):\n",
    "    user_edges = df[df['user_idx'] == user_idx][['user_idx', 'item_idx', 'rating']]\n",
    "    n_edges = len(user_edges)\n",
    "    \n",
    "    if n_edges >= 3:\n",
    "        user_edges = user_edges.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "        train_end = int(0.7 * n_edges)\n",
    "        val_end = train_end + int(0.15 * n_edges)\n",
    "        \n",
    "        train_end = max(1, train_end)\n",
    "        val_end = max(train_end + 1, val_end)\n",
    "        \n",
    "        train_data.append(user_edges.iloc[:train_end])\n",
    "        val_data.append(user_edges.iloc[train_end:val_end])\n",
    "        test_data.append(user_edges.iloc[val_end:])\n",
    "    elif n_edges == 2:\n",
    "        user_edges = user_edges.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "        train_data.append(user_edges.iloc[:1])\n",
    "        val_data.append(user_edges.iloc[1:])\n",
    "    elif n_edges == 1:\n",
    "        train_data.append(user_edges)\n",
    "\n",
    "train_df = pd.concat(train_data, ignore_index=True)\n",
    "val_df = pd.concat(val_data, ignore_index=True)\n",
    "test_df = pd.concat(test_data, ignore_index=True)\n",
    "\n",
    "print(f\"Train edges: {len(train_df):,}\")\n",
    "print(f\"Val edges: {len(val_df):,}\")\n",
    "print(f\"Test edges: {len(test_df):,}\")\n",
    "\n",
    "# Train rating 분포\n",
    "print(f\"\\nTrain rating distribution:\")\n",
    "print(train_df['rating'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train tensors ready: 73,293 edges\n"
     ]
    }
   ],
   "source": [
    "# Pre-computed tensors\n",
    "train_users = torch.LongTensor(train_df['user_idx'].values)\n",
    "train_items = torch.LongTensor(train_df['item_idx'].values)\n",
    "\n",
    "# User가 train에서 선택한 items (추천에서 제외용)\n",
    "user_train_items = defaultdict(set)\n",
    "for u, i in zip(train_df['user_idx'].values, train_df['item_idx'].values):\n",
    "    user_train_items[int(u)].add(int(i))\n",
    "\n",
    "print(f\"Train tensors ready: {len(train_users):,} edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating Weighted Graph: 146,586 edges\n",
      "\n",
      "Rating weight statistics:\n",
      "  Min: 0.0009\n",
      "  Max: 0.2711\n",
      "  Mean: 0.0168\n"
     ]
    }
   ],
   "source": [
    "# Rating Weighted Graph 구축 (Train edges only)\n",
    "def build_rating_weighted_graph():\n",
    "    \"\"\"\n",
    "    Rating에 따른 edge weight 차별화\n",
    "    높은 rating = 더 강한 신호 = 더 큰 weight\n",
    "    \"\"\"\n",
    "    users = train_df['user_idx'].values\n",
    "    items = train_df['item_idx'].values\n",
    "    ratings = train_df['rating'].values\n",
    "    \n",
    "    # Rating factor: rating 1→0.55, 2→0.7, 3→0.85, 4→1.0, 5→1.15\n",
    "    # 공식: 0.4 + 0.15 * rating\n",
    "    rating_factors = 0.4 + 0.15 * ratings\n",
    "    \n",
    "    edge_u2i = np.array([users, items + n_users])\n",
    "    edge_i2u = np.array([items + n_users, users])\n",
    "    edge_index = torch.LongTensor(np.concatenate([edge_u2i, edge_i2u], axis=1))\n",
    "    \n",
    "    # Rating factors도 양방향으로 복제\n",
    "    rating_factors_both = np.concatenate([rating_factors, rating_factors])\n",
    "    \n",
    "    num_nodes = n_users + n_items\n",
    "    deg = torch.zeros(num_nodes).scatter_add(0, edge_index[0], torch.ones(edge_index.shape[1]))\n",
    "    deg_inv_sqrt = deg.pow(-0.5)\n",
    "    deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "    \n",
    "    # 기존 degree normalization * rating factor\n",
    "    base_weight = deg_inv_sqrt[edge_index[0]] * deg_inv_sqrt[edge_index[1]]\n",
    "    rating_weight = torch.FloatTensor(rating_factors_both)\n",
    "    edge_weight = base_weight * rating_weight\n",
    "    \n",
    "    return edge_index.to(device), edge_weight.to(device)\n",
    "\n",
    "edge_index, edge_weight = build_rating_weighted_graph()\n",
    "print(f\"Rating Weighted Graph: {edge_index.shape[1]:,} edges\")\n",
    "\n",
    "# Rating weight 통계\n",
    "print(f\"\\nRating weight statistics:\")\n",
    "print(f\"  Min: {edge_weight.min().item():.4f}\")\n",
    "print(f\"  Max: {edge_weight.max().item():.4f}\")\n",
    "print(f\"  Mean: {edge_weight.mean().item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LightGCN 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGCN(nn.Module):\n",
    "    def __init__(self, n_users, n_items, emb_dim=64, n_layers=2):\n",
    "        super().__init__()\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.emb_dim = emb_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.user_emb = nn.Embedding(n_users, emb_dim)\n",
    "        self.item_emb = nn.Embedding(n_items, emb_dim)\n",
    "        nn.init.xavier_uniform_(self.user_emb.weight)\n",
    "        nn.init.xavier_uniform_(self.item_emb.weight)\n",
    "    \n",
    "    def forward(self, edge_index, edge_weight):\n",
    "        all_emb = torch.cat([self.user_emb.weight, self.item_emb.weight], dim=0)\n",
    "        embs = [all_emb]\n",
    "        \n",
    "        for _ in range(self.n_layers):\n",
    "            row, col = edge_index\n",
    "            messages = all_emb[col] * edge_weight.unsqueeze(1)\n",
    "            all_emb = torch.zeros_like(all_emb).scatter_add(0, row.unsqueeze(1).expand(-1, self.emb_dim), messages)\n",
    "            embs.append(all_emb)\n",
    "        \n",
    "        final_emb = torch.mean(torch.stack(embs), dim=0)\n",
    "        return final_emb[:self.n_users], final_emb[self.n_users:]\n",
    "\n",
    "def bpr_loss(pos_scores, neg_scores):\n",
    "    diff = pos_scores.unsqueeze(1) - neg_scores\n",
    "    return -torch.log(torch.sigmoid(diff) + 1e-8).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Sampling: Hard Negative Mining\n",
      "  Hard/Random ratio: 50% / 50%\n"
     ]
    }
   ],
   "source": [
    "def fast_sample_negatives(pos_users, num_neg=4):\n",
    "    \"\"\"Random negatives per user, excluding items the user already interacted with.\"\"\"\n",
    "    neg_items = []\n",
    "    for u in pos_users:\n",
    "        u_int = int(u.item()) if hasattr(u, 'item') else int(u)\n",
    "        seen = user_train_items[u_int]\n",
    "        samples = []\n",
    "        while len(samples) < num_neg:\n",
    "            candidate = np.random.randint(0, n_items)\n",
    "            if candidate not in seen:\n",
    "                samples.append(candidate)\n",
    "        neg_items.append(samples)\n",
    "    return torch.LongTensor(neg_items)\n",
    "\n",
    "@torch.no_grad()\n",
    "def hard_negative_sampling(user_emb, item_emb, pos_users, num_neg=4, num_candidates=50):\n",
    "    \"\"\"Hard negatives per user, excluding seen items.\"\"\"\n",
    "    batch_size = len(pos_users)\n",
    "    candidates = torch.randint(0, n_items, (batch_size, num_candidates), device=device)\n",
    "\n",
    "    # Re-sample candidates that are already in the user's train items\n",
    "    for idx, u in enumerate(pos_users):\n",
    "        u_int = int(u.item()) if hasattr(u, 'item') else int(u)\n",
    "        seen = user_train_items[u_int]\n",
    "        if seen:\n",
    "            seen_tensor = torch.tensor(list(seen), device=device)\n",
    "            bad_mask = (candidates[idx].unsqueeze(1) == seen_tensor).any(dim=1)\n",
    "            if bad_mask.any():\n",
    "                resample = torch.randint(0, n_items, (bad_mask.sum().item(),), device=device)\n",
    "                candidates[idx][bad_mask] = resample\n",
    "\n",
    "    user_expanded = user_emb[pos_users].unsqueeze(1)  # (B,1,D)\n",
    "    item_candidates = item_emb[candidates]            # (B,num_candidates,D)\n",
    "    scores = (user_expanded * item_candidates).sum(dim=2)\n",
    "\n",
    "    # Mask seen items to avoid selecting them\n",
    "    for idx, u in enumerate(pos_users):\n",
    "        u_int = int(u.item()) if hasattr(u, 'item') else int(u)\n",
    "        seen = user_train_items[u_int]\n",
    "        if seen:\n",
    "            seen_tensor = torch.tensor(list(seen), device=device)\n",
    "            bad_mask = (candidates[idx].unsqueeze(1) == seen_tensor).any(dim=1)\n",
    "            if bad_mask.any():\n",
    "                scores[idx][bad_mask] = -1e9\n",
    "\n",
    "    _, top_indices = scores.topk(num_neg, dim=1)\n",
    "    hard_negs = candidates.gather(1, top_indices)\n",
    "    return hard_negs\n",
    "\n",
    "# Negative sampling switches\n",
    "USE_HARD_NEGATIVE = True\n",
    "HARD_NEG_RATIO = 0.5  # 50% hard / 50% random\n",
    "print(f\"Negative Sampling: {'Hard Negative Mining' if USE_HARD_NEGATIVE else 'Random'}\")\n",
    "if USE_HARD_NEGATIVE:\n",
    "    print(f\"  Hard/Random ratio: {HARD_NEG_RATIO:.0%} / {1-HARD_NEG_RATIO:.0%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_user_wise_topk(model, eval_df, sample_users=100):\n",
    "    \"\"\"\n",
    "    User-wise Top-K 평가\n",
    "    각 user별로 K개의 추천을 하고, 실제 positive가 포함되었는지 확인\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    u_emb, i_emb = model(edge_index, edge_weight)\n",
    "    \n",
    "    # Sample users for evaluation\n",
    "    eval_users = eval_df['user_idx'].unique()\n",
    "    if len(eval_users) > sample_users:\n",
    "        eval_users = np.random.choice(eval_users, sample_users, replace=False)\n",
    "    \n",
    "    precisions, recalls, hits = [], [], []\n",
    "    \n",
    "    for user_idx in eval_users:\n",
    "        # User의 실제 positive items (val/test)\n",
    "        actual_items = set(eval_df[eval_df['user_idx'] == user_idx]['item_idx'].values)\n",
    "        if len(actual_items) == 0:\n",
    "            continue\n",
    "        \n",
    "        # User가 train에서 이미 선택한 items (제외)\n",
    "        train_items_set = user_train_items[int(user_idx)]\n",
    "        \n",
    "        # 후보: train에서 선택하지 않은 모든 items\n",
    "        candidate_items = [i for i in range(n_items) if i not in train_items_set]\n",
    "        if len(candidate_items) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Score all candidates\n",
    "        candidate_tensor = torch.LongTensor(candidate_items).to(device)\n",
    "        user_tensor = torch.full((len(candidate_items),), user_idx, dtype=torch.long, device=device)\n",
    "        scores = (u_emb[user_tensor] * i_emb[candidate_tensor]).sum(dim=1)\n",
    "        \n",
    "        # Top-K selection\n",
    "        K = user_k[int(user_idx)]\n",
    "        K = min(K, len(candidate_items))  # K가 후보보다 클 수 없음\n",
    "        \n",
    "        _, top_k_indices = torch.topk(scores, K)\n",
    "        top_k_items = set([candidate_items[idx.item()] for idx in top_k_indices])\n",
    "        \n",
    "        # Metrics\n",
    "        hits_count = len(top_k_items & actual_items)\n",
    "        precision = hits_count / K if K > 0 else 0\n",
    "        recall = hits_count / len(actual_items) if len(actual_items) > 0 else 0\n",
    "        hit = 1.0 if hits_count > 0 else 0.0\n",
    "        \n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        hits.append(hit)\n",
    "    \n",
    "    return np.mean(precisions), np.mean(recalls), np.mean(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training config:\n",
      "  emb_dim: 32\n",
      "  n_layers: 2\n",
      "  lr: 0.005\n",
      "  weight_decay: 1e-05\n",
      "  epochs: 50\n"
     ]
    }
   ],
   "source": [
    "# 학습 설정\n",
    "EMB_DIM = 32\n",
    "N_LAYERS = 2\n",
    "LR = 5e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 1024\n",
    "NUM_NEG = 4\n",
    "\n",
    "print(f\"Training config:\")\n",
    "print(f\"  emb_dim: {EMB_DIM}\")\n",
    "print(f\"  n_layers: {N_LAYERS}\")\n",
    "print(f\"  lr: {LR}\")\n",
    "print(f\"  weight_decay: {WEIGHT_DECAY}\")\n",
    "print(f\"  epochs: {EPOCHS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Hard Negative Mining + Rating Weighted Graph...\n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Hard negatives (현재 embedding 기반)\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_hard > \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     hard_negs = \u001b[43mhard_negative_sampling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_u\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_neg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_hard\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     40\u001b[39m     hard_negs = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/학교/2025-2/그래프신경망과빅데이터/gnn-recsys/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mhard_negative_sampling\u001b[39m\u001b[34m(user_emb, item_emb, pos_users, num_neg, num_candidates)\u001b[39m\n\u001b[32m     27\u001b[39m         bad_mask = (candidates[idx].unsqueeze(\u001b[32m1\u001b[39m) == seen_tensor).any(dim=\u001b[32m1\u001b[39m)\n\u001b[32m     28\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m bad_mask.any():\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m             resample = torch.randint(\u001b[32m0\u001b[39m, n_items, (\u001b[43mbad_mask\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.item(),), device=device)\n\u001b[32m     30\u001b[39m             candidates[idx][bad_mask] = resample\n\u001b[32m     32\u001b[39m user_expanded = user_emb[pos_users].unsqueeze(\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# (B,1,D)\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model = LightGCN(n_users, n_items, EMB_DIM, N_LAYERS).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "history = {'loss': [], 'precision': [], 'recall': [], 'hit': []}\n",
    "best_recall = 0\n",
    "n_train = len(train_users)\n",
    "\n",
    "# Pre-move to GPU\n",
    "train_u_gpu = train_users.to(device)\n",
    "train_i_gpu = train_items.to(device)\n",
    "\n",
    "print(f\"Training with Hard Negative Mining + Rating Weighted Graph...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    perm = torch.randperm(n_train, device=device)\n",
    "    epoch_loss = 0\n",
    "    n_batches = 0\n",
    "    \n",
    "    for i in range(0, n_train, BATCH_SIZE):\n",
    "        batch_idx = perm[i:i+BATCH_SIZE]\n",
    "        pos_u = train_u_gpu[batch_idx]\n",
    "        pos_i = train_i_gpu[batch_idx]\n",
    "        \n",
    "        # Forward pass (embedding 계산)\n",
    "        u_emb, i_emb = model(edge_index, edge_weight)\n",
    "        \n",
    "        # Hard Negative Mining + Random (혼합)\n",
    "        if USE_HARD_NEGATIVE:\n",
    "            n_hard = int(NUM_NEG * HARD_NEG_RATIO)\n",
    "            n_random = NUM_NEG - n_hard\n",
    "            \n",
    "            # Hard negatives (현재 embedding 기반)\n",
    "            if n_hard > 0:\n",
    "                hard_negs = hard_negative_sampling(u_emb, i_emb, pos_u, num_neg=n_hard)\n",
    "            else:\n",
    "                hard_negs = None\n",
    "            \n",
    "            # Random negatives\n",
    "            if n_random > 0:\n",
    "                random_negs = fast_sample_negatives(pos_u, n_random).to(device)\n",
    "            else:\n",
    "                random_negs = None\n",
    "            \n",
    "            # Combine\n",
    "            if hard_negs is not None and random_negs is not None:\n",
    "                neg_i = torch.cat([hard_negs, random_negs], dim=1)\n",
    "            elif hard_negs is not None:\n",
    "                neg_i = hard_negs\n",
    "            else:\n",
    "                neg_i = random_negs\n",
    "        else:\n",
    "            neg_i = fast_sample_negatives(pos_u, NUM_NEG).to(device)\n",
    "        \n",
    "        # Score 계산\n",
    "        pos_scores = (u_emb[pos_u] * i_emb[pos_i]).sum(dim=1)\n",
    "        neg_scores = (u_emb[pos_u].unsqueeze(1) * i_emb[neg_i]).sum(dim=2)\n",
    "        \n",
    "        loss = bpr_loss(pos_scores, neg_scores)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        n_batches += 1\n",
    "    \n",
    "    history['loss'].append(epoch_loss / n_batches)\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        prec, rec, hit = evaluate_user_wise_topk(model, val_df, sample_users=200)\n",
    "        history['precision'].append(prec)\n",
    "        history['recall'].append(rec)\n",
    "        history['hit'].append(hit)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1:3d} | Loss: {epoch_loss/n_batches:.4f} | \"\n",
    "              f\"Prec@K: {prec:.4f} | Recall@K: {rec:.4f} | Hit@K: {hit:.4f}\")\n",
    "        \n",
    "        if rec > best_recall:\n",
    "            best_recall = rec\n",
    "            torch.save(model.state_dict(), 'best_lightgcn_gv10a.pt')\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\nTraining time: {elapsed/60:.1f} minutes\")\n",
    "print(f\"Best Recall@K: {best_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "axes[0, 0].plot(history['loss'], 'b-', linewidth=2)\n",
    "axes[0, 0].set_title('Training Loss')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "epochs_val = np.arange(5, EPOCHS+1, 5)[:len(history['precision'])]\n",
    "axes[0, 1].plot(epochs_val, history['precision'], 'g-o', linewidth=2)\n",
    "axes[0, 1].set_title('Precision@K')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "axes[1, 0].plot(epochs_val, history['recall'], 'r-o', linewidth=2)\n",
    "axes[1, 0].set_title('Recall@K')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "axes[1, 1].plot(epochs_val, history['hit'], 'm-o', linewidth=2)\n",
    "axes[1, 1].set_title('Hit@K')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Set 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load('best_lightgcn_v9a.pt'))\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    u_emb, i_emb = model(edge_index, edge_weight)\n",
    "\n",
    "# Test set 전체 평가 (기존 Top-K only) - 참고용\n",
    "test_prec, test_rec, test_hit = evaluate_user_wise_topk(model, test_df, sample_users=500)\n",
    "\n",
    "print(\"Test Set Performance (User-wise Top-K only) - For reference:\")\n",
    "print(f\"  Precision@K: {test_prec:.4f}\")\n",
    "print(f\"  Recall@K: {test_rec:.4f}\")\n",
    "print(f\"  Hit@K: {test_hit:.4f}\")\n",
    "print(\"  → 무조건 K개 추천했을 때의 성능\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC-ROC 평가 + Threshold 튜닝\n",
    "print(\"Step 1: Calculating AUC-ROC...\")\n",
    "\n",
    "# Positive samples: val edges\n",
    "val_u_gpu = torch.LongTensor(val_df['user_idx'].values).to(device)\n",
    "val_i_gpu = torch.LongTensor(val_df['item_idx'].values).to(device)\n",
    "val_pos_scores = (u_emb[val_u_gpu] * i_emb[val_i_gpu]).sum(dim=1).cpu().numpy()\n",
    "\n",
    "# Negative samples: random (user, item) pairs not in train/val/test\n",
    "print(\"Generating negative samples (excluding train/val/test edges)...\")\n",
    "val_test_edges = set()\n",
    "for u, i in zip(val_df['user_idx'].values, val_df['item_idx'].values):\n",
    "    val_test_edges.add((int(u), int(i)))\n",
    "for u, i in zip(test_df['user_idx'].values, test_df['item_idx'].values):\n",
    "    val_test_edges.add((int(u), int(i)))\n",
    "\n",
    "n_neg_samples = len(val_df)\n",
    "neg_users, neg_items = [], []\n",
    "sample_count = 0\n",
    "while sample_count < n_neg_samples:\n",
    "    user_idx = np.random.randint(0, n_users)\n",
    "    item_idx = np.random.randint(0, n_items)\n",
    "    # Exclude train, val, test edges\n",
    "    if item_idx not in user_train_items[user_idx] and (user_idx, item_idx) not in val_test_edges:\n",
    "        neg_users.append(user_idx)\n",
    "        neg_items.append(item_idx)\n",
    "        sample_count += 1\n",
    "\n",
    "neg_u_gpu = torch.LongTensor(neg_users).to(device)\n",
    "neg_i_gpu = torch.LongTensor(neg_items).to(device)\n",
    "val_neg_scores = (u_emb[neg_u_gpu] * i_emb[neg_i_gpu]).sum(dim=1).cpu().numpy()\n",
    "\n",
    "# AUC-ROC\n",
    "all_scores = np.concatenate([val_pos_scores, val_neg_scores])\n",
    "all_labels = np.concatenate([np.ones(len(val_pos_scores)), np.zeros(len(val_neg_scores))])\n",
    "\n",
    "val_auc_roc = roc_auc_score(all_labels, all_scores)\n",
    "print(f\"\\nValidation AUC-ROC: {val_auc_roc:.4f}\")\n",
    "print(f\"  → 1.0 = 완벽한 구분, 0.5 = 랜덤\")\n",
    "print(f\"  → 모델이 O/X를 얼마나 잘 구분하는지 측정\")\n",
    "\n",
    "# Score 분포 확인\n",
    "print(f\"\\nScore distributions:\")\n",
    "print(f\"  Positive (val) scores: mean={val_pos_scores.mean():.4f}, std={val_pos_scores.std():.4f}\")\n",
    "print(f\"  Negative scores: mean={val_neg_scores.mean():.4f}, std={val_neg_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Threshold 튜닝 (F1 최대화)\n",
    "print(\"Step 2: Finding optimal threshold for F1 maximization...\")\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# 다양한 threshold 시도\n",
    "thresholds = np.linspace(all_scores.min(), all_scores.max(), 100)\n",
    "best_f1, best_th = 0, 0\n",
    "best_prec, best_rec = 0, 0\n",
    "\n",
    "results_list = []\n",
    "for th in thresholds:\n",
    "    preds = (all_scores > th).astype(int)\n",
    "    prec = precision_score(all_labels, preds, zero_division=0)\n",
    "    rec = recall_score(all_labels, preds, zero_division=0)\n",
    "    f1 = f1_score(all_labels, preds, zero_division=0)\n",
    "    o_ratio = preds.mean()\n",
    "    \n",
    "    results_list.append({\n",
    "        'threshold': th,\n",
    "        'precision': prec,\n",
    "        'recall': rec,\n",
    "        'f1': f1,\n",
    "        'o_ratio': o_ratio\n",
    "    })\n",
    "    \n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_th = th\n",
    "        best_prec = prec\n",
    "        best_rec = rec\n",
    "\n",
    "print(f\"\\nOptimal Threshold (F1 Maximization):\")\n",
    "print(f\"  Threshold: {best_th:.4f}\")\n",
    "print(f\"  Precision: {best_prec:.4f}\")\n",
    "print(f\"  Recall: {best_rec:.4f}\")\n",
    "print(f\"  F1 Score: {best_f1:.4f}\")\n",
    "\n",
    "# O ratio at best threshold\n",
    "preds_at_best = (all_scores > best_th).astype(int)\n",
    "o_ratio_best = preds_at_best.mean()\n",
    "print(f\"  O ratio: {o_ratio_best*100:.1f}%\")\n",
    "\n",
    "# 시각화\n",
    "results_df = pd.DataFrame(results_list)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(results_df['threshold'], results_df['precision'], 'b-', label='Precision', linewidth=2)\n",
    "axes[0].plot(results_df['threshold'], results_df['recall'], 'r-', label='Recall', linewidth=2)\n",
    "axes[0].plot(results_df['threshold'], results_df['f1'], 'g-', label='F1', linewidth=3)\n",
    "axes[0].axvline(x=best_th, color='k', linestyle='--', label=f'Best θ={best_th:.4f}')\n",
    "axes[0].set_xlabel('Threshold')\n",
    "axes[0].set_ylabel('Score')\n",
    "axes[0].set_title('Threshold vs Metrics')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "axes[1].plot(results_df['threshold'], results_df['o_ratio'], 'm-', linewidth=2)\n",
    "axes[1].axvline(x=best_th, color='k', linestyle='--')\n",
    "axes[1].set_xlabel('Threshold')\n",
    "axes[1].set_ylabel('O Ratio')\n",
    "axes[1].set_title('Threshold vs O Ratio')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save threshold\n",
    "OPTIMAL_THRESHOLD = best_th\n",
    "print(f\"\\nThreshold saved: OPTIMAL_THRESHOLD = {OPTIMAL_THRESHOLD:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_hybrid(test_input_df, threshold):\n",
    "    \"\"\"\n",
    "    Hybrid 추천: Threshold + Top-K 제약\n",
    "    1. Score > threshold인 item만 후보로 선택\n",
    "    2. 후보 중 Top-K만 O (0~K개 추천)\n",
    "\n",
    "    이렇게 하면:\n",
    "    - Threshold를 넘지 못하면 추천 안함 (O 남발 방지)\n",
    "    - 동시에 K개 이하로 제한 (과다 추천 방지)\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        u_emb, i_emb = model(edge_index, edge_weight)\n",
    "\n",
    "    results = []\n",
    "    stats = {'total_o': 0, 'total_items': 0, 'users_with_o': 0}\n",
    "\n",
    "    # User별로 처리\n",
    "    for user in test_input_df['user'].unique():\n",
    "        if user not in user2idx:\n",
    "            # Unknown user: 모두 X\n",
    "            user_rows = test_input_df[test_input_df['user'] == user]\n",
    "            for _, row in user_rows.iterrows():\n",
    "                results.append({'user': row['user'], 'item': row['item'], 'recommend': 'X'})\n",
    "                stats['total_items'] += 1\n",
    "            continue\n",
    "\n",
    "        user_idx = user2idx[user]\n",
    "        user_rows = test_input_df[test_input_df['user'] == user]\n",
    "\n",
    "        # User가 이미 선택한 items\n",
    "        train_items_set = user_train_items[user_idx]\n",
    "\n",
    "        # Test에서 주어진 items scoring\n",
    "        items_to_score = []\n",
    "        item_info = []  # (original_item, item_idx)\n",
    "\n",
    "        for _, row in user_rows.iterrows():\n",
    "            item = row['item']\n",
    "            if item not in item2idx:\n",
    "                # Unknown item: X\n",
    "                results.append({'user': user, 'item': item, 'recommend': 'X'})\n",
    "                stats['total_items'] += 1\n",
    "            elif item2idx[item] in train_items_set:\n",
    "                # 이미 선택한 item: X (추천 불가)\n",
    "                results.append({'user': user, 'item': item, 'recommend': 'X'})\n",
    "                stats['total_items'] += 1\n",
    "            else:\n",
    "                items_to_score.append(item2idx[item])\n",
    "                item_info.append(item)\n",
    "\n",
    "        if len(items_to_score) == 0:\n",
    "            continue\n",
    "\n",
    "        # Score items\n",
    "        item_tensor = torch.LongTensor(items_to_score).to(device)\n",
    "        user_tensor = torch.full((len(items_to_score),), user_idx, dtype=torch.long, device=device)\n",
    "        scores = (u_emb[user_tensor] * i_emb[item_tensor]).sum(dim=1).cpu().numpy()\n",
    "\n",
    "        # Hybrid selection:\n",
    "        # Step 1: Filter by threshold\n",
    "        above_threshold_mask = scores > threshold\n",
    "        above_threshold_indices = np.where(above_threshold_mask)[0]\n",
    "\n",
    "        # Step 2: Top-K selection among threshold-passing items\n",
    "        K = user_k[user_idx]\n",
    "\n",
    "        if len(above_threshold_indices) > K:\n",
    "            # Threshold 넘는게 K개 초과 → Top-K만 선택\n",
    "            above_scores = scores[above_threshold_indices]\n",
    "            top_k_in_above = np.argsort(above_scores)[-K:]\n",
    "            selected_indices = set(above_threshold_indices[top_k_in_above])\n",
    "        else:\n",
    "            # Threshold 넘는게 K개 이하 → 모두 선택\n",
    "            selected_indices = set(above_threshold_indices)\n",
    "\n",
    "        # Mark O/X\n",
    "        user_o_count = 0\n",
    "        for i, item in enumerate(item_info):\n",
    "            if i in selected_indices:\n",
    "                recommend = 'O'\n",
    "                user_o_count += 1\n",
    "            else:\n",
    "                recommend = 'X'\n",
    "            results.append({'user': user, 'item': item, 'recommend': recommend})\n",
    "            stats['total_items'] += 1\n",
    "\n",
    "        stats['total_o'] += user_o_count\n",
    "        if user_o_count > 0:\n",
    "            stats['users_with_o'] += 1\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # 통계 출력\n",
    "    o_ratio = stats['total_o'] / stats['total_items'] if stats['total_items'] > 0 else 0\n",
    "    print(f\"\\nHybrid Prediction Stats:\")\n",
    "    print(f\"  Total items: {stats['total_items']}\")\n",
    "    print(f\"  Total O: {stats['total_o']}\")\n",
    "    print(f\"  O ratio: {o_ratio*100:.2f}%\")\n",
    "    print(f\"  Users with ≥1 O: {stats['users_with_o']}\")\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample test with Hybrid prediction\n",
    "sample_test = pd.read_csv('../data/sample1.csv')\n",
    "\n",
    "print(\"Sample Test with Hybrid Prediction:\")\n",
    "print(f\"Threshold: {OPTIMAL_THRESHOLD:.4f}\")\n",
    "\n",
    "predictions = predict_hybrid(sample_test, OPTIMAL_THRESHOLD)\n",
    "\n",
    "print(\"\\n====================\")\n",
    "print(\"user   item   recommend\")\n",
    "for _, row in predictions.iterrows():\n",
    "    print(f\"{int(row['user']):<6}{int(row['item']):<7}{row['recommend']}\")\n",
    "print(\"====================\")\n",
    "\n",
    "counts = predictions['recommend'].value_counts()\n",
    "total = len(predictions)\n",
    "print(f\"Total Recommends: {counts.get('O', 0)}/{total}\")\n",
    "print(f\"Not Recommend: {counts.get('X', 0)}/{total}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set에서 AUC-ROC 계산\n",
    "print(\"Calculating Test Set AUC-ROC...\")\n",
    "\n",
    "# Test positive samples\n",
    "test_u_gpu = torch.LongTensor(test_df['user_idx'].values).to(device)\n",
    "test_i_gpu = torch.LongTensor(test_df['item_idx'].values).to(device)\n",
    "test_pos_scores = (u_emb[test_u_gpu] * i_emb[test_i_gpu]).sum(dim=1).cpu().numpy()\n",
    "\n",
    "# Test negative samples (random pairs not in train/val/test)\n",
    "n_test_neg = len(test_df)\n",
    "test_neg_scores = []\n",
    "for _ in range(n_test_neg):\n",
    "    user_idx = np.random.randint(0, n_users)\n",
    "    item_idx = np.random.randint(0, n_items)\n",
    "    # Exclude train, val, test\n",
    "    while (item_idx in user_train_items[user_idx] or \n",
    "           (user_idx, item_idx) in val_test_edges):\n",
    "        item_idx = np.random.randint(0, n_items)\n",
    "    score = (u_emb[user_idx] * i_emb[item_idx]).sum().item()\n",
    "    test_neg_scores.append(score)\n",
    "\n",
    "test_neg_scores = np.array(test_neg_scores)\n",
    "\n",
    "# Calculate Test AUC-ROC\n",
    "test_all_scores = np.concatenate([test_pos_scores, test_neg_scores])\n",
    "test_all_labels = np.concatenate([np.ones(len(test_pos_scores)), np.zeros(len(test_neg_scores))])\n",
    "\n",
    "test_auc_roc = roc_auc_score(test_all_labels, test_all_scores)\n",
    "\n",
    "print(f\"\\nTest Set AUC-ROC: {test_auc_roc:.4f}\")\n",
    "print(f\"Validation AUC-ROC: {val_auc_roc:.4f}\")\n",
    "\n",
    "# Test Accuracy, Precision, Recall, F1 with optimal threshold\n",
    "test_preds = (test_all_scores > OPTIMAL_THRESHOLD).astype(int)\n",
    "test_acc = (test_preds == test_all_labels).mean()\n",
    "test_prec_th = precision_score(test_all_labels, test_preds, zero_division=0)\n",
    "test_rec_th = recall_score(test_all_labels, test_preds, zero_division=0)\n",
    "test_f1 = f1_score(test_all_labels, test_preds, zero_division=0)\n",
    "test_o_ratio = test_preds.mean()\n",
    "\n",
    "print(f\"\\nTest Set with Threshold={OPTIMAL_THRESHOLD:.4f}:\")\n",
    "print(f\"  Accuracy: {test_acc:.4f}\")\n",
    "print(f\"  Precision: {test_prec_th:.4f}\")\n",
    "print(f\"  Recall: {test_rec_th:.4f}\")\n",
    "print(f\"  F1 Score: {test_f1:.4f}\")\n",
    "print(f\"  O Ratio: {test_o_ratio*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"LightGCN V10a - Hard Negative Mining + Rating Weighted Graph\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nModel Config:\")\n",
    "print(f\"  emb_dim: {EMB_DIM}\")\n",
    "print(f\"  n_layers: {N_LAYERS}\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "print(f\"\\nNew Features (V8 대비):\")\n",
    "print(f\"  • Hard Negative Mining: {USE_HARD_NEGATIVE}\")\n",
    "if USE_HARD_NEGATIVE:\n",
    "    print(f\"    - Hard/Random ratio: {HARD_NEG_RATIO:.0%} / {1-HARD_NEG_RATIO:.0%}\")\n",
    "print(f\"  • Rating Weighted Graph: Yes\")\n",
    "print(f\"    - Rating factor: 0.4 + 0.15 * rating\")\n",
    "\n",
    "print(f\"\\nData:\")\n",
    "print(f\"  Total edges: {len(df):,}\")\n",
    "print(f\"  Train: {len(train_df):,}\")\n",
    "print(f\"  Val: {len(val_df):,}\")\n",
    "print(f\"  Test: {len(test_df):,}\")\n",
    "\n",
    "print(f\"\\nUser K statistics (MAX_K={MAX_K}):\")\n",
    "print(f\"  Min K: {min(k_values)}\")\n",
    "print(f\"  Max K: {max(k_values)}\")\n",
    "print(f\"  Mean K: {np.mean(k_values):.2f}\")\n",
    "\n",
    "print(f\"\\nOptimal Threshold (F1 Maximization):\")\n",
    "print(f\"  Threshold: {OPTIMAL_THRESHOLD:.4f}\")\n",
    "\n",
    "print(f\"\\nTest Performance:\")\n",
    "print(f\"  AUC-ROC: {test_auc_roc:.4f}\")\n",
    "print(f\"  Accuracy: {test_acc:.4f}\")\n",
    "print(f\"  Precision: {test_prec_th:.4f}\")\n",
    "print(f\"  Recall: {test_rec_th:.4f}\")\n",
    "print(f\"  F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "print(f\"\\nComparison with V8:\")\n",
    "print(f\"  V8  AUC-ROC: 0.8795 | F1: 0.8342\")\n",
    "print(f\"  V9a AUC-ROC: {test_auc_roc:.4f} | F1: {test_f1:.4f}\")\n",
    "v8_auc = 0.8795\n",
    "v8_f1 = 0.8342\n",
    "print(f\"  Delta: AUC +{(test_auc_roc - v8_auc)*100:.2f}% | F1 +{(test_f1 - v8_f1)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final test inference (uncomment when ready)\n",
    "# final_test = pd.read_csv('../data/test.csv')\n",
    "# print(f\"Using threshold: {OPTIMAL_THRESHOLD:.4f}\")\n",
    "# final_predictions = predict_hybrid(final_test, OPTIMAL_THRESHOLD)\n",
    "# final_predictions.to_csv('predictions_v9a.csv', index=False)\n",
    "# print(f\"\\nPredictions saved to predictions_v9a.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
