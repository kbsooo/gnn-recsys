{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b4f1eab",
   "metadata": {},
   "source": [
    "# B버전 (rating 활용: 이진 + 회귀 실험)\n",
    "- label1: rating >= 4 → 1, else 0 (이진 분류)\n",
    "- label2: 회귀로 rating 예측 후 threshold=4로 추천\n",
    "- 네거티브: 평점<4만 음성으로 사용, 미관측 음성 미사용\n",
    "- 스플릿: 유저별 8/1/1 랜덤\n",
    "- 평가지표: AUC/F1/PR@thres (이진), RMSE/MAE + 분류메트릭(회귀→임계) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ce927a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    "# 환경 준비\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append('..')  # 상위 디렉토리 import 허용\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "from common import (\n",
    "    load_interactions,\n",
    "    encode_ids,\n",
    "    split_userwise,\n",
    "    make_binary_label,\n",
    ")\n",
    "\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364affaf",
   "metadata": {},
   "source": [
    "## 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07588a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('../data/train.csv')\n",
    "MODEL_DIR = Path('../codex_models')\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SEED = 42\n",
    "TRAIN_RATIO = 0.8\n",
    "VAL_RATIO = 0.1\n",
    "THRESHOLDS = [4.0]  # 분류 임계값 후보\n",
    "\n",
    "EMBED_DIM = 64\n",
    "N_LAYERS = 2\n",
    "LR = 1e-3\n",
    "BATCH_SIZE = 1024\n",
    "EPOCHS = 5  # 필요 시 조정\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "rng = np.random.default_rng(SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179ebb71",
   "metadata": {},
   "source": [
    "## 데이터 로드/인덱싱/라벨링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b438b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user  item  rating\n",
      "0     1    16     4.0\n",
      "1     1    24     1.5\n",
      "2     1    32     4.0\n",
      "3     1    47     4.0\n",
      "4     1    50     4.0\n",
      "users=668, items=10321, interactions=105139\n",
      "83855 10226 11058\n"
     ]
    }
   ],
   "source": [
    "df_raw = load_interactions(DATA_PATH)\n",
    "print(df_raw.head())\n",
    "\n",
    "df_bin = make_binary_label(df_raw, threshold=4.0)\n",
    "\n",
    "df, user2idx, item2idx = encode_ids(df_bin)\n",
    "print(f\"users={len(user2idx)}, items={len(item2idx)}, interactions={len(df)}\")\n",
    "\n",
    "train_df, val_df, test_df = split_userwise(df, train_ratio=TRAIN_RATIO, val_ratio=VAL_RATIO, seed=SEED)\n",
    "print(len(train_df), len(val_df), len(test_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884ac75c",
   "metadata": {},
   "source": [
    "## 이진 분류용 데이터셋/모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93cba4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.users = df['user_idx'].to_numpy()\n",
    "        self.items = df['item_idx'].to_numpy()\n",
    "        self.labels = df['label'].to_numpy().astype(np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return int(self.users[idx]), int(self.items[idx]), float(self.labels[idx])\n",
    "\n",
    "\n",
    "class MFClassifier(nn.Module):\n",
    "    def __init__(self, num_users: int, num_items: int, embed_dim: int):\n",
    "        super().__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, embed_dim)\n",
    "        self.item_emb = nn.Embedding(num_items, embed_dim)\n",
    "        nn.init.normal_(self.user_emb.weight, std=0.1)\n",
    "        nn.init.normal_(self.item_emb.weight, std=0.1)\n",
    "\n",
    "    def forward(self, u, i):\n",
    "        u_e = self.user_emb(u)\n",
    "        i_e = self.item_emb(i)\n",
    "        logits = (u_e * i_e).sum(dim=1)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733a28c5",
   "metadata": {},
   "source": [
    "## 이진 분류 학습/평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de7058de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_22248/4178059323.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  u = torch.tensor(u, device=DEVICE)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_22248/4178059323.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  i = torch.tensor(i, device=DEVICE)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_22248/4178059323.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, device=DEVICE)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_22248/4178059323.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  u = torch.tensor(u, device=device)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_22248/4178059323.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  i = torch.tensor(i, device=device)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_22248/4178059323.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, device=device)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_22248/4178059323.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  u = torch.tensor(u, device=DEVICE)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_22248/4178059323.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  i = torch.tensor(i, device=DEVICE)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_22248/4178059323.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, device=DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BIN] epoch=1 loss=0.6939 metrics={'auc': 0.5033773718058987, 'f1@0.5': 0.5039446771208727, 'prec@0.5': 0.5, 'recall@0.5': 0.5079520911054388}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_22248/4178059323.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  u = torch.tensor(u, device=device)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_22248/4178059323.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  i = torch.tensor(i, device=device)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_22248/4178059323.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, device=device)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_22248/4178059323.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  u = torch.tensor(u, device=DEVICE)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_22248/4178059323.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  i = torch.tensor(i, device=DEVICE)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_22248/4178059323.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, device=DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BIN] epoch=2 loss=0.6849 metrics={'auc': 0.5063906985629343, 'f1@0.5': 0.504523786360541, 'prec@0.5': 0.5, 'recall@0.5': 0.5091301786766149}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_22248/4178059323.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  u = torch.tensor(u, device=device)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_22248/4178059323.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  i = torch.tensor(i, device=device)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_22248/4178059323.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, device=device)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_22248/4178059323.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  u = torch.tensor(u, device=DEVICE)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_22248/4178059323.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  i = torch.tensor(i, device=DEVICE)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_22248/4178059323.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, device=DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BIN] epoch=3 loss=0.6745 metrics={'auc': 0.5138197689735005, 'f1@0.5': 0.5098995415975812, 'prec@0.5': 0.5065891472868217, 'recall@0.5': 0.5132534851757314}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_22248/4178059323.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  u = torch.tensor(u, device=device)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_22248/4178059323.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  i = torch.tensor(i, device=device)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_22248/4178059323.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, device=device)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_22248/4178059323.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  u = torch.tensor(u, device=DEVICE)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_22248/4178059323.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  i = torch.tensor(i, device=DEVICE)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_22248/4178059323.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, device=DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BIN] epoch=4 loss=0.6604 metrics={'auc': 0.5277778957216923, 'f1@0.5': 0.5223053746719798, 'prec@0.5': 0.5171285604311009, 'recall@0.5': 0.5275868839583743}\n",
      "[BIN] epoch=5 loss=0.6405 metrics={'auc': 0.5509159671030579, 'f1@0.5': 0.5385212497574229, 'prec@0.5': 0.5323230385574526, 'recall@0.5': 0.5448655016689574}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_22248/4178059323.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  u = torch.tensor(u, device=device)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_22248/4178059323.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  i = torch.tensor(i, device=device)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_22248/4178059323.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, device=device)\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(PairDataset(train_df), batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(PairDataset(val_df), batch_size=BATCH_SIZE)\n",
    "\n",
    "def evaluate_binary(model, loader, device='cpu'):\n",
    "    model.eval()\n",
    "    ys = []\n",
    "    ps = []\n",
    "    with torch.no_grad():\n",
    "        for u, i, y in loader:\n",
    "            u = torch.tensor(u, device=device)\n",
    "            i = torch.tensor(i, device=device)\n",
    "            y = torch.tensor(y, device=device, dtype=torch.float32)\n",
    "            logits = model(u, i)\n",
    "            prob = torch.sigmoid(logits)\n",
    "            ys.append(y.cpu().numpy())\n",
    "            ps.append(prob.cpu().numpy())\n",
    "    y_true = np.concatenate(ys)\n",
    "    y_prob = np.concatenate(ps)\n",
    "    metrics = {}\n",
    "    metrics['auc'] = roc_auc_score(y_true, y_prob)\n",
    "    for th in [0.5]:\n",
    "        y_pred = (y_prob >= th).astype(int)\n",
    "        metrics[f'f1@{th}'] = f1_score(y_true, y_pred)\n",
    "        metrics[f'prec@{th}'] = precision_score(y_true, y_pred)\n",
    "        metrics[f'recall@{th}'] = recall_score(y_true, y_pred)\n",
    "    return metrics\n",
    "\n",
    "model_bin = MFClassifier(len(user2idx), len(item2idx), EMBED_DIM).to(DEVICE)\n",
    "optim_bin = torch.optim.Adam(model_bin.parameters(), lr=LR)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model_bin.train()\n",
    "    total_loss = 0.0\n",
    "    for u, i, y in train_loader:\n",
    "        u = torch.tensor(u, device=DEVICE)\n",
    "        i = torch.tensor(i, device=DEVICE)\n",
    "        y = torch.tensor(y, device=DEVICE, dtype=torch.float32)\n",
    "        logits = model_bin(u, i)\n",
    "        loss = nn.functional.binary_cross_entropy_with_logits(logits, y)\n",
    "        optim_bin.zero_grad()\n",
    "        loss.backward()\n",
    "        optim_bin.step()\n",
    "        total_loss += loss.item() * u.shape[0]\n",
    "    metrics = evaluate_binary(model_bin, val_loader, device=DEVICE)\n",
    "    print(f\"[BIN] epoch={epoch} loss={total_loss/len(train_loader.dataset):.4f} metrics={metrics}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3e0b41",
   "metadata": {},
   "source": [
    "## 회귀용 모델/평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b464dc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFRegressor(nn.Module):\n",
    "    def __init__(self, num_users: int, num_items: int, embed_dim: int):\n",
    "        super().__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, embed_dim)\n",
    "        self.item_emb = nn.Embedding(num_items, embed_dim)\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "        nn.init.normal_(self.user_emb.weight, std=0.1)\n",
    "        nn.init.normal_(self.item_emb.weight, std=0.1)\n",
    "\n",
    "    def forward(self, u, i):\n",
    "        u_e = self.user_emb(u)\n",
    "        i_e = self.item_emb(i)\n",
    "        pred = (u_e * i_e).sum(dim=1) + self.bias\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d5faaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_22248/4196462296.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  u = torch.tensor(u, device=DEVICE)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_22248/4196462296.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  i = torch.tensor(i, device=DEVICE)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_22248/4196462296.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, device=DEVICE)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found dtype Double but expected Float",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     36\u001b[39m loss = nn.functional.mse_loss(pred, y)\n\u001b[32m     37\u001b[39m optim_reg.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m optim_reg.step()\n\u001b[32m     40\u001b[39m total_loss += loss.item() * u.shape[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/학교/2025-2/그래프신경망과빅데이터/gnn-recsys/.venv/lib/python3.12/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/학교/2025-2/그래프신경망과빅데이터/gnn-recsys/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/학교/2025-2/그래프신경망과빅데이터/gnn-recsys/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mRuntimeError\u001b[39m: Found dtype Double but expected Float"
     ]
    }
   ],
   "source": [
    "train_loader_reg = DataLoader(PairDataset(train_df.assign(label=train_df['rating'])), batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader_reg = DataLoader(PairDataset(val_df.assign(label=val_df['rating'])), batch_size=BATCH_SIZE)\n",
    "\n",
    "def evaluate_reg(model, loader, device='cpu', threshold=4.0):\n",
    "    model.eval()\n",
    "    ys = []\n",
    "    ps = []\n",
    "    with torch.no_grad():\n",
    "        for u, i, y in loader:\n",
    "            u = torch.tensor(u, device=device)\n",
    "            i = torch.tensor(i, device=device)\n",
    "            y = torch.tensor(y, device=device, dtype=torch.float32)\n",
    "            pred = model(u, i)\n",
    "            ys.append(y.cpu().numpy())\n",
    "            ps.append(pred.cpu().numpy())\n",
    "    y_true = np.concatenate(ys)\n",
    "    y_pred = np.concatenate(ps)\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    y_bin = (y_true >= threshold).astype(int)\n",
    "    y_bin_pred = (y_pred >= threshold).astype(int)\n",
    "    f1 = f1_score(y_bin, y_bin_pred)\n",
    "    return {'rmse': rmse, 'mae': mae, f'f1@{threshold}': f1}\n",
    "\n",
    "model_reg = MFRegressor(len(user2idx), len(item2idx), EMBED_DIM).to(DEVICE)\n",
    "optim_reg = torch.optim.Adam(model_reg.parameters(), lr=LR)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model_reg.train()\n",
    "    total_loss = 0.0\n",
    "    for u, i, y in train_loader_reg:\n",
    "        u = torch.tensor(u, device=DEVICE)\n",
    "        i = torch.tensor(i, device=DEVICE)\n",
    "        y = torch.tensor(y, device=DEVICE, dtype=torch.float32)\n",
    "        pred = model_reg(u, i)\n",
    "        loss = nn.functional.mse_loss(pred, y)\n",
    "        optim_reg.zero_grad()\n",
    "        loss.backward()\n",
    "        optim_reg.step()\n",
    "        total_loss += loss.item() * u.shape[0]\n",
    "    metrics = evaluate_reg(model_reg, val_loader_reg, device=DEVICE, threshold=4.0)\n",
    "    print(f\"[REG] epoch={epoch} loss={total_loss/len(train_loader_reg.dataset):.4f} metrics={metrics}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce8ce35",
   "metadata": {},
   "source": [
    "## 체크포인트 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6643325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'model_state': model_bin.state_dict(),\n",
    "    'num_users': len(user2idx),\n",
    "    'num_items': len(item2idx),\n",
    "    'embed_dim': EMBED_DIM,\n",
    "    'type': 'binary'\n",
    "}, MODEL_DIR / 'codexb1_binary.pth')\n",
    "\n",
    "torch.save({\n",
    "    'model_state': model_reg.state_dict(),\n",
    "    'num_users': len(user2idx),\n",
    "    'num_items': len(item2idx),\n",
    "    'embed_dim': EMBED_DIM,\n",
    "    'type': 'regression'\n",
    "}, MODEL_DIR / 'codexb1_regression.pth')\n",
    "print('saved checkpoints')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11317fe",
   "metadata": {},
   "source": [
    "## 추론 유틸 (O/X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a25847f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ox_binary(model, user_enc, item_enc, csv_path: Path, threshold=0.5):\n",
    "    df_in = pd.read_csv(csv_path)\n",
    "    users = df_in['user'].map(user_enc)\n",
    "    items = df_in['item'].map(item_enc)\n",
    "    if users.isnull().any() or items.isnull().any():\n",
    "        raise ValueError('미등록 user/item 존재')\n",
    "    u = torch.tensor(users.to_numpy(), device=DEVICE)\n",
    "    i = torch.tensor(items.to_numpy(), device=DEVICE)\n",
    "    with torch.no_grad():\n",
    "        prob = torch.sigmoid(model(u, i)).cpu().numpy()\n",
    "    df_in['recommend'] = np.where(prob >= threshold, 'O', 'X')\n",
    "    total_o = (df_in['recommend'] == 'O').sum()\n",
    "    total = len(df_in)\n",
    "    print(df_in)\n",
    "    print(f\"====================\n",
    "Total recommends = {total_o}/{total}\n",
    "Not recommend = {total - total_o}/{total}\")\n",
    "    return df_in\n",
    "\n",
    "\n",
    "def predict_ox_reg(model, user_enc, item_enc, csv_path: Path, threshold=4.0):\n",
    "    df_in = pd.read_csv(csv_path)\n",
    "    users = df_in['user'].map(user_enc)\n",
    "    items = df_in['item'].map(item_enc)\n",
    "    if users.isnull().any() or items.isnull().any():\n",
    "        raise ValueError('미등록 user/item 존재')\n",
    "    u = torch.tensor(users.to_numpy(), device=DEVICE)\n",
    "    i = torch.tensor(items.to_numpy(), device=DEVICE)\n",
    "    with torch.no_grad():\n",
    "        pred = model(u, i).cpu().numpy()\n",
    "    df_in['recommend'] = np.where(pred >= threshold, 'O', 'X')\n",
    "    total_o = (df_in['recommend'] == 'O').sum()\n",
    "    total = len(df_in)\n",
    "    print(df_in)\n",
    "    print(f\"====================\n",
    "Total recommends = {total_o}/{total}\n",
    "Not recommend = {total - total_o}/{total}\")\n",
    "    return df_in\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e168f92f",
   "metadata": {},
   "source": [
    "## 추론 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c50e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 후 실행 예시\n",
    "# predict_ox_binary(model_bin, user2idx, item2idx, Path('../data/sample1.csv'), threshold=0.5)\n",
    "# predict_ox_reg(model_reg, user2idx, item2idx, Path('../data/sample1.csv'), threshold=4.0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
