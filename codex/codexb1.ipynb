{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b4f1eab",
   "metadata": {},
   "source": [
    "# B버전 (rating 활용: 이진 + 회귀 실험)\n",
    "- label1: rating >= 4 → 1, else 0 (이진 분류)\n",
    "- label2: 회귀로 rating 예측 후 threshold=4로 추천\n",
    "- 네거티브: 평점<4만 음성으로 사용, 미관측 음성 미사용\n",
    "- 스플릿: 유저별 8/1/1 랜덤\n",
    "- 평가지표: AUC/F1/PR@thres (이진), RMSE/MAE + 분류메트릭(회귀→임계) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce927a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경 준비\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append('..')  # 상위 디렉토리 import 허용\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "from common import (\n",
    "    load_interactions,\n",
    "    encode_ids,\n",
    "    split_userwise,\n",
    "    make_binary_label,\n",
    ")\n",
    "\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364affaf",
   "metadata": {},
   "source": [
    "## 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07588a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('../data/train.csv')\n",
    "MODEL_DIR = Path('../codex_models')\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SEED = 42\n",
    "TRAIN_RATIO = 0.8\n",
    "VAL_RATIO = 0.1\n",
    "THRESHOLDS = [4.0]  # 분류 임계값 후보\n",
    "\n",
    "EMBED_DIM = 64\n",
    "N_LAYERS = 2\n",
    "LR = 1e-3\n",
    "BATCH_SIZE = 1024\n",
    "EPOCHS = 5  # 필요 시 조정\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "rng = np.random.default_rng(SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179ebb71",
   "metadata": {},
   "source": [
    "## 데이터 로드/인덱싱/라벨링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b438b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = load_interactions(DATA_PATH)\n",
    "print(df_raw.head())\n",
    "\n",
    "df_bin = make_binary_label(df_raw, threshold=4.0)\n",
    "\n",
    "df, user2idx, item2idx = encode_ids(df_bin)\n",
    "print(f\"users={len(user2idx)}, items={len(item2idx)}, interactions={len(df)}\")\n",
    "\n",
    "train_df, val_df, test_df = split_userwise(df, train_ratio=TRAIN_RATIO, val_ratio=VAL_RATIO, seed=SEED)\n",
    "print(len(train_df), len(val_df), len(test_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884ac75c",
   "metadata": {},
   "source": [
    "## 이진 분류용 데이터셋/모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cba4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.users = df['user_idx'].to_numpy()\n",
    "        self.items = df['item_idx'].to_numpy()\n",
    "        self.labels = df['label'].to_numpy().astype(np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return int(self.users[idx]), int(self.items[idx]), float(self.labels[idx])\n",
    "\n",
    "\n",
    "class MFClassifier(nn.Module):\n",
    "    def __init__(self, num_users: int, num_items: int, embed_dim: int):\n",
    "        super().__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, embed_dim)\n",
    "        self.item_emb = nn.Embedding(num_items, embed_dim)\n",
    "        nn.init.normal_(self.user_emb.weight, std=0.1)\n",
    "        nn.init.normal_(self.item_emb.weight, std=0.1)\n",
    "\n",
    "    def forward(self, u, i):\n",
    "        u_e = self.user_emb(u)\n",
    "        i_e = self.item_emb(i)\n",
    "        logits = (u_e * i_e).sum(dim=1)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733a28c5",
   "metadata": {},
   "source": [
    "## 이진 분류 학습/평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7058de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(PairDataset(train_df), batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(PairDataset(val_df), batch_size=BATCH_SIZE)\n",
    "\n",
    "def evaluate_binary(model, loader, device='cpu'):\n",
    "    model.eval()\n",
    "    ys = []\n",
    "    ps = []\n",
    "    with torch.no_grad():\n",
    "        for u, i, y in loader:\n",
    "            u = torch.tensor(u, device=device)\n",
    "            i = torch.tensor(i, device=device)\n",
    "            y = torch.tensor(y, device=device)\n",
    "            logits = model(u, i)\n",
    "            prob = torch.sigmoid(logits)\n",
    "            ys.append(y.cpu().numpy())\n",
    "            ps.append(prob.cpu().numpy())\n",
    "    y_true = np.concatenate(ys)\n",
    "    y_prob = np.concatenate(ps)\n",
    "    metrics = {}\n",
    "    metrics['auc'] = roc_auc_score(y_true, y_prob)\n",
    "    for th in [0.5]:\n",
    "        y_pred = (y_prob >= th).astype(int)\n",
    "        metrics[f'f1@{th}'] = f1_score(y_true, y_pred)\n",
    "        metrics[f'prec@{th}'] = precision_score(y_true, y_pred)\n",
    "        metrics[f'recall@{th}'] = recall_score(y_true, y_pred)\n",
    "    return metrics\n",
    "\n",
    "model_bin = MFClassifier(len(user2idx), len(item2idx), EMBED_DIM).to(DEVICE)\n",
    "optim_bin = torch.optim.Adam(model_bin.parameters(), lr=LR)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model_bin.train()\n",
    "    total_loss = 0.0\n",
    "    for u, i, y in train_loader:\n",
    "        u = torch.tensor(u, device=DEVICE)\n",
    "        i = torch.tensor(i, device=DEVICE)\n",
    "        y = torch.tensor(y, device=DEVICE)\n",
    "        logits = model_bin(u, i)\n",
    "        loss = nn.functional.binary_cross_entropy_with_logits(logits, y)\n",
    "        optim_bin.zero_grad()\n",
    "        loss.backward()\n",
    "        optim_bin.step()\n",
    "        total_loss += loss.item() * u.shape[0]\n",
    "    metrics = evaluate_binary(model_bin, val_loader, device=DEVICE)\n",
    "    print(f\"[BIN] epoch={epoch} loss={total_loss/len(train_loader.dataset):.4f} metrics={metrics}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3e0b41",
   "metadata": {},
   "source": [
    "## 회귀용 모델/평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b464dc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFRegressor(nn.Module):\n",
    "    def __init__(self, num_users: int, num_items: int, embed_dim: int):\n",
    "        super().__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, embed_dim)\n",
    "        self.item_emb = nn.Embedding(num_items, embed_dim)\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "        nn.init.normal_(self.user_emb.weight, std=0.1)\n",
    "        nn.init.normal_(self.item_emb.weight, std=0.1)\n",
    "\n",
    "    def forward(self, u, i):\n",
    "        u_e = self.user_emb(u)\n",
    "        i_e = self.item_emb(i)\n",
    "        pred = (u_e * i_e).sum(dim=1) + self.bias\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5faaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_reg = DataLoader(PairDataset(train_df.assign(label=train_df['rating'])), batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader_reg = DataLoader(PairDataset(val_df.assign(label=val_df['rating'])), batch_size=BATCH_SIZE)\n",
    "\n",
    "def evaluate_reg(model, loader, device='cpu', threshold=4.0):\n",
    "    model.eval()\n",
    "    ys = []\n",
    "    ps = []\n",
    "    with torch.no_grad():\n",
    "        for u, i, y in loader:\n",
    "            u = torch.tensor(u, device=device)\n",
    "            i = torch.tensor(i, device=device)\n",
    "            y = torch.tensor(y, device=device)\n",
    "            pred = model(u, i)\n",
    "            ys.append(y.cpu().numpy())\n",
    "            ps.append(pred.cpu().numpy())\n",
    "    y_true = np.concatenate(ys)\n",
    "    y_pred = np.concatenate(ps)\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    y_bin = (y_true >= threshold).astype(int)\n",
    "    y_bin_pred = (y_pred >= threshold).astype(int)\n",
    "    f1 = f1_score(y_bin, y_bin_pred)\n",
    "    return {'rmse': rmse, 'mae': mae, f'f1@{threshold}': f1}\n",
    "\n",
    "model_reg = MFRegressor(len(user2idx), len(item2idx), EMBED_DIM).to(DEVICE)\n",
    "optim_reg = torch.optim.Adam(model_reg.parameters(), lr=LR)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model_reg.train()\n",
    "    total_loss = 0.0\n",
    "    for u, i, y in train_loader_reg:\n",
    "        u = torch.tensor(u, device=DEVICE)\n",
    "        i = torch.tensor(i, device=DEVICE)\n",
    "        y = torch.tensor(y, device=DEVICE)\n",
    "        pred = model_reg(u, i)\n",
    "        loss = nn.functional.mse_loss(pred, y)\n",
    "        optim_reg.zero_grad()\n",
    "        loss.backward()\n",
    "        optim_reg.step()\n",
    "        total_loss += loss.item() * u.shape[0]\n",
    "    metrics = evaluate_reg(model_reg, val_loader_reg, device=DEVICE, threshold=4.0)\n",
    "    print(f\"[REG] epoch={epoch} loss={total_loss/len(train_loader_reg.dataset):.4f} metrics={metrics}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce8ce35",
   "metadata": {},
   "source": [
    "## 체크포인트 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6643325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'model_state': model_bin.state_dict(),\n",
    "    'num_users': len(user2idx),\n",
    "    'num_items': len(item2idx),\n",
    "    'embed_dim': EMBED_DIM,\n",
    "    'type': 'binary'\n",
    "}, MODEL_DIR / 'codexb1_binary.pth')\n",
    "\n",
    "torch.save({\n",
    "    'model_state': model_reg.state_dict(),\n",
    "    'num_users': len(user2idx),\n",
    "    'num_items': len(item2idx),\n",
    "    'embed_dim': EMBED_DIM,\n",
    "    'type': 'regression'\n",
    "}, MODEL_DIR / 'codexb1_regression.pth')\n",
    "print('saved checkpoints')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11317fe",
   "metadata": {},
   "source": [
    "## 추론 유틸 (O/X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a25847f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ox_binary(model, user_enc, item_enc, csv_path: Path, threshold=0.5):\n",
    "    df_in = pd.read_csv(csv_path)\n",
    "    users = df_in['user'].map(user_enc)\n",
    "    items = df_in['item'].map(item_enc)\n",
    "    if users.isnull().any() or items.isnull().any():\n",
    "        raise ValueError('미등록 user/item 존재')\n",
    "    u = torch.tensor(users.to_numpy(), device=DEVICE)\n",
    "    i = torch.tensor(items.to_numpy(), device=DEVICE)\n",
    "    with torch.no_grad():\n",
    "        prob = torch.sigmoid(model(u, i)).cpu().numpy()\n",
    "    df_in['recommend'] = np.where(prob >= threshold, 'O', 'X')\n",
    "    total_o = (df_in['recommend'] == 'O').sum()\n",
    "    total = len(df_in)\n",
    "    print(df_in)\n",
    "    print(f\"====================\n",
    "Total recommends = {total_o}/{total}\n",
    "Not recommend = {total - total_o}/{total}\")\n",
    "    return df_in\n",
    "\n",
    "\n",
    "def predict_ox_reg(model, user_enc, item_enc, csv_path: Path, threshold=4.0):\n",
    "    df_in = pd.read_csv(csv_path)\n",
    "    users = df_in['user'].map(user_enc)\n",
    "    items = df_in['item'].map(item_enc)\n",
    "    if users.isnull().any() or items.isnull().any():\n",
    "        raise ValueError('미등록 user/item 존재')\n",
    "    u = torch.tensor(users.to_numpy(), device=DEVICE)\n",
    "    i = torch.tensor(items.to_numpy(), device=DEVICE)\n",
    "    with torch.no_grad():\n",
    "        pred = model(u, i).cpu().numpy()\n",
    "    df_in['recommend'] = np.where(pred >= threshold, 'O', 'X')\n",
    "    total_o = (df_in['recommend'] == 'O').sum()\n",
    "    total = len(df_in)\n",
    "    print(df_in)\n",
    "    print(f\"====================\n",
    "Total recommends = {total_o}/{total}\n",
    "Not recommend = {total - total_o}/{total}\")\n",
    "    return df_in\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e168f92f",
   "metadata": {},
   "source": [
    "## 추론 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c50e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 후 실행 예시\n",
    "# predict_ox_binary(model_bin, user2idx, item2idx, Path('../data/sample1.csv'), threshold=0.5)\n",
    "# predict_ox_reg(model_reg, user2idx, item2idx, Path('../data/sample1.csv'), threshold=4.0)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}