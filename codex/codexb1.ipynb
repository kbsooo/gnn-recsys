{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b4f1eab",
   "metadata": {},
   "source": [
    "# B버전 (rating 활용: 이진 + 회귀 실험)\n",
    "- label1: rating >= 4 → 1, else 0 (이진 분류)\n",
    "- label2: 회귀로 rating 예측 후 threshold=4로 추천\n",
    "- 네거티브: 평점<4만 음성으로 사용, 미관측 음성 미사용\n",
    "- 스플릿: 유저별 8/1/1 랜덤\n",
    "- 평가지표: AUC/F1/PR@thres (이진), RMSE/MAE + 분류메트릭(회귀→임계) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ce927a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    "# 환경 준비\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append('..')  # 상위 디렉토리 import 허용\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "from common import (\n",
    "    load_interactions,\n",
    "    encode_ids,\n",
    "    split_userwise,\n",
    "    make_binary_label,\n",
    ")\n",
    "\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364affaf",
   "metadata": {},
   "source": [
    "## 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07588a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('../data/train.csv')\n",
    "MODEL_DIR = Path('../codex_models')\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SEED = 42\n",
    "TRAIN_RATIO = 0.8\n",
    "VAL_RATIO = 0.1\n",
    "THRESHOLDS = [4.0]  # 분류 임계값 후보\n",
    "\n",
    "EMBED_DIM = 64\n",
    "N_LAYERS = 2\n",
    "LR = 1e-3\n",
    "BATCH_SIZE = 1024\n",
    "EPOCHS = 5  # 필요 시 조정\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "rng = np.random.default_rng(SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179ebb71",
   "metadata": {},
   "source": [
    "## 데이터 로드/인덱싱/라벨링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b438b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user  item  rating\n",
      "0     1    16     4.0\n",
      "1     1    24     1.5\n",
      "2     1    32     4.0\n",
      "3     1    47     4.0\n",
      "4     1    50     4.0\n",
      "users=668, items=10321, interactions=105139\n",
      "83855 10226 11058\n"
     ]
    }
   ],
   "source": [
    "df_raw = load_interactions(DATA_PATH)\n",
    "print(df_raw.head())\n",
    "\n",
    "df_bin = make_binary_label(df_raw, threshold=4.0)\n",
    "\n",
    "df, user2idx, item2idx = encode_ids(df_bin)\n",
    "print(f\"users={len(user2idx)}, items={len(item2idx)}, interactions={len(df)}\")\n",
    "\n",
    "train_df, val_df, test_df = split_userwise(df, train_ratio=TRAIN_RATIO, val_ratio=VAL_RATIO, seed=SEED)\n",
    "print(len(train_df), len(val_df), len(test_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884ac75c",
   "metadata": {},
   "source": [
    "## 이진 분류용 데이터셋/모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93cba4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.users = df['user_idx'].to_numpy()\n",
    "        self.items = df['item_idx'].to_numpy()\n",
    "        self.labels = df['label'].to_numpy().astype(np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return int(self.users[idx]), int(self.items[idx]), float(self.labels[idx])\n",
    "\n",
    "\n",
    "class MFClassifier(nn.Module):\n",
    "    def __init__(self, num_users: int, num_items: int, embed_dim: int):\n",
    "        super().__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, embed_dim)\n",
    "        self.item_emb = nn.Embedding(num_items, embed_dim)\n",
    "        nn.init.normal_(self.user_emb.weight, std=0.1)\n",
    "        nn.init.normal_(self.item_emb.weight, std=0.1)\n",
    "\n",
    "    def forward(self, u, i):\n",
    "        u_e = self.user_emb(u)\n",
    "        i_e = self.item_emb(i)\n",
    "        logits = (u_e * i_e).sum(dim=1)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733a28c5",
   "metadata": {},
   "source": [
    "## 이진 분류 학습/평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de7058de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_23338/875425565.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  u = torch.tensor(u, device=DEVICE)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_23338/875425565.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  i = torch.tensor(i, device=DEVICE)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_23338/875425565.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, device=DEVICE, dtype=torch.float32)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_23338/875425565.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  u = torch.tensor(u, device=device)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_23338/875425565.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  i = torch.tensor(i, device=device)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_23338/875425565.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, device=device, dtype=torch.float32)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_23338/875425565.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  u = torch.tensor(u, device=DEVICE)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_23338/875425565.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  i = torch.tensor(i, device=DEVICE)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_23338/875425565.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, device=DEVICE, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BIN] epoch=1 loss=0.6939 metrics={'auc': 0.49871080926139477, 'f1@0.5': 0.5036418374283772, 'prec@0.5': 0.49827056110684087, 'recall@0.5': 0.5091301786766149}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_23338/875425565.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  u = torch.tensor(u, device=device)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_23338/875425565.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  i = torch.tensor(i, device=device)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_23338/875425565.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, device=device, dtype=torch.float32)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_23338/875425565.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  u = torch.tensor(u, device=DEVICE)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_23338/875425565.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  i = torch.tensor(i, device=DEVICE)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_23338/875425565.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, device=DEVICE, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BIN] epoch=2 loss=0.6849 metrics={'auc': 0.5003559738599054, 'f1@0.5': 0.5070887550980773, 'prec@0.5': 0.5016330451488953, 'recall@0.5': 0.5126644413901433}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_23338/875425565.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  u = torch.tensor(u, device=device)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_23338/875425565.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  i = torch.tensor(i, device=device)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_23338/875425565.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, device=device, dtype=torch.float32)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_23338/875425565.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  u = torch.tensor(u, device=DEVICE)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_23338/875425565.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  i = torch.tensor(i, device=DEVICE)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_23338/875425565.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, device=DEVICE, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BIN] epoch=3 loss=0.6746 metrics={'auc': 0.507301136327775, 'f1@0.5': 0.5123114355231143, 'prec@0.5': 0.507912003087611, 'recall@0.5': 0.5167877478892597}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_23338/875425565.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  u = torch.tensor(u, device=device)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_23338/875425565.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  i = torch.tensor(i, device=device)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_23338/875425565.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, device=device, dtype=torch.float32)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_23338/875425565.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  u = torch.tensor(u, device=DEVICE)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_23338/875425565.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  i = torch.tensor(i, device=DEVICE)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_23338/875425565.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, device=DEVICE, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BIN] epoch=4 loss=0.6606 metrics={'auc': 0.5223311054939206, 'f1@0.5': 0.5214341387373344, 'prec@0.5': 0.5175014503964417, 'recall@0.5': 0.5254270567445514}\n",
      "[BIN] epoch=5 loss=0.6410 metrics={'auc': 0.5461003553273998, 'f1@0.5': 0.5379605327111889, 'prec@0.5': 0.53273007316134, 'recall@0.5': 0.5432947182407225}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_23338/875425565.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  u = torch.tensor(u, device=device)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_23338/875425565.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  i = torch.tensor(i, device=device)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_23338/875425565.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, device=device, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(PairDataset(train_df), batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(PairDataset(val_df), batch_size=BATCH_SIZE)\n",
    "\n",
    "def evaluate_binary(model, loader, device='cpu'):\n",
    "    model.eval()\n",
    "    ys = []\n",
    "    ps = []\n",
    "    with torch.no_grad():\n",
    "        for u, i, y in loader:\n",
    "            u = torch.tensor(u, device=device)\n",
    "            i = torch.tensor(i, device=device)\n",
    "            y = torch.tensor(y, device=device, dtype=torch.float32)\n",
    "            logits = model(u, i)\n",
    "            prob = torch.sigmoid(logits)\n",
    "            ys.append(y.cpu().numpy())\n",
    "            ps.append(prob.cpu().numpy())\n",
    "    y_true = np.concatenate(ys)\n",
    "    y_prob = np.concatenate(ps)\n",
    "    metrics = {}\n",
    "    metrics['auc'] = roc_auc_score(y_true, y_prob)\n",
    "    for th in [0.5]:\n",
    "        y_pred = (y_prob >= th).astype(int)\n",
    "        metrics[f'f1@{th}'] = f1_score(y_true, y_pred)\n",
    "        metrics[f'prec@{th}'] = precision_score(y_true, y_pred)\n",
    "        metrics[f'recall@{th}'] = recall_score(y_true, y_pred)\n",
    "    return metrics\n",
    "\n",
    "model_bin = MFClassifier(len(user2idx), len(item2idx), EMBED_DIM).to(DEVICE)\n",
    "optim_bin = torch.optim.Adam(model_bin.parameters(), lr=LR)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model_bin.train()\n",
    "    total_loss = 0.0\n",
    "    for u, i, y in train_loader:\n",
    "        u = torch.tensor(u, device=DEVICE)\n",
    "        i = torch.tensor(i, device=DEVICE)\n",
    "        y = torch.tensor(y, device=DEVICE, dtype=torch.float32)\n",
    "        logits = model_bin(u, i)\n",
    "        loss = nn.functional.binary_cross_entropy_with_logits(logits, y)\n",
    "        optim_bin.zero_grad()\n",
    "        loss.backward()\n",
    "        optim_bin.step()\n",
    "        total_loss += loss.item() * u.shape[0]\n",
    "    metrics = evaluate_binary(model_bin, val_loader, device=DEVICE)\n",
    "    print(f\"[BIN] epoch={epoch} loss={total_loss/len(train_loader.dataset):.4f} metrics={metrics}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3e0b41",
   "metadata": {},
   "source": [
    "## 회귀용 모델/평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b464dc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFRegressor(nn.Module):\n",
    "    def __init__(self, num_users: int, num_items: int, embed_dim: int):\n",
    "        super().__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, embed_dim)\n",
    "        self.item_emb = nn.Embedding(num_items, embed_dim)\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "        nn.init.normal_(self.user_emb.weight, std=0.1)\n",
    "        nn.init.normal_(self.item_emb.weight, std=0.1)\n",
    "\n",
    "    def forward(self, u, i):\n",
    "        u_e = self.user_emb(u)\n",
    "        i_e = self.item_emb(i)\n",
    "        pred = (u_e * i_e).sum(dim=1) + self.bias\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d5faaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_23338/3815646220.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  u = torch.tensor(u, device=DEVICE)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_23338/3815646220.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  i = torch.tensor(i, device=DEVICE)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_23338/3815646220.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, device=DEVICE, dtype=torch.float32)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_23338/3815646220.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  u = torch.tensor(u, device=device)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_23338/3815646220.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  i = torch.tensor(i, device=device)\n",
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_23338/3815646220.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, device=device, dtype=torch.float32)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "got an unexpected keyword argument 'squared'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     39\u001b[39m     optim_reg.step()\n\u001b[32m     40\u001b[39m     total_loss += loss.item() * u.shape[\u001b[32m0\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m metrics = \u001b[43mevaluate_reg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[REG] epoch=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss/\u001b[38;5;28mlen\u001b[39m(train_loader_reg.dataset)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m metrics=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mevaluate_reg\u001b[39m\u001b[34m(model, loader, device, threshold)\u001b[39m\n\u001b[32m     16\u001b[39m y_true = np.concatenate(ys)\n\u001b[32m     17\u001b[39m y_pred = np.concatenate(ps)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m rmse = \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m mae = mean_absolute_error(y_true, y_pred)\n\u001b[32m     20\u001b[39m y_bin = (y_true >= threshold).astype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/학교/2025-2/그래프신경망과빅데이터/gnn-recsys/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:196\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    193\u001b[39m func_sig = signature(func)\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m params = \u001b[43mfunc_sig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    197\u001b[39m params.apply_defaults()\n\u001b[32m    199\u001b[39m \u001b[38;5;66;03m# ignore self/cls and positional/keyword markers\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.12/Frameworks/Python.framework/Versions/3.12/lib/python3.12/inspect.py:3280\u001b[39m, in \u001b[36mSignature.bind\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3275\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, /, *args, **kwargs):\n\u001b[32m   3276\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[32m   3277\u001b[39m \u001b[33;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[32m   3278\u001b[39m \u001b[33;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[32m   3279\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3280\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.12/Frameworks/Python.framework/Versions/3.12/lib/python3.12/inspect.py:3269\u001b[39m, in \u001b[36mSignature._bind\u001b[39m\u001b[34m(self, args, kwargs, partial)\u001b[39m\n\u001b[32m   3259\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   3260\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mgot some positional-only arguments passed as \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   3261\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mkeyword arguments: \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[33m'\u001b[39m.format(\n\u001b[32m   (...)\u001b[39m\u001b[32m   3266\u001b[39m             ),\n\u001b[32m   3267\u001b[39m         )\n\u001b[32m   3268\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3269\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   3270\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mgot an unexpected keyword argument \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[33m'\u001b[39m.format(\n\u001b[32m   3271\u001b[39m                 arg=\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))))\n\u001b[32m   3273\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_arguments_cls(\u001b[38;5;28mself\u001b[39m, arguments)\n",
      "\u001b[31mTypeError\u001b[39m: got an unexpected keyword argument 'squared'"
     ]
    }
   ],
   "source": [
    "train_loader_reg = DataLoader(PairDataset(train_df.assign(label=train_df['rating'])), batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader_reg = DataLoader(PairDataset(val_df.assign(label=val_df['rating'])), batch_size=BATCH_SIZE)\n",
    "\n",
    "def evaluate_reg(model, loader, device='cpu', threshold=4.0):\n",
    "    model.eval()\n",
    "    ys = []\n",
    "    ps = []\n",
    "    with torch.no_grad():\n",
    "        for u, i, y in loader:\n",
    "            u = torch.tensor(u, device=device)\n",
    "            i = torch.tensor(i, device=device)\n",
    "            y = torch.tensor(y, device=device, dtype=torch.float32)\n",
    "            pred = model(u, i)\n",
    "            ys.append(y.cpu().numpy())\n",
    "            ps.append(pred.cpu().numpy())\n",
    "    y_true = np.concatenate(ys)\n",
    "    y_pred = np.concatenate(ps)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    y_bin = (y_true >= threshold).astype(int)\n",
    "    y_bin_pred = (y_pred >= threshold).astype(int)\n",
    "    f1 = f1_score(y_bin, y_bin_pred)\n",
    "    return {'rmse': rmse, 'mae': mae, f'f1@{threshold}': f1}\n",
    "\n",
    "model_reg = MFRegressor(len(user2idx), len(item2idx), EMBED_DIM).to(DEVICE)\n",
    "optim_reg = torch.optim.Adam(model_reg.parameters(), lr=LR)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model_reg.train()\n",
    "    total_loss = 0.0\n",
    "    for u, i, y in train_loader_reg:\n",
    "        u = torch.tensor(u, device=DEVICE)\n",
    "        i = torch.tensor(i, device=DEVICE)\n",
    "        y = torch.tensor(y, device=DEVICE, dtype=torch.float32)\n",
    "        pred = model_reg(u, i)\n",
    "        loss = nn.functional.mse_loss(pred, y)\n",
    "        optim_reg.zero_grad()\n",
    "        loss.backward()\n",
    "        optim_reg.step()\n",
    "        total_loss += loss.item() * u.shape[0]\n",
    "    metrics = evaluate_reg(model_reg, val_loader_reg, device=DEVICE, threshold=4.0)\n",
    "    print(f\"[REG] epoch={epoch} loss={total_loss/len(train_loader_reg.dataset):.4f} metrics={metrics}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce8ce35",
   "metadata": {},
   "source": [
    "## 체크포인트 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6643325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'model_state': model_bin.state_dict(),\n",
    "    'num_users': len(user2idx),\n",
    "    'num_items': len(item2idx),\n",
    "    'embed_dim': EMBED_DIM,\n",
    "    'type': 'binary'\n",
    "}, MODEL_DIR / 'codexb1_binary.pth')\n",
    "\n",
    "torch.save({\n",
    "    'model_state': model_reg.state_dict(),\n",
    "    'num_users': len(user2idx),\n",
    "    'num_items': len(item2idx),\n",
    "    'embed_dim': EMBED_DIM,\n",
    "    'type': 'regression'\n",
    "}, MODEL_DIR / 'codexb1_regression.pth')\n",
    "print('saved checkpoints')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11317fe",
   "metadata": {},
   "source": [
    "## 추론 유틸 (O/X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a25847f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ox_binary(model, user_enc, item_enc, csv_path: Path, threshold=0.5):\n",
    "    df_in = pd.read_csv(csv_path)\n",
    "    users = df_in['user'].map(user_enc)\n",
    "    items = df_in['item'].map(item_enc)\n",
    "    if users.isnull().any() or items.isnull().any():\n",
    "        raise ValueError('미등록 user/item 존재')\n",
    "    u = torch.tensor(users.to_numpy(), device=DEVICE)\n",
    "    i = torch.tensor(items.to_numpy(), device=DEVICE)\n",
    "    with torch.no_grad():\n",
    "        prob = torch.sigmoid(model(u, i)).cpu().numpy()\n",
    "    df_in['recommend'] = np.where(prob >= threshold, 'O', 'X')\n",
    "    total_o = (df_in['recommend'] == 'O').sum()\n",
    "    total = len(df_in)\n",
    "    print(df_in)\n",
    "    print(f\"====================\n",
    "Total recommends = {total_o}/{total}\n",
    "Not recommend = {total - total_o}/{total}\")\n",
    "    return df_in\n",
    "\n",
    "\n",
    "def predict_ox_reg(model, user_enc, item_enc, csv_path: Path, threshold=4.0):\n",
    "    df_in = pd.read_csv(csv_path)\n",
    "    users = df_in['user'].map(user_enc)\n",
    "    items = df_in['item'].map(item_enc)\n",
    "    if users.isnull().any() or items.isnull().any():\n",
    "        raise ValueError('미등록 user/item 존재')\n",
    "    u = torch.tensor(users.to_numpy(), device=DEVICE)\n",
    "    i = torch.tensor(items.to_numpy(), device=DEVICE)\n",
    "    with torch.no_grad():\n",
    "        pred = model(u, i).cpu().numpy()\n",
    "    df_in['recommend'] = np.where(pred >= threshold, 'O', 'X')\n",
    "    total_o = (df_in['recommend'] == 'O').sum()\n",
    "    total = len(df_in)\n",
    "    print(df_in)\n",
    "    print(f\"====================\n",
    "Total recommends = {total_o}/{total}\n",
    "Not recommend = {total - total_o}/{total}\")\n",
    "    return df_in\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e168f92f",
   "metadata": {},
   "source": [
    "## 추론 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c50e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 후 실행 예시\n",
    "predict_ox_binary(model_bin, user2idx, item2idx, Path('../data/sample1.csv'), threshold=0.5)\n",
    "predict_ox_reg(model_reg, user2idx, item2idx, Path('../data/sample1.csv'), threshold=4.0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
