# CCA1 & CCB1 ê°œì„  ì „ëµ ë° Breakthrough Ideas

**ì‘ì„±ì¼**: 2025-11-18
**í˜„ì¬ ì„±ëŠ¥**: CCA1 (AUC 0.889), CCB1 (AUC 0.927)
**ëª©í‘œ**: 0.93+ (CCA1), 0.95+ (CCB1)

---

## Part 1: í˜„ì¬ ëª¨ë¸ì˜ í•œê³„ì  ë¶„ì„

### CCA1 (Binary Classification)ì˜ ë¬¸ì œì 

#### 1. í’ˆì§ˆ ë¯¸ê³ ë ¤ (Critical Issue âš ï¸)
```
ë¬¸ì œ: Rating 0.5ë„ positiveë¡œ ì·¨ê¸‰
ê²°ê³¼: ì‚¬ìš©ìê°€ ì‹«ì–´í•œ ì˜í™”ë„ ì¶”ì²œë  ìˆ˜ ìˆìŒ
ì˜í–¥: "ì˜ëª»ëœ ì¶”ì²œì€ ê°ì " ê·œì¹™ì—ì„œ ë¶ˆë¦¬
```

**ì‹¤ì œ ì˜ˆì‹œ**:
- User Aê°€ ì˜í™” Xë¥¼ ë´¤ì§€ë§Œ rating 1.0 (ìµœì•…)
- CCA1: "ì—°ê²°ì´ ìˆìœ¼ë‹ˆ ë¹„ìŠ·í•œ ì˜í™” ì¶”ì²œ" â†’ ì˜ëª»ëœ ì¶”ì²œ
- CCB1: "Rating < 4ë‹ˆê¹Œ ì¶”ì²œ ì•ˆí•¨" â†’ ì˜¬ë°”ë¥¸ íŒë‹¨

#### 2. Precision/Recall Trade-off í•œê³„
- Precision: 87.2% (ì¢‹ìŒ)
- Recall: 82.0% (ê°œì„  ì—¬ì§€)
- **ë¬¸ì œ**: ì¢‹ì€ ì˜í™”ë¥¼ 18%ë‚˜ ë†“ì¹¨

#### 3. Score Distribution ë¬¸ì œ
- Positive mean: 1.34, std: 0.80
- Negative mean: 0.16, std: 0.39
- **Gap**: 1.18 (ì¶©ë¶„í•˜ì§€ë§Œ CCB1ì˜ 1.15ë³´ë‹¤ ì‘ìŒ)

#### 4. Top-K Rankingì˜ ë¶ˆì•ˆì •ì„±
- Recall@Kê°€ epochë§ˆë‹¤ í¬ê²Œ ë³€ë™ (0.11 ~ 0.15)
- Best epoch 25 ì´í›„ ì„±ëŠ¥ í•˜ë½

---

### CCB1 (Rating Prediction)ì˜ ë¬¸ì œì 

#### 1. Rating ì •ë³´ ì˜ì¡´ì„± (Critical Issue âš ï¸)
```
ë¬¸ì œ: Test setì— rating ì—†ìœ¼ë©´ íŒë‹¨ ê¸°ì¤€ ìƒì‹¤
ê²°ê³¼: sample2.csvì—ì„œ ëª¨ë‘ O ì˜ˆì¸¡ (ë„ˆë¬´ ê³µê²©ì )
ì˜í–¥: Real-worldì—ì„œ rating ì—†ëŠ” ê²½ìš° ëŒ€ì‘ ë¶ˆê°€
```

**í•´ê²° í•„ìš”**:
- Rating ì—†ì„ ë•Œ Conservative ì „ëµ í•„ìš”
- Uncertainty estimation í•„ìš”

#### 2. Rating < 4 ë°ì´í„°ì˜ ë¹„íš¨ìœ¨ì  í™œìš©
- Rating < 4: Train graphì—ë§Œ í¬í•¨ (í‰ê°€ ì œì™¸)
- **ë¬¸ì œ**: 53,309ê°œì˜ negative signalì„ ì¶©ë¶„íˆ í™œìš© ëª»í•¨
- **ê°œì„  ê°€ëŠ¥**: Negativeë„ ì ê·¹ì ìœ¼ë¡œ í•™ìŠµì— í™œìš©

#### 3. Good Purchaseì˜ Imbalance
- Good (>=4): 51,830ê°œ (49.3%)
- Poor (<4): 53,309ê°œ (50.7%)
- **ê±°ì˜ ê· í˜•**: ì¢‹ì§€ë§Œ, class weight ì¡°ì •ìœ¼ë¡œ ë” ê°œì„  ê°€ëŠ¥

#### 4. Recall@Kì˜ ë³€ë™ì„±
- 0.15 ~ 0.23 ì‚¬ì´ì—ì„œ í° ë³€ë™
- CCA1ë³´ë‹¤ ë” ë¶ˆì•ˆì •

---

## Part 2: ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ ê°œì„  (v2 Level)

### A. CCA1 ê°œì„  ë°©í–¥ (cca2)

#### 1. Weighted BPR Loss (í’ˆì§ˆ ë°˜ì˜)
**ì•„ì´ë””ì–´**: Ratingì„ loss weightë¡œ í™œìš©
```python
# í˜„ì¬ (cca1)
loss = -log(sigmoid(pos_score - neg_score))

# ê°œì„  (cca2)
rating_weight = 0.5 + 0.1 * rating  # rating 5 -> weight 1.0
loss = rating_weight * (-log(sigmoid(pos_score - neg_score)))
```

**ê¸°ëŒ€ íš¨ê³¼**:
- ë†’ì€ ratingì˜ interactionì— ë” ì§‘ì¤‘
- ë‚®ì€ ratingì€ ëœ ì¤‘ìš”í•˜ê²Œ í•™ìŠµ
- í’ˆì§ˆ ê³ ë ¤í•˜ë©´ì„œë„ ëª¨ë“  ë°ì´í„° í™œìš©
- **ì˜ˆìƒ AUC**: 0.89 â†’ 0.91

#### 2. Score Re-calibration (Threshold ê°œì„ )
**ì•„ì´ë””ì–´**: Rating ë¶„í¬ë¥¼ ê³ ë ¤í•œ threshold ì¡°ì •
```python
# Userë³„ í‰ê·  rating ê³„ì‚°
user_avg_rating = df.groupby('user')['rating'].mean()

# Thresholdë¥¼ userë³„ë¡œ ì¡°ì •
adjusted_threshold = base_threshold * (user_avg_rating / 4.0)
```

**ê¸°ëŒ€ íš¨ê³¼**:
- í‰ê°€ ê¸°ì¤€ì´ ë†’ì€ user: threshold ë†’ì„
- í‰ê°€ ê¸°ì¤€ì´ ë‚®ì€ user: threshold ë‚®ì¶¤
- **ì˜ˆìƒ F1**: 0.845 â†’ 0.860

#### 3. Multi-Hop Attention (Layer ê°œì„ )
**ì•„ì´ë””ì–´**: Layerë³„ë¡œ ë‹¤ë¥¸ ê°€ì¤‘ì¹˜ í•™ìŠµ
```python
# í˜„ì¬: Simple mean
final_emb = mean([emb_0, emb_1, emb_2])

# ê°œì„ : Learnable attention
alpha = softmax([w_0, w_1, w_2])  # learnable
final_emb = alpha_0 * emb_0 + alpha_1 * emb_1 + alpha_2 * emb_2
```

**ê¸°ëŒ€ íš¨ê³¼**:
- Layerë³„ ì¤‘ìš”ë„ ìë™ í•™ìŠµ
- ë” expressiveí•œ representation
- **ì˜ˆìƒ AUC**: +0.5% ~ 1%

---

### B. CCB1 ê°œì„  ë°©í–¥ (ccb2)

#### 1. Uncertainty-Aware Recommendation (Rating ì˜ì¡´ì„± í•´ê²° â­)
**ì•„ì´ë””ì–´**: Bayesian ë˜ëŠ” Dropoutìœ¼ë¡œ uncertainty ì¸¡ì •
```python
# MC Dropoutìœ¼ë¡œ uncertainty ì¶”ì •
def predict_with_uncertainty(model, user, item, n_samples=10):
    model.train()  # Enable dropout
    scores = []
    for _ in range(n_samples):
        score = model(user, item)
        scores.append(score)

    mean_score = np.mean(scores)
    uncertainty = np.std(scores)

    # High uncertaintyë©´ conservative
    if uncertainty > threshold_unc:
        return 'X'  # Don't recommend
    else:
        return 'O' if mean_score > threshold else 'X'
```

**ê¸°ëŒ€ íš¨ê³¼**:
- Rating ì—†ì–´ë„ ëª¨ë¸ì˜ í™•ì‹ ë„ë¡œ íŒë‹¨ ê°€ëŠ¥
- Sample2 ë¬¸ì œ í•´ê²°
- **ì˜ˆìƒ**: Conservative but accurate

#### 2. Contrastive Learning for Better Separation (AUC í–¥ìƒ â­)
**ì•„ì´ë””ì–´**: Positiveë¼ë¦¬ ê°€ê¹ê²Œ, Negativeì™€ ë©€ê²Œ
```python
# Contrastive Loss (SimCLR style)
def contrastive_loss(pos_emb, neg_emb, temperature=0.1):
    # Positive pairs: ê°€ê¹ê²Œ
    pos_sim = cosine_similarity(pos_emb[0], pos_emb[1])

    # Negative pairs: ë©€ê²Œ
    neg_sim = cosine_similarity(pos_emb[0], neg_emb)

    loss = -log(exp(pos_sim / T) / (exp(pos_sim / T) + sum(exp(neg_sim / T))))
    return loss

# Total Loss
total_loss = BPR_loss + lambda_cl * contrastive_loss
```

**ê¸°ëŒ€ íš¨ê³¼**:
- Embedding spaceì—ì„œ ë” ëª…í™•í•œ êµ¬ì¡°
- AUC í–¥ìƒ (separation ê°œì„ )
- **ì˜ˆìƒ AUC**: 0.927 â†’ 0.940+

#### 3. Rating Distribution Modeling (Rating ì •ë³´ ìµœëŒ€ í™œìš©)
**ì•„ì´ë””ì–´**: Ratingì„ categoricalë¡œ ì·¨ê¸‰í•˜ì—¬ ë¶„í¬ í•™ìŠµ
```python
# Ratingì„ 10-class classification
rating_logits = MLP(user_emb, item_emb)  # (10,)
rating_probs = softmax(rating_logits)

# Expected rating
expected_rating = sum(rating_probs[i] * (i * 0.5 + 0.5) for i in range(10))

# Loss
classification_loss = CrossEntropy(rating_logits, true_rating_class)
total_loss = BPR_loss + lambda_rating * classification_loss
```

**ê¸°ëŒ€ íš¨ê³¼**:
- Ratingì˜ ordinal nature í™œìš©
- ë” ì •í™•í•œ rating ì˜ˆì¸¡ ê°€ëŠ¥
- **ì˜ˆìƒ F1**: 0.872 â†’ 0.885

#### 4. Negative Sampling ê³ ë„í™”
**ì•„ì´ë””ì–´**: Hard negative ë¹„ìœ¨ì„ ë™ì ìœ¼ë¡œ ì¡°ì •
```python
# Curriculum Learning: Easy â†’ Hard
hard_ratio = min(0.8, 0.2 + epoch / total_epochs * 0.6)

# Adaptive Hard Negative: Loss ë†’ì€ ê²ƒ ìœ„ì£¼ë¡œ
if loss > threshold:
    hard_ratio = 0.7  # More hard negatives
else:
    hard_ratio = 0.3  # Less hard negatives
```

**ê¸°ëŒ€ íš¨ê³¼**:
- í•™ìŠµ ì´ˆë°˜: Easy negativeë¡œ ì•ˆì •í™”
- í•™ìŠµ í›„ë°˜: Hard negativeë¡œ fine-tuning
- **ì˜ˆìƒ**: ìˆ˜ë ´ ì†ë„ +20%, ì„±ëŠ¥ +0.5%

---

## Part 3: Breakthrough Ideas (v3+ Level)

### Idea 1: Self-Supervised Auxiliary Tasks (ëŒ€í˜• ê°œì„  ğŸš€)

#### ì»¨ì…‰
**"User-item interaction ì™¸ì˜ ì‹ í˜¸ë¡œ representation ê°•í™”"**

#### êµ¬ì²´ì  ë°©ë²•
```python
# Task 1: User-User Similarity Prediction
# ë¹„ìŠ·í•œ ì·¨í–¥ì˜ user pairë¥¼ positiveë¡œ
similar_users = find_similar_users_by_jaccard(threshold=0.3)
loss_uu = contrastive_loss(user_emb[u1], user_emb[u2], label='similar')

# Task 2: Item-Item Co-occurrence Prediction
# ê°™ì€ userê°€ ë³¸ item pairë¥¼ positiveë¡œ
co_occur_items = find_co_occurrence_items()
loss_ii = contrastive_loss(item_emb[i1], item_emb[i2], label='co-occur')

# Task 3: Temporal Order Prediction (if timestamp available)
# Userê°€ item1 â†’ item2 ìˆœì„œë¡œ ë´¤ìœ¼ë©´ ê·¸ ìˆœì„œ í•™ìŠµ
loss_temp = temporal_order_loss(user, item1, item2)

# Total Loss
loss = BPR_loss + Î»1 * loss_uu + Î»2 * loss_ii + Î»3 * loss_temp
```

**ê¸°ëŒ€ íš¨ê³¼**:
- Rich representation learning
- Cold start ê°œì„  (ìƒˆ user/itemë„ similarityë¡œ ì¶”ë¡ )
- **ì˜ˆìƒ AUC**: +2% ~ 3%

**ë‚œì´ë„**: â­â­â­â­ (êµ¬í˜„ ë³µì¡, íš¨ê³¼ ë¶ˆí™•ì‹¤)

---

### Idea 2: Graph Structure Learning (ê·¸ë˜í”„ êµ¬ì¡° ê°œì„  ğŸš€)

#### í˜„ì¬ ë¬¸ì œ
- Graph = Train data edges only
- **ë¬¸ì œ**: Trainì— ì—†ëŠ” latent connection ë†“ì¹¨

#### ê°œì„  ë°©ë²•
**Learnable Edge Addition**: ìœ ì‚¬í•œ user/itemì— soft edge ì¶”ê°€
```python
# User similarity graph
user_sim = cosine_similarity(user_emb, user_emb)  # (n_users, n_users)
user_adj = (user_sim > threshold).float() * user_sim

# Item similarity graph
item_sim = cosine_similarity(item_emb, item_emb)
item_adj = (item_sim > threshold).float() * item_sim

# Augmented graph
edge_index_aug = concat([
    edge_index_original,
    user_user_edges,
    item_item_edges
])

# GNN on augmented graph
emb = LightGCN(edge_index_aug, edge_weight_aug)
```

**ê¸°ëŒ€ íš¨ê³¼**:
- Higher-order connectivity í™œìš©
- Long-tail item ì¶”ì²œ ê°œì„ 
- **ì˜ˆìƒ AUC**: +1% ~ 2%

**ë‚œì´ë„**: â­â­â­â­ (graph í¬ê¸° ì¦ê°€, ë©”ëª¨ë¦¬ ì´ìŠˆ)

---

### Idea 3: Multi-Task Learning (A + B ë™ì‹œ í•™ìŠµ ğŸš€)

#### ì»¨ì…‰
**"Binary classificationê³¼ Rating predictionì„ ë™ì‹œì— í•™ìŠµ"**

#### êµ¬í˜„
```python
class MultiTaskGNN(nn.Module):
    def __init__(self):
        self.shared_gnn = LightGCN(...)
        self.binary_head = MLP(emb_dim, 1)  # Binary
        self.rating_head = MLP(emb_dim, 1)  # Rating

    def forward(self, user, item):
        u_emb, i_emb = self.shared_gnn(edge_index, edge_weight)

        # Task 1: Binary
        binary_score = self.binary_head(u_emb[user] * i_emb[item])

        # Task 2: Rating
        rating_pred = self.rating_head(u_emb[user] * i_emb[item])

        return binary_score, rating_pred

# Loss
loss_binary = BPR_loss(binary_score_pos, binary_score_neg)
loss_rating = MSE_loss(rating_pred, rating_true)
total_loss = loss_binary + Î» * loss_rating
```

**ê¸°ëŒ€ íš¨ê³¼**:
- Shared representationì´ ë” ê°•ê±´í•´ì§
- Binaryì™€ Ratingì˜ ìƒí˜¸ ë³´ì™„
- **ì˜ˆìƒ**: ë‘ task ëª¨ë‘ +1% ~ 2%

**ì¥ì **: í•˜ë‚˜ì˜ ëª¨ë¸ë¡œ A/B ë‘ ì „ëµ ì»¤ë²„ ê°€ëŠ¥

**ë‚œì´ë„**: â­â­â­ (êµ¬í˜„ ì¤‘ê°„, íš¨ê³¼ ë†’ìŒ)

---

### Idea 4: Attention-based GNN (í‘œí˜„ë ¥ ê°•í™” ğŸš€)

#### í˜„ì¬ LightGCNì˜ í•œê³„
- ëª¨ë“  neighborë¥¼ ë™ë“±í•˜ê²Œ ì·¨ê¸‰ (degreeë¡œë§Œ normalize)
- **ë¬¸ì œ**: ì¤‘ìš”í•œ neighborì™€ ëœ ì¤‘ìš”í•œ neighbor êµ¬ë¶„ ëª»í•¨

#### GAT (Graph Attention Network) ë„ì…
```python
class LightGAT(nn.Module):
    def __init__(self):
        self.user_emb = nn.Embedding(n_users, emb_dim)
        self.item_emb = nn.Embedding(n_items, emb_dim)
        self.attn = nn.Linear(emb_dim * 2, 1)  # Attention

    def forward(self, edge_index, edge_weight):
        all_emb = concat([user_emb.weight, item_emb.weight])

        for layer in range(n_layers):
            # Compute attention weights
            row, col = edge_index
            alpha = softmax(self.attn(concat([all_emb[row], all_emb[col]])))

            # Weighted aggregation
            messages = all_emb[col] * alpha * edge_weight
            all_emb = scatter_add(messages, row, dim=0)

        return all_emb[:n_users], all_emb[n_users:]
```

**ê¸°ëŒ€ íš¨ê³¼**:
- Important neighborì— ë” ì§‘ì¤‘
- More expressive representation
- **ì˜ˆìƒ AUC**: +1% ~ 2%

**ë‹¨ì **:
- í•™ìŠµ ëŠë¦¼ (attention ê³„ì‚°)
- Overfitting ìœ„í—˜
- **ë‚œì´ë„**: â­â­â­â­

---

### Idea 5: Curriculum Learning (í•™ìŠµ ì „ëµ ê°œì„  ğŸš€)

#### ì»¨ì…‰
**"Easy examples â†’ Hard examples ìˆœì„œë¡œ í•™ìŠµ"**

#### êµ¬í˜„
```python
# Step 1: Easy/Hard ì •ì˜
def get_difficulty(user, item, rating):
    # Easy: Rating ê·¹ë‹¨ê°’ (0.5 ë˜ëŠ” 5.0)
    # Hard: Rating ì¤‘ê°„ê°’ (3.0, 3.5)
    return abs(rating - 3.0)

# Step 2: Curriculum schedule
def get_samples_for_epoch(epoch, total_epochs):
    if epoch < total_epochs * 0.3:
        # ì´ˆë°˜: Easyë§Œ
        return df[df['difficulty'] > 1.5]
    elif epoch < total_epochs * 0.6:
        # ì¤‘ë°˜: Easy + Medium
        return df[df['difficulty'] > 0.5]
    else:
        # í›„ë°˜: All
        return df
```

**ê¸°ëŒ€ íš¨ê³¼**:
- í•™ìŠµ ì´ˆë°˜ ì•ˆì •í™”
- Hard case ì„±ëŠ¥ í–¥ìƒ
- **ì˜ˆìƒ**: F1 +0.5% ~ 1%

**ë‚œì´ë„**: â­â­ (êµ¬í˜„ ì‰¬ì›€, íš¨ê³¼ ì¤‘ê°„)

---

### Idea 6: Ensemble with Diversity (ì•™ìƒë¸” ê°•í™” ğŸš€)

#### í˜„ì¬ ê³„íš
- CCA1 + CCB1 ë‹¨ìˆœ averaging

#### ê°œì„ : Diversity í™•ë³´
```python
# Model 1: CCA1 (emb_dim=32, layers=2)
# Model 2: CCB1 (emb_dim=32, layers=2)
# Model 3: CCA1 (emb_dim=64, layers=1)  # Different architecture
# Model 4: CCB1 (emb_dim=16, layers=3)  # Different architecture
# Model 5: GAT-based (emb_dim=32, layers=2, attention)

# Weighted ensemble
weights = [0.15, 0.30, 0.15, 0.25, 0.15]  # CCB1 highest
final_score = sum(w * model.predict() for w, model in zip(weights, models))
```

**ê¸°ëŒ€ íš¨ê³¼**:
- Errorì˜ independence ì¦ê°€ â†’ ensemble íš¨ê³¼ ê·¹ëŒ€í™”
- **ì˜ˆìƒ AUC**: +1% ~ 3%

**ë‚œì´ë„**: â­â­ (ëª¨ë¸ ì—¬ëŸ¬ê°œ í•™ìŠµ í•„ìš”)

---

### Idea 7: Cold Start Enhancement (ì‹¤ì „ ëŒ€ë¹„ ğŸš€)

#### ë¬¸ì œ ì¸ì‹
- í˜„ì¬: ëª¨ë“  userê°€ ì¶©ë¶„í•œ ë°ì´í„° (>10 interactions)
- **ì‹¤ì „**: ìƒˆ user/item ë“±ì¥ ê°€ëŠ¥

#### í•´ê²° ë°©ë²•
**Meta-Learning (MAML) ì ìš©**
```python
# Few-shot learning for new users
def adapt_to_new_user(new_user_interactions):
    # Step 1: Initialize with global model
    user_emb_init = model.user_emb.mean(dim=0)

    # Step 2: Few-shot adaptation (1-5 interactions)
    for _ in range(5):  # Inner loop
        loss = compute_loss(new_user_interactions)
        user_emb_new = user_emb_init - lr * grad(loss)

    return user_emb_new
```

**ê¸°ëŒ€ íš¨ê³¼**:
- ìƒˆ userë„ ë¹ ë¥´ê²Œ ì ì‘
- ì‹¤ì „ robustness ì¦ê°€

**ë‚œì´ë„**: â­â­â­â­â­ (ë§¤ìš° ì–´ë ¤ì›€, ìš°ë¦¬ ë°ì´í„°ì—ì„  ë¶ˆí•„ìš”)

---

### Idea 8: Rating Calibration with Debiasing (í¸í–¥ ì œê±° ğŸš€)

#### ê´€ì°°
- Userë§ˆë‹¤ rating í‰ê· ì´ ë‹¤ë¦„
  - User A: í‰ê·  4.5 (ê´€ëŒ€í•œ í‰ê°€)
  - User B: í‰ê·  2.5 (ì—„ê²©í•œ í‰ê°€)
- **ë¬¸ì œ**: Rating 4ê°€ userë§ˆë‹¤ ë‹¤ë¥¸ ì˜ë¯¸

#### í•´ê²°: Debiasing
```python
# User bias ê³„ì‚°
user_bias = df.groupby('user')['rating'].mean() - df['rating'].mean()

# Rating ì •ê·œí™”
df['rating_normalized'] = df['rating'] - df['user'].map(user_bias)

# í•™ìŠµ ì‹œ normalized rating ì‚¬ìš©
edge_weight = 0.4 + 0.15 * rating_normalized
```

**ê¸°ëŒ€ íš¨ê³¼**:
- Userê°„ ê³µì •í•œ ë¹„êµ
- Rating weighting ì •í™•ë„ í–¥ìƒ
- **ì˜ˆìƒ AUC**: +0.5% ~ 1%

**ë‚œì´ë„**: â­â­ (ì‰¬ì›€)

---

## Part 4: ìš°ì„ ìˆœìœ„ ë° ì‹¤í–‰ ê³„íš

### Tier 1 (ì¦‰ì‹œ ì‹¤í–‰, ë†’ì€ íš¨ê³¼/ë‚®ì€ ë‚œì´ë„) â­â­â­

#### CCA2
1. **Weighted BPR Loss** (Rating weight ë°˜ì˜)
   - ì˜ˆìƒ íš¨ê³¼: AUC +2% (0.89 â†’ 0.91)
   - ë‚œì´ë„: â­â­
   - ì‹œê°„: 1ì‹œê°„

2. **Rating Calibration** (User bias ì œê±°)
   - ì˜ˆìƒ íš¨ê³¼: AUC +0.5%
   - ë‚œì´ë„: â­
   - ì‹œê°„: 30ë¶„

#### CCB2
1. **Contrastive Learning** (Separation ê°•í™”)
   - ì˜ˆìƒ íš¨ê³¼: AUC +1% (0.927 â†’ 0.937)
   - ë‚œì´ë„: â­â­â­
   - ì‹œê°„: 2ì‹œê°„

2. **Uncertainty-Aware Prediction** (Sample2 ë¬¸ì œ í•´ê²°)
   - ì˜ˆìƒ íš¨ê³¼: Conservative but accurate
   - ë‚œì´ë„: â­â­
   - ì‹œê°„: 1ì‹œê°„

**ì˜ˆìƒ ê²°ê³¼**:
- CCA2: AUC 0.915 (í˜„ì¬ 0.889)
- CCB2: AUC 0.940 (í˜„ì¬ 0.927)

---

### Tier 2 (ì¤‘ê¸°, ì¤‘ê°„ íš¨ê³¼/ì¤‘ê°„ ë‚œì´ë„) â­â­

#### CCA3 / CCB3
1. **Multi-Task Learning** (Binary + Rating)
   - ì˜ˆìƒ íš¨ê³¼: +1% ~ 2%
   - ë‚œì´ë„: â­â­â­
   - ì‹œê°„: 3-4ì‹œê°„

2. **Curriculum Learning**
   - ì˜ˆìƒ íš¨ê³¼: +0.5% ~ 1%
   - ë‚œì´ë„: â­â­
   - ì‹œê°„: 1ì‹œê°„

3. **Dynamic Hard Negative Sampling**
   - ì˜ˆìƒ íš¨ê³¼: ìˆ˜ë ´ ì†ë„ +20%
   - ë‚œì´ë„: â­â­
   - ì‹œê°„: 1ì‹œê°„

**ì˜ˆìƒ ê²°ê³¼**:
- CCA3: AUC 0.925
- CCB3: AUC 0.950

---

### Tier 3 (ì¥ê¸°, ì—°êµ¬ ìˆ˜ì¤€) â­

1. **Graph Attention (GAT)**
   - ì˜ˆìƒ íš¨ê³¼: +1% ~ 2%
   - ë‚œì´ë„: â­â­â­â­
   - ì‹œê°„: 5-6ì‹œê°„

2. **Self-Supervised Learning**
   - ì˜ˆìƒ íš¨ê³¼: +2% ~ 3%
   - ë‚œì´ë„: â­â­â­â­
   - ì‹œê°„: 6-8ì‹œê°„

3. **Graph Structure Learning**
   - ì˜ˆìƒ íš¨ê³¼: +1% ~ 2%
   - ë‚œì´ë„: â­â­â­â­â­
   - ì‹œê°„: 8-10ì‹œê°„

---

## Part 5: ìµœì¢… ê¶Œì¥ ë¡œë“œë§µ

### Phase 1: Quick Wins (v2) - 1ì¼
```
CCA2:
âœ“ Weighted BPR Loss
âœ“ Rating Calibration
â†’ ëª©í‘œ: AUC 0.91

CCB2:
âœ“ Contrastive Learning
âœ“ Uncertainty Estimation
â†’ ëª©í‘œ: AUC 0.94
```

### Phase 2: Strategic Improvements (v3) - 2ì¼
```
âœ“ Multi-Task Learning (A+B í†µí•©)
âœ“ Curriculum Learning
âœ“ Advanced Negative Sampling
â†’ ëª©í‘œ: AUC 0.93 (A), 0.95 (B)
```

### Phase 3: Research-Level (v4+) - ì„ íƒì 
```
âœ“ GAT
âœ“ Self-Supervised
âœ“ Graph Structure Learning
â†’ ëª©í‘œ: SOTA (0.96+)
```

---

## Part 6: í‰ê°€ ê·œì¹™ ëŒ€ì‘ ì „ëµ

### "ì˜ëª»ëœ ì¶”ì²œì€ ê°ì " ëŒ€ì‘

#### Conservative ì „ëµ
```python
# Precision ìš°ì„  threshold
threshold_conservative = optimal_threshold * 1.15

# Uncertainty ê¸°ë°˜ í•„í„°ë§
if uncertainty > 0.3:
    return 'X'  # Don't recommend if uncertain

# Top-K ì œí•œ
K_conservative = max(2, int(K_optimal * 0.8))
```

#### Ensemble with Voting
```python
# ì—¬ëŸ¬ ëª¨ë¸ì´ ëª¨ë‘ Oì¼ ë•Œë§Œ O
votes = [model1.predict(), model2.predict(), model3.predict()]
if votes.count('O') >= 3:
    return 'O'
else:
    return 'X'
```

---

## Part 7: ì‹¤í—˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

### CCA2 ì‹¤í—˜
- [ ] Weighted BPR Loss êµ¬í˜„
- [ ] Rating Calibration êµ¬í˜„
- [ ] Baseline (CCA1) ëŒ€ë¹„ ì„±ëŠ¥ ë¹„êµ
- [ ] Sample í…ŒìŠ¤íŠ¸ (í˜•ì‹ í¬í•¨)
- [ ] Threshold ì¬íŠœë‹
- [ ] ë¬¸ì„œí™”

### CCB2 ì‹¤í—˜
- [ ] Contrastive Loss êµ¬í˜„
- [ ] MC Dropout Uncertainty êµ¬í˜„
- [ ] Baseline (CCB1) ëŒ€ë¹„ ì„±ëŠ¥ ë¹„êµ
- [ ] Sample2 ë¬¸ì œ í•´ê²° í™•ì¸
- [ ] Conservative mode í…ŒìŠ¤íŠ¸
- [ ] ë¬¸ì„œí™”

### ë¹„êµ ë¶„ì„
- [ ] CCA1 vs CCA2
- [ ] CCB1 vs CCB2
- [ ] CCA2 vs CCB2 (ìµœì¢… ì„ íƒ)
- [ ] Ensemble ì‹œë„
- [ ] ê²°ê³¼ ì‹œê°í™”

---

## ê²°ë¡ 

### í•µì‹¬ ì „ëµ
1. **Tier 1 ë¨¼ì € êµ¬í˜„** (Weighted BPR, Contrastive, Uncertainty)
2. **CCB2ì— ì§‘ì¤‘** (ì´ë¯¸ CCB1ì´ ìš°ìˆ˜í•˜ë¯€ë¡œ)
3. **Conservative ì „ëµ ì¤€ë¹„** (í‰ê°€ ê·œì¹™ ëŒ€ì‘)
4. **Ensemble ì¤€ë¹„** (ì—¬ëŸ¬ ëª¨ë¸ í•™ìŠµ)

### ì˜ˆìƒ ìµœì¢… ì„±ëŠ¥
- **CCA2**: AUC 0.91, F1 0.86
- **CCB2**: AUC 0.94, F1 0.88
- **Ensemble**: AUC 0.95+, F1 0.89+

### ì„±ê³µ ê°€ëŠ¥ì„±
- Tier 1: 90% (ê²€ì¦ëœ ë°©ë²•)
- Tier 2: 70% (íš¨ê³¼ ë¶ˆí™•ì‹¤)
- Tier 3: 50% (ì—°êµ¬ ìˆ˜ì¤€)

**ì¶”ì²œ**: Tier 1 â†’ Tier 2 ìˆœì„œë¡œ ì§„í–‰, Tier 3ëŠ” ì‹œê°„ ì—¬ìœ  ìˆì„ ë•Œë§Œ

---

**ë¬¸ì„œ ë²„ì „**: v1.0
**ìµœì¢… ìˆ˜ì •**: 2025-11-18
