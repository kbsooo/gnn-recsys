{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bab66bc1",
   "metadata": {},
   "source": [
    "# B버전 codexb2 (rating 활용: 이진 + 회귀)\n",
    "- 이진(label=rating>=4, 미관측 neg 미사용) + 회귀(pred->thres=4)\n",
    "- early stopping + 임계 최적화 + 규칙기반 평가 + 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455f8063",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATA_PATH = Path('../data/train.csv')\n",
    "MODEL_DIR = Path('../codex_models'); MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "SEED=42\n",
    "TRAIN_RATIO=0.8; VAL_RATIO=0.1\n",
    "EMBED_DIM=64\n",
    "HIDDEN=[64]\n",
    "LR=1e-3\n",
    "WEIGHT_DECAY=1e-5\n",
    "BATCH_SIZE=1024\n",
    "EPOCHS_BIN=20; EPOCHS_REG=30\n",
    "PATIENCE=5\n",
    "DEVICE='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "np.random.seed(SEED); torch.manual_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98278a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_interactions(path):\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "def encode_ids(df):\n",
    "    users = sorted(df['user'].unique()); items = sorted(df['item'].unique())\n",
    "    u2i={u:i for i,u in enumerate(users)}; it2i={v:i for i,v in enumerate(items)}\n",
    "    out=df.copy(); out['user_idx']=out['user'].map(u2i); out['item_idx']=out['item'].map(it2i)\n",
    "    return out, u2i, it2i\n",
    "\n",
    "def split_userwise(df, train_ratio=0.8, val_ratio=0.1, seed=42):\n",
    "    rng=np.random.default_rng(seed); trains=[]; vals=[]; tests=[]\n",
    "    for _, g in df.groupby('user_idx'):\n",
    "        idx=rng.permutation(len(g)); g=g.iloc[idx]; n=len(g); n_train=int(n*train_ratio); n_val=int(n*val_ratio)\n",
    "        trains.append(g.iloc[:n_train]); vals.append(g.iloc[n_train:n_train+n_val]); tests.append(g.iloc[n_train+n_val:])\n",
    "    return pd.concat(trains, ignore_index=True), pd.concat(vals, ignore_index=True), pd.concat(tests, ignore_index=True)\n",
    "\n",
    "def rule_k(count):\n",
    "    if count<=10: return max(2,1)\n",
    "    return max(int(np.floor(0.2*count)),1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a52f9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PairDataset(Dataset):\n",
    "    def __init__(self, df, label_col='label'):\n",
    "        self.users=df['user_idx'].to_numpy(); self.items=df['item_idx'].to_numpy(); self.labels=df[label_col].to_numpy().astype(np.float32)\n",
    "    def __len__(self): return len(self.users)\n",
    "    def __getitem__(self, idx):\n",
    "        return int(self.users[idx]), int(self.items[idx]), float(self.labels[idx])\n",
    "\n",
    "class MFClassifier(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embed_dim):\n",
    "        super().__init__(); self.u=nn.Embedding(num_users, embed_dim); self.i=nn.Embedding(num_items, embed_dim); nn.init.normal_(self.u.weight, std=0.1); nn.init.normal_(self.i.weight, std=0.1)\n",
    "    def forward(self, u, it):\n",
    "        return (self.u(u)*self.i(it)).sum(dim=1)\n",
    "\n",
    "class MFRegressor(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embed_dim):\n",
    "        super().__init__(); self.u=nn.Embedding(num_users, embed_dim); self.i=nn.Embedding(num_items, embed_dim); self.bias=nn.Parameter(torch.zeros(1)); nn.init.normal_(self.u.weight, std=0.1); nn.init.normal_(self.i.weight, std=0.1)\n",
    "    def forward(self, u, it):\n",
    "        return (self.u(u)*self.i(it)).sum(dim=1)+self.bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4314e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eval_binary(model, loader, device='cpu', thresholds=[0.5]):\n",
    "    model.eval(); ys=[]; ps=[]\n",
    "    with torch.no_grad():\n",
    "        for u,i,y in loader:\n",
    "            u=torch.tensor(u, device=device); i=torch.tensor(i, device=device)\n",
    "            prob=torch.sigmoid(model(u,i)).cpu().numpy(); ys.append(np.array(y)); ps.append(prob)\n",
    "    y_true=np.concatenate(ys); y_prob=np.concatenate(ps); metrics={'auc': roc_auc_score(y_true, y_prob)}\n",
    "    for th in thresholds:\n",
    "        y_pred=(y_prob>=th).astype(int)\n",
    "        metrics[f'f1@{th}']=f1_score(y_true, y_pred)\n",
    "        metrics[f'prec@{th}']=precision_score(y_true, y_pred)\n",
    "        metrics[f'recall@{th}']=recall_score(y_true, y_pred)\n",
    "    return metrics, y_true, y_prob\n",
    "\n",
    "def eval_reg(model, loader, device='cpu', threshold=4.0, clip_range=(0.5,5.0)):\n",
    "    model.eval(); ys=[]; ps=[]\n",
    "    with torch.no_grad():\n",
    "        for u,i,y in loader:\n",
    "            u=torch.tensor(u, device=device); i=torch.tensor(i, device=device)\n",
    "            pred=model(u,i).cpu().numpy(); ys.append(np.array(y)); ps.append(pred)\n",
    "    y_true=np.concatenate(ys); y_pred=np.concatenate(ps)\n",
    "    if clip_range:\n",
    "        lo,hi=clip_range; y_pred=np.clip(y_pred, lo, hi)\n",
    "    rmse=np.sqrt(mean_squared_error(y_true, y_pred)); mae=mean_absolute_error(y_true, y_pred)\n",
    "    y_bin=(y_true>=threshold).astype(int); y_hat=(y_pred>=threshold).astype(int)\n",
    "    f1=f1_score(y_bin, y_hat)\n",
    "    return {'rmse':rmse, 'mae':mae, f'f1@{threshold}':f1}, y_pred\n",
    "\n",
    "def thresholds_from_val(y_true, y_prob, n=5):\n",
    "    qs=np.linspace(0.3,0.7,n)\n",
    "    best_th=0.5; best_f1=0\n",
    "    for th in qs:\n",
    "        y_pred=(y_prob>=th).astype(int)\n",
    "        f1=f1_score(y_true, y_pred)\n",
    "        if f1>best_f1:\n",
    "            best_f1=f1; best_th=th\n",
    "    return best_th, best_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e88097",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 데이터 로드/라벨링\n",
    "df_raw = load_interactions(DATA_PATH)\n",
    "df_raw['label'] = (df_raw['rating']>=4).astype(int)\n",
    "df, user2idx, item2idx = encode_ids(df_raw)\n",
    "train_df, val_df, test_df = split_userwise(df, train_ratio=TRAIN_RATIO, val_ratio=VAL_RATIO, seed=SEED)\n",
    "num_users=len(user2idx); num_items=len(item2idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed537046",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 데이터로더 준비\n",
    "train_loader_bin = DataLoader(PairDataset(train_df, 'label'), batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader_bin = DataLoader(PairDataset(val_df, 'label'), batch_size=BATCH_SIZE)\n",
    "test_loader_bin = DataLoader(PairDataset(test_df, 'label'), batch_size=BATCH_SIZE)\n",
    "\n",
    "train_loader_reg = DataLoader(PairDataset(train_df.assign(label=train_df['rating'])), batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader_reg = DataLoader(PairDataset(val_df.assign(label=val_df['rating'])), batch_size=BATCH_SIZE)\n",
    "test_loader_reg = DataLoader(PairDataset(test_df.assign(label=test_df['rating'])), batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd89944",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 이진 학습 + early stopping + best threshold\n",
    "clf = MFClassifier(num_users, num_items, EMBED_DIM).to(DEVICE)\n",
    "opt = torch.optim.Adam(clf.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "best_auc=-1; patience=0; history_auc=[]; history_f1=[]; best_state=None; best_th=0.5\n",
    "for epoch in range(1, EPOCHS_BIN+1):\n",
    "    clf.train(); total=0.0\n",
    "    for u,i,y in train_loader_bin:\n",
    "        u=torch.tensor(u, device=DEVICE); i=torch.tensor(i, device=DEVICE); y=torch.tensor(y, device=DEVICE)\n",
    "        logit = clf(u,i); loss = nn.functional.binary_cross_entropy_with_logits(logit, y)\n",
    "        opt.zero_grad(); loss.backward(); opt.step(); total += loss.item()*u.shape[0]\n",
    "    metrics, y_true_val, y_prob_val = eval_binary(clf, val_loader_bin, device=DEVICE, thresholds=[0.5])\n",
    "    th_opt, f1_opt = thresholds_from_val(y_true_val, y_prob_val)\n",
    "    history_auc.append(metrics['auc']); history_f1.append(metrics['f1@0.5'])\n",
    "    if metrics['auc']>best_auc:\n",
    "        best_auc=metrics['auc']; best_state={k:v.cpu() if torch.is_tensor(v) else v for k,v in clf.state_dict().items()}; patience=0; best_th=th_opt\n",
    "    else:\n",
    "        patience+=1\n",
    "    print(f\"[BIN] epoch={epoch} loss={total/len(train_loader_bin.dataset):.4f} auc={metrics['auc']:.4f} f1@0.5={metrics['f1@0.5']:.4f} th_opt={th_opt:.2f} (patience {patience}/{PATIENCE})\")\n",
    "    if patience>=PATIENCE:\n",
    "        print('Early stopping bin'); break\n",
    "if best_state:\n",
    "    clf.load_state_dict(best_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14056275",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 회귀 학습 + early stopping\n",
    "reg = MFRegressor(num_users, num_items, EMBED_DIM).to(DEVICE)\n",
    "opt_r = torch.optim.Adam(reg.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "best_rmse=1e9; patience=0; hist_rmse=[]\n",
    "for epoch in range(1, EPOCHS_REG+1):\n",
    "    reg.train(); total=0.0\n",
    "    for u,i,y in train_loader_reg:\n",
    "        u=torch.tensor(u, device=DEVICE); i=torch.tensor(i, device=DEVICE); y=torch.tensor(y, device=DEVICE)\n",
    "        pred = reg(u,i); loss = nn.functional.mse_loss(pred, y)\n",
    "        opt_r.zero_grad(); loss.backward(); opt_r.step(); total += loss.item()*u.shape[0]\n",
    "    metrics, _ = eval_reg(reg, val_loader_reg, device=DEVICE, threshold=4.0)\n",
    "    hist_rmse.append(metrics['rmse'])\n",
    "    if metrics['rmse']<best_rmse:\n",
    "        best_rmse=metrics['rmse']; best_state={k:v.cpu() if torch.is_tensor(v) else v for k,v in reg.state_dict().items()}; patience=0\n",
    "    else:\n",
    "        patience+=1\n",
    "    print(f\"[REG] epoch={epoch} loss={total/len(train_loader_reg.dataset):.4f} rmse={metrics['rmse']:.4f} mae={metrics['mae']:.4f} f1@4={metrics['f1@4.0']:.4f} (patience {patience}/{PATIENCE})\")\n",
    "    if patience>=PATIENCE:\n",
    "        print('Early stopping reg'); break\n",
    "if best_state:\n",
    "    reg.load_state_dict(best_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e576dae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 평가 (test) - 이진\n",
    "metrics_val, y_true_val, y_prob_val = eval_binary(clf, val_loader_bin, device=DEVICE, thresholds=[best_th])\n",
    "metrics_test, y_true_test, y_prob_test = eval_binary(clf, test_loader_bin, device=DEVICE, thresholds=[best_th])\n",
    "print('BINARY VAL', metrics_val, 'best_th', best_th)\n",
    "print('BINARY TEST', metrics_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eff1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 평가 (test) - 회귀\n",
    "metrics_val_reg, _ = eval_reg(reg, val_loader_reg, device=DEVICE, threshold=4.0)\n",
    "metrics_test_reg, _ = eval_reg(reg, test_loader_reg, device=DEVICE, threshold=4.0)\n",
    "print('REG VAL', metrics_val_reg)\n",
    "print('REG TEST', metrics_test_reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99463dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.subplot(1,2,1); plt.plot(history_auc); plt.title('Bin Val AUC'); plt.xlabel('epoch')\n",
    "plt.subplot(1,2,2); plt.plot(hist_rmse); plt.title('Reg Val RMSE'); plt.xlabel('epoch')\n",
    "plt.tight_layout(); plt.savefig(MODEL_DIR/'codexb2_learning_curves.png'); plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b6f75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 체크포인트 저장\n",
    "torch.save({'state_dict': clf.state_dict(), 'num_users': num_users, 'num_items': num_items, 'embed_dim': EMBED_DIM, 'type':'binary', 'best_th': best_th}, MODEL_DIR/'codexb2_binary.pth')\n",
    "torch.save({'state_dict': reg.state_dict(), 'num_users': num_users, 'num_items': num_items, 'embed_dim': EMBED_DIM, 'type':'regression'}, MODEL_DIR/'codexb2_regression.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea54c58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 추론 유틸\n",
    "\n",
    "def predict_binary(model, user_enc, item_enc, csv_path: Path, threshold=0.5, return_prob=False):\n",
    "    df_in=pd.read_csv(csv_path)\n",
    "    users=df_in['user'].map(user_enc); items=df_in['item'].map(item_enc)\n",
    "    if users.isnull().any() or items.isnull().any():\n",
    "        raise ValueError('미등록 user/item')\n",
    "    u=torch.tensor(users.to_numpy(), device=DEVICE); i=torch.tensor(items.to_numpy(), device=DEVICE)\n",
    "    with torch.no_grad():\n",
    "        prob=torch.sigmoid(model(u,i)).cpu().numpy()\n",
    "    df_in['recommend']=np.where(prob>=threshold,'O','X')\n",
    "    if return_prob:\n",
    "        df_in['prob']=prob\n",
    "    total_o=df_in['recommend'].eq('O').sum(); total=len(df_in)\n",
    "    print(df_in)\n",
    "    print(f\"====================\n",
    "Total recommends = {total_o}/{total}\n",
    "Not recommend = {total-total_o}/{total}\")\n",
    "    return df_in\n",
    "\n",
    "def predict_reg(model, user_enc, item_enc, csv_path: Path, threshold=4.0, return_score=False):\n",
    "    df_in=pd.read_csv(csv_path)\n",
    "    users=df_in['user'].map(user_enc); items=df_in['item'].map(item_enc)\n",
    "    if users.isnull().any() or items.isnull().any():\n",
    "        raise ValueError('미등록 user/item')\n",
    "    u=torch.tensor(users.to_numpy(), device=DEVICE); i=torch.tensor(items.to_numpy(), device=DEVICE)\n",
    "    with torch.no_grad():\n",
    "        pred=model(u,i).cpu().numpy()\n",
    "    df_in['recommend']=np.where(pred>=threshold,'O','X')\n",
    "    if return_score:\n",
    "        df_in['score']=pred\n",
    "    total_o=df_in['recommend'].eq('O').sum(); total=len(df_in)\n",
    "    print(df_in)\n",
    "    print(f\"====================\n",
    "Total recommends = {total_o}/{total}\n",
    "Not recommend = {total-total_o}/{total}\")\n",
    "    return df_in\n",
    "\n",
    "# 예시\n",
    "# predict_binary(clf, user2idx, item2idx, Path('../data/sample1.csv'), threshold=best_th, return_prob=True)\n",
    "# predict_reg(reg, user2idx, item2idx, Path('../data/sample1.csv'), threshold=4.0, return_score=True)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}