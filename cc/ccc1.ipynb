{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCC1 - Combined Collaborative Approach (Two-Stage Filtering)\n",
    "\n",
    "## Strategy\n",
    "- **Stage 1 (CCA2)**: Filter candidates with high connection probability\n",
    "  - Use CCA2 model to score all items\n",
    "  - Select Top-K candidates per user\n",
    "- **Stage 2 (CCB2)**: Predict rating and filter by quality\n",
    "  - Use CCB2 model to predict rating for candidates\n",
    "  - Recommend if predicted_rating >= threshold\n",
    "- **Combine**: Only items passing both stages are recommended\n",
    "\n",
    "## Key Features:\n",
    "- ✅ Leverages both CCA2 (connection) and CCB2 (rating) models\n",
    "- ✅ No additional training needed (uses pretrained models)\n",
    "- ✅ Highly interpretable: clear two-stage decision process\n",
    "- ✅ Flexible: adjust CCA_TOP_K and CCB_THRESHOLD independently\n",
    "\n",
    "## Hyperparameters:\n",
    "- `CCA_TOP_K_CANDIDATES`: 100 (number of candidates from Stage 1)\n",
    "- `CCB_RATING_THRESHOLD`: 4.0 (minimum rating for recommendation)\n",
    "- `GOOD_RATING_THRESHOLD`: 4.0 (ground truth definition)\n",
    "\n",
    "## Expected Performance:\n",
    "- Better than CCA2: Stage 2 filters low-quality connections\n",
    "- Better than CCB2: Stage 1 focuses on realistic candidates\n",
    "- AUC-ROC target: 0.93+\n",
    "- F1 target: 0.87+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Device setup (CUDA > MPS > CPU)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f'Device: {device} ({torch.cuda.get_device_name()})')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(f'Device: {device}')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing\n",
    "\n",
    "### CCC1 Strategy:\n",
    "- Uses same data preprocessing as CCB (rating-based split)\n",
    "- Positive: Rating >= 4 (for evaluation)\n",
    "- Train on all interactions (for graph structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total interactions: 105,139\n",
      "Unique users: 668\n",
      "Unique items: 10321\n",
      "\n",
      "Rating distribution:\n",
      "rating\n",
      "0.5     1189\n",
      "1.0     3254\n",
      "1.5     1564\n",
      "2.0     7929\n",
      "2.5     5473\n",
      "3.0    21676\n",
      "3.5    12224\n",
      "4.0    28831\n",
      "4.5     8174\n",
      "5.0    14825\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Good purchases (rating >= 4.0): 51,830 (49.3%)\n",
      "\n",
      "Users: 668, Items: 10321\n",
      "Sparsity: 98.4750%\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/train.csv')\n",
    "\n",
    "print(f\"Total interactions: {len(df):,}\")\n",
    "print(f\"Unique users: {df['user'].nunique()}\")\n",
    "print(f\"Unique items: {df['item'].nunique()}\")\n",
    "print(f\"\\nRating distribution:\")\n",
    "print(df['rating'].value_counts().sort_index())\n",
    "\n",
    "# Define good purchases\n",
    "GOOD_RATING_THRESHOLD = 4.0\n",
    "n_good_purchases = (df['rating'] >= GOOD_RATING_THRESHOLD).sum()\n",
    "print(f\"\\nGood purchases (rating >= {GOOD_RATING_THRESHOLD}): {n_good_purchases:,} ({100*n_good_purchases/len(df):.1f}%)\")\n",
    "\n",
    "# ID mapping\n",
    "user2idx = {u: i for i, u in enumerate(sorted(df['user'].unique()))}\n",
    "item2idx = {it: i for i, it in enumerate(sorted(df['item'].unique()))}\n",
    "idx2user = {i: u for u, i in user2idx.items()}\n",
    "idx2item = {i: it for it, i in item2idx.items()}\n",
    "\n",
    "n_users, n_items = len(user2idx), len(item2idx)\n",
    "\n",
    "df['user_idx'] = df['user'].map(user2idx)\n",
    "df['item_idx'] = df['item'].map(item2idx)\n",
    "\n",
    "print(f\"\\nUsers: {n_users}, Items: {n_items}\")\n",
    "print(f\"Sparsity: {(1 - len(df) / (n_users * n_items)) * 100:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User K values statistics (MAX_K=100):\n",
      "  Min K: 4\n",
      "  Max K: 100\n",
      "  Mean K: 24.74\n",
      "  Median K: 14.00\n"
     ]
    }
   ],
   "source": [
    "# User별 interaction count 및 K값 계산\n",
    "user_interaction_count = df.groupby('user_idx').size().to_dict()\n",
    "\n",
    "MAX_K = 100\n",
    "\n",
    "def get_k_for_user(count):\n",
    "    \"\"\"User별 추천 개수 K 계산 (평가 규칙: 20% 이하 추천)\"\"\"\n",
    "    if count <= 10:\n",
    "        return 2\n",
    "    k = max(2, int(count * 0.2))\n",
    "    return min(k, MAX_K)\n",
    "\n",
    "user_k = {u: get_k_for_user(c) for u, c in user_interaction_count.items()}\n",
    "\n",
    "k_values = list(user_k.values())\n",
    "print(f\"User K values statistics (MAX_K={MAX_K}):\")\n",
    "print(f\"  Min K: {min(k_values)}\")\n",
    "print(f\"  Max K: {max(k_values)}\")\n",
    "print(f\"  Mean K: {np.mean(k_values):.2f}\")\n",
    "print(f\"  Median K: {np.median(k_values):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train/Val/Test Split\n",
    "\n",
    "### CCC1 Split (CCB-style):\n",
    "- **Good purchases (rating >= 4)**: Split into train/val/test (7:1.5:1.5)\n",
    "- **Poor purchases (rating < 4)**: All go to train\n",
    "- **Evaluation**: Only on rating >= 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train edges (all purchases for graph): 89,294\n",
      "Val edges (good purchases only): 7,480\n",
      "Test edges (good purchases only): 8,365\n",
      "\n",
      "Good purchases in Val/Test: 15,845 / 51,830 (30.6%)\n"
     ]
    }
   ],
   "source": [
    "# Train/Val/Test Split (70/15/15) - Rating-aware\n",
    "train_data, val_data, test_data = [], [], []\n",
    "\n",
    "for user_idx in range(n_users):\n",
    "    user_df = df[df['user_idx'] == user_idx]\n",
    "    \n",
    "    good_purchases = user_df[user_df['rating'] >= GOOD_RATING_THRESHOLD][['user_idx', 'item_idx', 'rating']]\n",
    "    bad_purchases = user_df[user_df['rating'] < GOOD_RATING_THRESHOLD][['user_idx', 'item_idx', 'rating']]\n",
    "    \n",
    "    if len(bad_purchases) > 0:\n",
    "        train_data.append(bad_purchases[['user_idx', 'item_idx']])\n",
    "    \n",
    "    n_good = len(good_purchases)\n",
    "    \n",
    "    if n_good >= 3:\n",
    "        good_purchases = good_purchases.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "        train_end = int(0.7 * n_good)\n",
    "        val_end = train_end + int(0.15 * n_good)\n",
    "        \n",
    "        train_end = max(1, train_end)\n",
    "        val_end = max(train_end + 1, val_end)\n",
    "        \n",
    "        train_data.append(good_purchases.iloc[:train_end][['user_idx', 'item_idx']])\n",
    "        val_data.append(good_purchases.iloc[train_end:val_end][['user_idx', 'item_idx']])\n",
    "        test_data.append(good_purchases.iloc[val_end:][['user_idx', 'item_idx']])\n",
    "    elif n_good == 2:\n",
    "        good_purchases = good_purchases.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "        train_data.append(good_purchases.iloc[:1][['user_idx', 'item_idx']])\n",
    "        val_data.append(good_purchases.iloc[1:][['user_idx', 'item_idx']])\n",
    "    elif n_good == 1:\n",
    "        train_data.append(good_purchases[['user_idx', 'item_idx']])\n",
    "\n",
    "train_df = pd.concat(train_data, ignore_index=True)\n",
    "val_df = pd.concat(val_data, ignore_index=True) if val_data else pd.DataFrame(columns=['user_idx', 'item_idx'])\n",
    "test_df = pd.concat(test_data, ignore_index=True) if test_data else pd.DataFrame(columns=['user_idx', 'item_idx'])\n",
    "\n",
    "print(f\"Train edges (all purchases for graph): {len(train_df):,}\")\n",
    "print(f\"Val edges (good purchases only): {len(val_df):,}\")\n",
    "print(f\"Test edges (good purchases only): {len(test_df):,}\")\n",
    "\n",
    "n_val_test = len(val_df) + len(test_df)\n",
    "print(f\"\\nGood purchases in Val/Test: {n_val_test:,} / {n_good_purchases:,} ({100*n_val_test/n_good_purchases:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User train items dictionary ready: 668 users\n"
     ]
    }
   ],
   "source": [
    "# User가 train에서 선택한 items (추천 시 제외용)\n",
    "user_train_items = defaultdict(set)\n",
    "for u, i in zip(train_df['user_idx'].values, train_df['item_idx'].values):\n",
    "    user_train_items[int(u)].add(int(i))\n",
    "\n",
    "print(f\"User train items dictionary ready: {len(user_train_items)} users\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Pretrained Models\n",
    "\n",
    "### Load CCA2 and CCB2:\n",
    "- **CCA2**: For connection probability (Stage 1)\n",
    "- **CCB2**: For rating prediction (Stage 2)\n",
    "- Both models use same graph structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model classes defined\n"
     ]
    }
   ],
   "source": [
    "# Model definitions (copy from CCA2 and CCB2)\n",
    "\n",
    "class LightGCN(nn.Module):\n",
    "    \"\"\"LightGCN for CCA2 (connection prediction)\"\"\"\n",
    "    def __init__(self, n_users, n_items, emb_dim=64, n_layers=2):\n",
    "        super().__init__()\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.emb_dim = emb_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.user_emb = nn.Embedding(n_users, emb_dim)\n",
    "        self.item_emb = nn.Embedding(n_items, emb_dim)\n",
    "        nn.init.xavier_uniform_(self.user_emb.weight)\n",
    "        nn.init.xavier_uniform_(self.item_emb.weight)\n",
    "    \n",
    "    def forward(self, edge_index, edge_weight):\n",
    "        all_emb = torch.cat([self.user_emb.weight, self.item_emb.weight], dim=0)\n",
    "        embs = [all_emb]\n",
    "        \n",
    "        for _ in range(self.n_layers):\n",
    "            row, col = edge_index\n",
    "            messages = all_emb[col] * edge_weight.unsqueeze(1)\n",
    "            all_emb = torch.zeros_like(all_emb).scatter_add(\n",
    "                0, row.unsqueeze(1).expand(-1, self.emb_dim), messages\n",
    "            )\n",
    "            embs.append(all_emb)\n",
    "        \n",
    "        final_emb = torch.mean(torch.stack(embs), dim=0)\n",
    "        return final_emb[:self.n_users], final_emb[self.n_users:]\n",
    "\n",
    "\n",
    "class LightGCN_with_Rating(nn.Module):\n",
    "    \"\"\"LightGCN with Rating Head for CCB2 (rating prediction)\"\"\"\n",
    "    def __init__(self, n_users, n_items, emb_dim=64, n_layers=2):\n",
    "        super().__init__()\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.emb_dim = emb_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.user_emb = nn.Embedding(n_users, emb_dim)\n",
    "        self.item_emb = nn.Embedding(n_items, emb_dim)\n",
    "        nn.init.xavier_uniform_(self.user_emb.weight)\n",
    "        nn.init.xavier_uniform_(self.item_emb.weight)\n",
    "        \n",
    "        self.rating_mlp = nn.Sequential(\n",
    "            nn.Linear(emb_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, edge_index, edge_weight):\n",
    "        all_emb = torch.cat([self.user_emb.weight, self.item_emb.weight], dim=0)\n",
    "        embs = [all_emb]\n",
    "        \n",
    "        for _ in range(self.n_layers):\n",
    "            row, col = edge_index\n",
    "            messages = all_emb[col] * edge_weight.unsqueeze(1)\n",
    "            all_emb = torch.zeros_like(all_emb).scatter_add(\n",
    "                0, row.unsqueeze(1).expand(-1, self.emb_dim), messages\n",
    "            )\n",
    "            embs.append(all_emb)\n",
    "        \n",
    "        final_emb = torch.mean(torch.stack(embs), dim=0)\n",
    "        return final_emb[:self.n_users], final_emb[self.n_users:]\n",
    "    \n",
    "    def predict_rating(self, user_idx, item_idx, edge_index, edge_weight):\n",
    "        u_emb, i_emb = self.forward(edge_index, edge_weight)\n",
    "        interaction = u_emb[user_idx] * i_emb[item_idx]\n",
    "        rating_logit = self.rating_mlp(interaction).squeeze(-1)\n",
    "        predicted_rating = torch.sigmoid(rating_logit) * 4.5 + 0.5\n",
    "        return predicted_rating\n",
    "\n",
    "\n",
    "print(\"Model classes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCA Graph (unweighted): 178,588 edges\n",
      "CCB Graph (rating-weighted): 178,588 edges\n"
     ]
    }
   ],
   "source": [
    "# Build graphs for both models\n",
    "\n",
    "def build_unweighted_graph():\n",
    "    \"\"\"Unweighted graph for CCA2\"\"\"\n",
    "    users = train_df['user_idx'].values\n",
    "    items = train_df['item_idx'].values\n",
    "    \n",
    "    edge_u2i = np.array([users, items + n_users])\n",
    "    edge_i2u = np.array([items + n_users, users])\n",
    "    edge_index = torch.LongTensor(np.concatenate([edge_u2i, edge_i2u], axis=1))\n",
    "    \n",
    "    num_nodes = n_users + n_items\n",
    "    deg = torch.zeros(num_nodes).scatter_add(0, edge_index[0], torch.ones(edge_index.shape[1]))\n",
    "    deg_inv_sqrt = deg.pow(-0.5)\n",
    "    deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "    \n",
    "    edge_weight = deg_inv_sqrt[edge_index[0]] * deg_inv_sqrt[edge_index[1]]\n",
    "    \n",
    "    return edge_index.to(device), edge_weight.to(device)\n",
    "\n",
    "\n",
    "def build_rating_weighted_graph():\n",
    "    \"\"\"Rating weighted graph for CCB2\"\"\"\n",
    "    users = train_df['user_idx'].values\n",
    "    items = train_df['item_idx'].values\n",
    "    \n",
    "    ratings = []\n",
    "    for u, i in zip(users, items):\n",
    "        rating = df[(df['user_idx'] == u) & (df['item_idx'] == i)]['rating'].values\n",
    "        ratings.append(rating[0] if len(rating) > 0 else 3)\n",
    "    ratings = np.array(ratings)\n",
    "    \n",
    "    rating_factors = 0.4 + 0.15 * ratings\n",
    "    \n",
    "    edge_u2i = np.array([users, items + n_users])\n",
    "    edge_i2u = np.array([items + n_users, users])\n",
    "    edge_index = torch.LongTensor(np.concatenate([edge_u2i, edge_i2u], axis=1))\n",
    "    \n",
    "    rating_factors_both = np.concatenate([rating_factors, rating_factors])\n",
    "    \n",
    "    num_nodes = n_users + n_items\n",
    "    deg = torch.zeros(num_nodes).scatter_add(0, edge_index[0], torch.ones(edge_index.shape[1]))\n",
    "    deg_inv_sqrt = deg.pow(-0.5)\n",
    "    deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "    \n",
    "    base_weight = deg_inv_sqrt[edge_index[0]] * deg_inv_sqrt[edge_index[1]]\n",
    "    rating_weight = torch.FloatTensor(rating_factors_both)\n",
    "    edge_weight = base_weight * rating_weight\n",
    "    \n",
    "    return edge_index.to(device), edge_weight.to(device)\n",
    "\n",
    "\n",
    "# Build both graphs\n",
    "cca_edge_index, cca_edge_weight = build_unweighted_graph()\n",
    "ccb_edge_index, ccb_edge_weight = build_rating_weighted_graph()\n",
    "\n",
    "print(f\"CCA Graph (unweighted): {cca_edge_index.shape[1]:,} edges\")\n",
    "print(f\"CCB Graph (rating-weighted): {ccb_edge_index.shape[1]:,} edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ CCA2 model loaded from ../cc_models/cca2_best.pt\n",
      "✓ CCB2 model loaded from ../cc_models/ccb2_best.pt\n",
      "\n",
      "Both models ready for Two-Stage inference!\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained models\n",
    "\n",
    "EMB_DIM = 32\n",
    "N_LAYERS = 2\n",
    "\n",
    "# CCA2 model\n",
    "cca_model = LightGCN(n_users, n_items, EMB_DIM, N_LAYERS).to(device)\n",
    "cca_model.load_state_dict(torch.load('../cc_models/cca2_best.pt'))\n",
    "cca_model.eval()\n",
    "print(f\"✓ CCA2 model loaded from ../cc_models/cca2_best.pt\")\n",
    "\n",
    "# CCB2 model\n",
    "ccb_model = LightGCN_with_Rating(n_users, n_items, EMB_DIM, N_LAYERS).to(device)\n",
    "ccb_model.load_state_dict(torch.load('../cc_models/ccb2_best.pt'))\n",
    "ccb_model.eval()\n",
    "print(f\"✓ CCB2 model loaded from ../cc_models/ccb2_best.pt\")\n",
    "\n",
    "print(f\"\\nBoth models ready for Two-Stage inference!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Two-Stage Recommendation\n",
    "\n",
    "### Implementation:\n",
    "```\n",
    "Stage 1 (CCA2):\n",
    "  - Score all candidate items with CCA model\n",
    "  - Select Top-K candidates (CCA_TOP_K_CANDIDATES)\n",
    "\n",
    "Stage 2 (CCB2):\n",
    "  - Predict rating for each candidate with CCB model\n",
    "  - Recommend if predicted_rating >= CCB_RATING_THRESHOLD\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-Stage Hyperparameters:\n",
      "  Stage 1 (CCA): Top-100 candidates\n",
      "  Stage 2 (CCB): Rating >= 4.0\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters for Two-Stage\n",
    "CCA_TOP_K_CANDIDATES = 100  # Stage 1: Top-K from CCA\n",
    "CCB_RATING_THRESHOLD = 4.0  # Stage 2: Rating threshold for CCB\n",
    "\n",
    "print(f\"Two-Stage Hyperparameters:\")\n",
    "print(f\"  Stage 1 (CCA): Top-{CCA_TOP_K_CANDIDATES} candidates\")\n",
    "print(f\"  Stage 2 (CCB): Rating >= {CCB_RATING_THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-Stage prediction function ready!\n"
     ]
    }
   ],
   "source": [
    "def predict_two_stage(test_input_df, cca_top_k=100, ccb_threshold=4.0, verbose=True, show_details=False):\n",
    "    \"\"\"\n",
    "    ★ CCC1: Two-Stage Recommendation\n",
    "    \n",
    "    Stage 1 (CCA): Filter candidates by connection probability\n",
    "    Stage 2 (CCB): Filter by predicted rating quality\n",
    "    \n",
    "    Args:\n",
    "        test_input_df: Test data (user, item columns)\n",
    "        cca_top_k: Number of candidates from Stage 1\n",
    "        ccb_threshold: Rating threshold for Stage 2\n",
    "        verbose: Print AGENTS.md format\n",
    "        show_details: Show Stage 1/2 decisions\n",
    "    \n",
    "    Returns:\n",
    "        results_df: DataFrame with recommendations\n",
    "    \"\"\"\n",
    "    cca_model.eval()\n",
    "    ccb_model.eval()\n",
    "    \n",
    "    # Get embeddings\n",
    "    with torch.no_grad():\n",
    "        cca_u_emb, cca_i_emb = cca_model(cca_edge_index, cca_edge_weight)\n",
    "    \n",
    "    results = []\n",
    "    stats = {\n",
    "        'total_o': 0, \n",
    "        'total_items': 0,\n",
    "        'stage1_pass': 0,\n",
    "        'stage2_pass': 0\n",
    "    }\n",
    "\n",
    "    for user in test_input_df['user'].unique():\n",
    "        if user not in user2idx:\n",
    "            # Unknown user: all X\n",
    "            user_rows = test_input_df[test_input_df['user'] == user]\n",
    "            for _, row in user_rows.iterrows():\n",
    "                results.append({\n",
    "                    'user': row['user'], \n",
    "                    'item': row['item'], \n",
    "                    'recommend': 'X',\n",
    "                    'stage': 'unknown_user'\n",
    "                })\n",
    "                stats['total_items'] += 1\n",
    "            continue\n",
    "\n",
    "        user_idx = user2idx[user]\n",
    "        user_rows = test_input_df[test_input_df['user'] == user]\n",
    "        train_items_set = user_train_items[user_idx]\n",
    "\n",
    "        # Stage 1: CCA - Get Top-K candidates\n",
    "        candidate_items = [i for i in range(n_items) if i not in train_items_set]\n",
    "        \n",
    "        if len(candidate_items) == 0:\n",
    "            for _, row in user_rows.iterrows():\n",
    "                results.append({\n",
    "                    'user': user,\n",
    "                    'item': row['item'],\n",
    "                    'recommend': 'X',\n",
    "                    'stage': 'no_candidates'\n",
    "                })\n",
    "                stats['total_items'] += 1\n",
    "            continue\n",
    "        \n",
    "        # Score all candidates with CCA\n",
    "        candidate_tensor = torch.LongTensor(candidate_items).to(device)\n",
    "        user_tensor = torch.full((len(candidate_items),), user_idx, dtype=torch.long, device=device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            cca_scores = (cca_u_emb[user_tensor] * cca_i_emb[candidate_tensor]).sum(dim=1).cpu().numpy()\n",
    "        \n",
    "        # Select Top-K from CCA\n",
    "        K = min(cca_top_k, len(candidate_items))\n",
    "        top_k_indices = np.argsort(cca_scores)[-K:]\n",
    "        stage1_candidates = {candidate_items[idx]: cca_scores[idx] for idx in top_k_indices}\n",
    "        \n",
    "        # Process test items\n",
    "        for _, row in user_rows.iterrows():\n",
    "            item = row['item']\n",
    "            stats['total_items'] += 1\n",
    "            \n",
    "            # Check unknown item or train item\n",
    "            if item not in item2idx:\n",
    "                results.append({\n",
    "                    'user': user,\n",
    "                    'item': item,\n",
    "                    'recommend': 'X',\n",
    "                    'stage': 'unknown_item'\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            item_idx = item2idx[item]\n",
    "            \n",
    "            if item_idx in train_items_set:\n",
    "                results.append({\n",
    "                    'user': user,\n",
    "                    'item': item,\n",
    "                    'recommend': 'X',\n",
    "                    'stage': 'in_train'\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # Stage 1: Check if in Top-K from CCA\n",
    "            if item_idx not in stage1_candidates:\n",
    "                results.append({\n",
    "                    'user': user,\n",
    "                    'item': item,\n",
    "                    'recommend': 'X',\n",
    "                    'stage': 'stage1_filtered'\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            stats['stage1_pass'] += 1\n",
    "            \n",
    "            # Stage 2: CCB - Predict rating\n",
    "            user_tensor = torch.tensor([user_idx], dtype=torch.long).to(device)\n",
    "            item_tensor = torch.tensor([item_idx], dtype=torch.long).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                pred_rating = ccb_model.predict_rating(\n",
    "                    user_tensor, item_tensor,\n",
    "                    ccb_edge_index, ccb_edge_weight\n",
    "                ).item()\n",
    "            \n",
    "            # Stage 2: Check rating threshold\n",
    "            if pred_rating >= ccb_threshold:\n",
    "                recommend = 'O'\n",
    "                stats['total_o'] += 1\n",
    "                stats['stage2_pass'] += 1\n",
    "                stage = 'both_pass'\n",
    "            else:\n",
    "                recommend = 'X'\n",
    "                stage = 'stage2_filtered'\n",
    "            \n",
    "            results.append({\n",
    "                'user': user,\n",
    "                'item': item,\n",
    "                'recommend': recommend,\n",
    "                'stage': stage,\n",
    "                'cca_score': stage1_candidates[item_idx],\n",
    "                'ccb_rating': pred_rating\n",
    "            })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Print results\n",
    "    if verbose:\n",
    "        print(\"=\" * 70)\n",
    "        if show_details:\n",
    "            print(f\"{'user':<10} {'item':<10} {'CCA_score':<12} {'CCB_rating':<12} {'recommend':<10} {'stage':<15}\")\n",
    "            for _, row in results_df.iterrows():\n",
    "                cca_s = f\"{row.get('cca_score', 0):.4f}\" if 'cca_score' in row else 'N/A'\n",
    "                ccb_r = f\"{row.get('ccb_rating', 0):.2f}\" if 'ccb_rating' in row else 'N/A'\n",
    "                print(f\"{row['user']:<10} {row['item']:<10} {cca_s:<12} {ccb_r:<12} {row['recommend']:<10} {row['stage']:<15}\")\n",
    "        else:\n",
    "            print(f\"{'user':<10} {'item':<10} {'recommend':<10}\")\n",
    "            for _, row in results_df.iterrows():\n",
    "                print(f\"{row['user']:<10} {row['item']:<10} {row['recommend']:<10}\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"Total recommends = {stats['total_o']}/{stats['total_items']}\")\n",
    "        print(f\"Not recommend = {stats['total_items'] - stats['total_o']}/{stats['total_items']}\")\n",
    "        print(f\"\\nTwo-Stage Statistics:\")\n",
    "        print(f\"  Stage 1 pass rate: {stats['stage1_pass']}/{stats['total_items']} ({100*stats['stage1_pass']/stats['total_items']:.1f}%)\")\n",
    "        print(f\"  Stage 2 pass rate: {stats['stage2_pass']}/{stats['stage1_pass']} ({100*stats['stage2_pass']/stats['stage1_pass']:.1f}% of Stage 1)\")\n",
    "        print()\n",
    "\n",
    "    return results_df\n",
    "\n",
    "\n",
    "print(\"Two-Stage prediction function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sample Prediction Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample1.csv Test (CCC1 - Two-Stage):\n",
      "Stage 1 (CCA): Top-100 candidates\n",
      "Stage 2 (CCB): Rating >= 4.0\n",
      "\n",
      "Predictions with details:\n",
      "======================================================================\n",
      "user       item       CCA_score    CCB_rating   recommend  stage          \n",
      "109        3745       nan          nan          X          stage1_filtered\n",
      "88         4447       nan          nan          X          stage1_filtered\n",
      "71         4306       1.8564       4.73         O          both_pass      \n",
      "66         1747       1.6747       3.45         X          stage2_filtered\n",
      "15         66934      nan          nan          X          stage1_filtered\n",
      "======================================================================\n",
      "Total recommends = 1/5\n",
      "Not recommend = 4/5\n",
      "\n",
      "Two-Stage Statistics:\n",
      "  Stage 1 pass rate: 2/5 (40.0%)\n",
      "  Stage 2 pass rate: 1/2 (50.0% of Stage 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with sample1.csv\n",
    "sample1 = pd.read_csv('../data/sample1.csv')\n",
    "\n",
    "print(\"Sample1.csv Test (CCC1 - Two-Stage):\")\n",
    "print(f\"Stage 1 (CCA): Top-{CCA_TOP_K_CANDIDATES} candidates\")\n",
    "print(f\"Stage 2 (CCB): Rating >= {CCB_RATING_THRESHOLD}\")\n",
    "print()\n",
    "print(\"Predictions with details:\")\n",
    "predictions1 = predict_two_stage(sample1, CCA_TOP_K_CANDIDATES, CCB_RATING_THRESHOLD, verbose=True, show_details=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample2.csv Test (CCC1 - Two-Stage):\n",
      "Stage 1 (CCA): Top-100 candidates\n",
      "Stage 2 (CCB): Rating >= 4.0\n",
      "\n",
      "Predictions with details:\n",
      "======================================================================\n",
      "user       item       CCA_score    CCB_rating   recommend  stage          \n",
      "109        3745.0     nan          nan          X          stage1_filtered\n",
      "88         4447.0     nan          nan          X          stage1_filtered\n",
      "71         4306.0     1.8564       4.73         O          both_pass      \n",
      "66         1747.0     1.6747       3.45         X          stage2_filtered\n",
      "15         66934.0    nan          nan          X          stage1_filtered\n",
      "======================================================================\n",
      "Total recommends = 1/5\n",
      "Not recommend = 4/5\n",
      "\n",
      "Two-Stage Statistics:\n",
      "  Stage 1 pass rate: 2/5 (40.0%)\n",
      "  Stage 2 pass rate: 1/2 (50.0% of Stage 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with sample2.csv\n",
    "sample2 = pd.read_csv('../data/sample2.csv')\n",
    "\n",
    "print(\"Sample2.csv Test (CCC1 - Two-Stage):\")\n",
    "print(f\"Stage 1 (CCA): Top-{CCA_TOP_K_CANDIDATES} candidates\")\n",
    "print(f\"Stage 2 (CCB): Rating >= {CCB_RATING_THRESHOLD}\")\n",
    "print()\n",
    "print(\"Predictions with details:\")\n",
    "predictions2 = predict_two_stage(sample2, CCA_TOP_K_CANDIDATES, CCB_RATING_THRESHOLD, verbose=True, show_details=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Validation Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set: 7480 samples\n",
      "\n",
      "\n",
      "Validation Performance (CCC1 - Two-Stage):\n",
      "  Accuracy: 0.2136\n",
      "  Precision: 1.0000\n",
      "  Recall: 0.2136\n",
      "  F1 Score: 0.3521\n",
      "  O ratio: 21.4%\n"
     ]
    }
   ],
   "source": [
    "# Convert val_df to test format\n",
    "val_test_df = val_df.copy()\n",
    "val_test_df['user'] = val_test_df['user_idx'].map(idx2user)\n",
    "val_test_df['item'] = val_test_df['item_idx'].map(idx2item)\n",
    "val_test_df = val_test_df[['user', 'item']]\n",
    "\n",
    "print(f\"Evaluating on validation set: {len(val_test_df)} samples\")\n",
    "print()\n",
    "\n",
    "val_predictions = predict_two_stage(val_test_df, CCA_TOP_K_CANDIDATES, CCB_RATING_THRESHOLD, verbose=False)\n",
    "\n",
    "# All items in val are positive (rating >= 4)\n",
    "val_labels = np.ones(len(val_predictions))\n",
    "val_preds = (val_predictions['recommend'] == 'O').astype(int).values\n",
    "\n",
    "val_acc = (val_preds == val_labels).mean()\n",
    "val_prec = precision_score(val_labels, val_preds, zero_division=0)\n",
    "val_rec = recall_score(val_labels, val_preds, zero_division=0)\n",
    "val_f1 = f1_score(val_labels, val_preds, zero_division=0)\n",
    "\n",
    "print(f\"\\nValidation Performance (CCC1 - Two-Stage):\")\n",
    "print(f\"  Accuracy: {val_acc:.4f}\")\n",
    "print(f\"  Precision: {val_prec:.4f}\")\n",
    "print(f\"  Recall: {val_rec:.4f}\")\n",
    "print(f\"  F1 Score: {val_f1:.4f}\")\n",
    "print(f\"  O ratio: {val_preds.mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set: 8365 samples\n",
      "\n",
      "\n",
      "Test Performance (CCC1 - Two-Stage):\n",
      "  Accuracy: 0.2245\n",
      "  Precision: 1.0000\n",
      "  Recall: 0.2245\n",
      "  F1 Score: 0.3667\n",
      "  O ratio: 22.5%\n"
     ]
    }
   ],
   "source": [
    "# Convert test_df to test format\n",
    "test_test_df = test_df.copy()\n",
    "test_test_df['user'] = test_test_df['user_idx'].map(idx2user)\n",
    "test_test_df['item'] = test_test_df['item_idx'].map(idx2item)\n",
    "test_test_df = test_test_df[['user', 'item']]\n",
    "\n",
    "print(f\"Evaluating on test set: {len(test_test_df)} samples\")\n",
    "print()\n",
    "\n",
    "test_predictions = predict_two_stage(test_test_df, CCA_TOP_K_CANDIDATES, CCB_RATING_THRESHOLD, verbose=False)\n",
    "\n",
    "# All items in test are positive (rating >= 4)\n",
    "test_labels = np.ones(len(test_predictions))\n",
    "test_preds = (test_predictions['recommend'] == 'O').astype(int).values\n",
    "\n",
    "test_acc = (test_preds == test_labels).mean()\n",
    "test_prec = precision_score(test_labels, test_preds, zero_division=0)\n",
    "test_rec = recall_score(test_labels, test_preds, zero_division=0)\n",
    "test_f1 = f1_score(test_labels, test_preds, zero_division=0)\n",
    "\n",
    "print(f\"\\nTest Performance (CCC1 - Two-Stage):\")\n",
    "print(f\"  Accuracy: {test_acc:.4f}\")\n",
    "print(f\"  Precision: {test_prec:.4f}\")\n",
    "print(f\"  Recall: {test_rec:.4f}\")\n",
    "print(f\"  F1 Score: {test_f1:.4f}\")\n",
    "print(f\"  O ratio: {test_preds.mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Full AUC-ROC Evaluation\n",
    "\n",
    "To calculate AUC-ROC properly, we need positive and negative samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating AUC-ROC with negative samples...\n",
      "\n",
      "Validation AUC-ROC: 0.9562\n",
      "  Positive scores: mean=1.0583, std=0.3497\n",
      "  Negative scores: mean=0.2677, std=0.2316\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating AUC-ROC with negative samples...\")\n",
    "\n",
    "# Positive samples: validation good purchases\n",
    "val_pos_users = val_df['user_idx'].values\n",
    "val_pos_items = val_df['item_idx'].values\n",
    "\n",
    "# Negative samples: random non-interactions\n",
    "val_test_edges = set()\n",
    "for u, i in zip(val_df['user_idx'].values, val_df['item_idx'].values):\n",
    "    val_test_edges.add((int(u), int(i)))\n",
    "for u, i in zip(test_df['user_idx'].values, test_df['item_idx'].values):\n",
    "    val_test_edges.add((int(u), int(i)))\n",
    "\n",
    "n_neg = len(val_df)\n",
    "neg_users, neg_items = [], []\n",
    "attempts = 0\n",
    "max_attempts = n_neg * 100\n",
    "\n",
    "while len(neg_users) < n_neg and attempts < max_attempts:\n",
    "    u = np.random.randint(0, n_users)\n",
    "    i = np.random.randint(0, n_items)\n",
    "    attempts += 1\n",
    "    \n",
    "    if i not in user_train_items[u] and (u, i) not in val_test_edges:\n",
    "        neg_users.append(u)\n",
    "        neg_items.append(i)\n",
    "\n",
    "# Score positive samples\n",
    "pos_scores = []\n",
    "cca_u_emb, cca_i_emb = cca_model(cca_edge_index, cca_edge_weight)\n",
    "\n",
    "for u_idx, i_idx in zip(val_pos_users, val_pos_items):\n",
    "    # Stage 1: CCA score\n",
    "    with torch.no_grad():\n",
    "        cca_score = (cca_u_emb[u_idx] * cca_i_emb[i_idx]).sum().item()\n",
    "    \n",
    "    # Stage 2: CCB rating (combine as final score)\n",
    "    with torch.no_grad():\n",
    "        u_t = torch.tensor([u_idx], dtype=torch.long).to(device)\n",
    "        i_t = torch.tensor([i_idx], dtype=torch.long).to(device)\n",
    "        ccb_rating = ccb_model.predict_rating(u_t, i_t, ccb_edge_index, ccb_edge_weight).item()\n",
    "    \n",
    "    # Combined score (normalized)\n",
    "    combined_score = 0.5 * cca_score + 0.5 * (ccb_rating / 5.0)\n",
    "    pos_scores.append(combined_score)\n",
    "\n",
    "# Score negative samples\n",
    "neg_scores = []\n",
    "for u_idx, i_idx in zip(neg_users, neg_items):\n",
    "    with torch.no_grad():\n",
    "        cca_score = (cca_u_emb[u_idx] * cca_i_emb[i_idx]).sum().item()\n",
    "        u_t = torch.tensor([u_idx], dtype=torch.long).to(device)\n",
    "        i_t = torch.tensor([i_idx], dtype=torch.long).to(device)\n",
    "        ccb_rating = ccb_model.predict_rating(u_t, i_t, ccb_edge_index, ccb_edge_weight).item()\n",
    "    \n",
    "    combined_score = 0.5 * cca_score + 0.5 * (ccb_rating / 5.0)\n",
    "    neg_scores.append(combined_score)\n",
    "\n",
    "# Calculate AUC-ROC\n",
    "all_scores = np.concatenate([pos_scores, neg_scores])\n",
    "all_labels = np.concatenate([np.ones(len(pos_scores)), np.zeros(len(neg_scores))])\n",
    "\n",
    "val_auc = roc_auc_score(all_labels, all_scores)\n",
    "\n",
    "print(f\"\\nValidation AUC-ROC: {val_auc:.4f}\")\n",
    "print(f\"  Positive scores: mean={np.mean(pos_scores):.4f}, std={np.std(pos_scores):.4f}\")\n",
    "print(f\"  Negative scores: mean={np.mean(neg_scores):.4f}, std={np.std(neg_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CCC1 - Combined Collaborative Approach (Two-Stage Filtering)\n",
      "======================================================================\n",
      "\n",
      "Strategy:\n",
      "  Stage 1 (CCA2): Connection probability filter\n",
      "    → Top-100 candidates per user\n",
      "  Stage 2 (CCB2): Rating quality filter\n",
      "    → Recommend if predicted_rating >= 4.0\n",
      "\n",
      "Models:\n",
      "  CCA2: 351,648 parameters\n",
      "  CCB2: 352,737 parameters\n",
      "\n",
      "Data:\n",
      "  Good purchases (rating >= 4.0): 51,830\n",
      "  Train: 89,294\n",
      "  Val: 7,480\n",
      "  Test: 8,365\n",
      "\n",
      "Validation Performance:\n",
      "  AUC-ROC: 0.9562\n",
      "  Accuracy: 0.2136\n",
      "  Precision: 1.0000\n",
      "  Recall: 0.2136\n",
      "  F1 Score: 0.3521\n",
      "\n",
      "Test Performance:\n",
      "  Accuracy: 0.2245\n",
      "  Precision: 1.0000\n",
      "  Recall: 0.2245\n",
      "  F1 Score: 0.3667\n",
      "\n",
      "Ready for comparison with CCA2, CCB2, and other CCC variants!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"CCC1 - Combined Collaborative Approach (Two-Stage Filtering)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nStrategy:\")\n",
    "print(f\"  Stage 1 (CCA2): Connection probability filter\")\n",
    "print(f\"    → Top-{CCA_TOP_K_CANDIDATES} candidates per user\")\n",
    "print(f\"  Stage 2 (CCB2): Rating quality filter\")\n",
    "print(f\"    → Recommend if predicted_rating >= {CCB_RATING_THRESHOLD}\")\n",
    "\n",
    "print(f\"\\nModels:\")\n",
    "print(f\"  CCA2: {sum(p.numel() for p in cca_model.parameters()):,} parameters\")\n",
    "print(f\"  CCB2: {sum(p.numel() for p in ccb_model.parameters()):,} parameters\")\n",
    "\n",
    "print(f\"\\nData:\")\n",
    "print(f\"  Good purchases (rating >= {GOOD_RATING_THRESHOLD}): {n_good_purchases:,}\")\n",
    "print(f\"  Train: {len(train_df):,}\")\n",
    "print(f\"  Val: {len(val_df):,}\")\n",
    "print(f\"  Test: {len(test_df):,}\")\n",
    "\n",
    "print(f\"\\nValidation Performance:\")\n",
    "print(f\"  AUC-ROC: {val_auc:.4f}\")\n",
    "print(f\"  Accuracy: {val_acc:.4f}\")\n",
    "print(f\"  Precision: {val_prec:.4f}\")\n",
    "print(f\"  Recall: {val_rec:.4f}\")\n",
    "print(f\"  F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "print(f\"\\nTest Performance:\")\n",
    "print(f\"  Accuracy: {test_acc:.4f}\")\n",
    "print(f\"  Precision: {test_prec:.4f}\")\n",
    "print(f\"  Recall: {test_rec:.4f}\")\n",
    "print(f\"  F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "print(f\"\\nReady for comparison with CCA2, CCB2, and other CCC variants!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
